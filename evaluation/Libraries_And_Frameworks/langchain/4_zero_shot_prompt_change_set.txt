Changes between langchain-openai==0.1.21 and langchain-openai==0.1.22
================================================================================

COMMITS
--------------------------------------------------------------------------------

Commit: 9cd608efb3f7a63af4590c3142c435fd6100a562
Author: maang-h
Date: 2024-08-11 20:20:16+00:00
Message: docs: Standardize OpenAI Docs (#25280)

- **Description:** Standardize OpenAI Docs
- **Issue:** the issue #24803

---------

Co-authored-by: Chester Curme <chester.curme@gmail.com>
----------------------------------------

Commit: 43deed2a95d4739430159fa17f415294f6913d12
Author: ZhangShenao
Date: 2024-08-11 20:20:37+00:00
Message: Improvement[Embeddings] Add dimension support to `ZhipuAIEmbeddings` (#25274)

- In the in ` embedding-3 ` and later models of Zhipu AI, it is
supported to specify the dimensions parameter of Embedding. Ref:
https://bigmodel.cn/dev/api#text_embedding-3 .
- Add test case for `embedding-3` model by assigning dimensions.
----------------------------------------

Commit: bc60cddc1b33e6aff11b1ffec12eae6ab6b21afc
Author: maang-h
Date: 2024-08-11 20:23:55+00:00
Message: docs: Fix ChatBaichuan, QianfanChatEndpoint, ChatSparkLLM, ChatZhipuAI docs (#25265)

- **Description:** Fix some chat models docs, include:
  - ChatBaichuan
  - QianfanChatEndpoint
  - ChatSparkLLM
  - ChatZhipuAI
----------------------------------------

Commit: a82c0533f206548e0ebbdb1a8603e0d9a2eac370
Author: Maddy Adams
Date: 2024-08-11 20:30:52+00:00
Message: langchain: default to langsmith sdk for pulling prompts, fallback to langchainhub (#24156)

**Description:** Deprecating langchainhub, replacing with langsmith sdk
----------------------------------------

Commit: aa2722cbe23e54eea66680caeb1877ea7f3004de
Author: gbaian10
Date: 2024-08-11 20:50:24+00:00
Message: docs: update numbering of items in docstring (#25267)

A problem similar to #25093 .

Co-authored-by: ccurme <chester.curme@gmail.com>
----------------------------------------

Commit: 4fd1efc48f6ccd667b28fe8639d24ff47faf37b7
Author: gbaian10
Date: 2024-08-11 20:51:34+00:00
Message: docs: update "Build an Agent" Installation Hint in agents.ipynb (#25263)

fix #25257
----------------------------------------

Commit: 074fa0db736cdcdd1789ce4cea9983d522b186ac
Author: Aryan Singh
Date: 2024-08-11 20:53:27+00:00
Message: docs: Fixed grammer error in functions.ipynb (#25255)

**Description**: Grammer Error in functions.ipynb
**Issue**: #25222
----------------------------------------

Commit: 472527166f334e47e562fb1d3f11e9cb35d8a45b
Author: Anush
Date: 2024-08-11 20:54:14+00:00
Message: qdrant: Update API reference link and install command (#25245)

## Description

As the title goes. The current API reference links to the deprecated
class.
----------------------------------------

Commit: 9f0eda6a1809f6eab5fe178753bfdf5c68680efa
Author: Soichi Sumi
Date: 2024-08-12 05:12:31+00:00
Message: docs: Fix link for API reference of Gmail Toolkit (#25286)

- **Description:** Fix link for API reference of Gmail Toolkit
- **Issue:** I've just found this issue while I'm reading the doc
- **Dependencies:** N/A
- **Twitter handle:** [@soichisumi](https://x.com/soichisumi)

TODO: If no one reviews your PR within a few days, please @-mention one
of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.
----------------------------------------

Commit: f28ae20b8158f31f03b2ef616c59f3651339371e
Author: JasonJ
Date: 2024-08-12 05:12:44+00:00
Message: docs: pip install bug fixed (#25287)

Thank you for contributing to LangChain!
- **Description:** Fixing package install bug in cookbook
- **Issue:** zsh:1: no matches found: unstructured[all-docs]
- **Dependencies:** N/A
- **Twitter handle:** if your PR gets announced, and you'd like a
mention, we'll gladly shout you out!



If no one reviews your PR within a few days, please @-mention one of
baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.
----------------------------------------

Commit: 794f28d4e29a70e6e7bd65fe47ed7c474cbecc90
Author: Yunus Emre Özdemir
Date: 2024-08-12 13:17:11+00:00
Message: docs: document upstash vector namespaces (#25289)

**Description:** This PR rearranges the examples in Upstash Vector
integration documentation to describe how to use namespaces and improve
the description of metadata filtering.
----------------------------------------

Commit: 420534c8ca637b985cb74b5828fd955e4ab48585
Author: Hassan-Memon
Date: 2024-08-12 13:24:51+00:00
Message: docs: Replaced SqliteSaver with MemorySaver and updated installation instru… (#25285)

…ctions to match LangGraph v2 documentation. Corrected code snippet to
prevent validation errors.

Here's how you can fill out the provided template for your pull request:

---

**Thank you for contributing to LangChain!**

- [ ] **PR title**: `docs: update checkpointer example in Conversational
RAG tutorial`

- [ ] **PR message**:
- **Description:** Updated the Conversational RAG tutorial to correct
the checkpointer example by replacing `SqliteSaver` with `MemorySaver`.
Added installation instructions for `langgraph-checkpoint-memory` to
match LangGraph v2 documentation and prevent validation errors.
    - **Issue:** N/A
    - **Dependencies:** `langgraph-checkpoint-memory`
    - **Twitter handle:** N/A

- [ ] **Add tests and docs**: 
  1. No new integration tests are required.
  2. Updated documentation in the Conversational RAG tutorial.

- [ ] **Lint and test**: Run `make format`, `make lint` and `make test`
from the root of the package(s) you've modified. See contribution
guidelines for more: [LangChain Contribution
Guidelines](https://python.langchain.com/docs/contributing/)

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional
ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in
langchain.

If no one reviews your PR within a few days, please @-mention one of
baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.
----------------------------------------

Commit: 9927a4866d9687dea893765ce07e1195295ce4e5
Author: Mohammad Mohtashim
Date: 2024-08-12 14:11:43+00:00
Message: [Community] - Added bind_tools and with_structured_output for ChatZhipuAI (#23887)

- **Description:** This PR implements the `bind_tool` functionality for
ChatZhipuAI as requested by the user. ChatZhipuAI models support tool
calling according to the `OpenAI` tool format, as outlined in their
official documentation [here](https://open.bigmodel.cn/dev/api#glm-4).
- **Issue:**  ##23868

---------

Co-authored-by: ccurme <chester.curme@gmail.com>
----------------------------------------

Commit: e77eeee6ee8253710b9427565d3c3b987827cccf
Author: ccurme
Date: 2024-08-12 14:51:59+00:00
Message: core[patch]: add standard tracing params for retrievers (#25240)
----------------------------------------

Commit: ee8a585791501e33a7290d039daf0b298d848e66
Author: Eugene Yurtsev
Date: 2024-08-12 14:53:51+00:00
Message: openai[patch]: Add API Reference docs to OpenAIEmbeddings (#25290)

Issue: [24856](https://github.com/langchain-ai/langchain/issues/24856)
----------------------------------------

Commit: 0a3500808dc4b53691e5a2dbb20bea84435bab9c
Author: Eugene Yurtsev
Date: 2024-08-12 15:24:35+00:00
Message: openai[patch]: Docs fix RST formatting in OpenAIEmbeddings (#25293)
----------------------------------------

Commit: 1af8456a2cc8ae94c4beed89f220f18ab7623f70
Author: Eugene Yurtsev
Date: 2024-08-12 15:25:37+00:00
Message: mistralai[patch]: Docs Update APIReference for MistralAIEmbeddings (#25294)

Update API Reference for MistralAI embeddings

Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

Commit: 8626abf8b59b731dd35b8e17401154eddf9bdb81
Author: Eugene Yurtsev
Date: 2024-08-12 17:12:28+00:00
Message: togetherai[patch]: Update API Reference for together AI embeddings model (#25295)

Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

Commit: 53ee5770d3e2dff110a483da4de071b50484c749
Author: Eugene Yurtsev
Date: 2024-08-12 17:13:43+00:00
Message: fireworks: Add APIReference for the FireworksEmbeddings model (#25292)

Add API Reference documentation for the FireworksEmbedding model.

Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

Commit: ccff1ba8b852e6c768ffae4aa3b36d4d8e292951
Author: Eugene Yurtsev
Date: 2024-08-12 17:15:27+00:00
Message: ai21[patch]: Update API reference documentation (#25302)

Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

Commit: 1c9917dfa2239f246a9edaaf140d6818384b79f4
Author: Eugene Yurtsev
Date: 2024-08-12 17:16:13+00:00
Message: fireworks[patch]: Fix doc-string for API Referenmce (#25304)
----------------------------------------

Commit: 5efd0fe9ae03c00f7d236017168c951c1a7658d3
Author: gbaian10
Date: 2024-08-12 17:45:32+00:00
Message: docs: Change SqliteSaver to MemorySaver (#25306)

fix: #25137

`SqliteSaver.from_conn_string()` has been changed to a `contextmanager`
method in `langgraph >= 0.2.0`, the original usage is no longer
applicable.

Refer to
<https://github.com/langchain-ai/langgraph/pull/1271#issue-2454736415>
modification method to replace `SqliteSaver` with `MemorySaver`.
----------------------------------------

Commit: deb27d89701038bd1362a4171631b867935e6fba
Author: Hassan-Memon
Date: 2024-08-12 17:49:55+00:00
Message: docs: remove unused imports in Conversational RAG tutorial (#25297)

Cleaned up the "Tying it Together" section of the Conversational RAG
tutorial by removing unnecessary imports that were not used. This
reduces confusion and makes the code more concise.

Thank you for contributing to LangChain!

PR title: docs: remove unused imports in Conversational RAG tutorial

PR message:

Description: Removed unnecessary imports from the "Tying it Together"
section of the Conversational RAG tutorial. These imports were not used
in the code and created confusion. The updated code is now more concise
and easier to understand.
Issue: N/A
Dependencies: None
LinkedIn handle: [Hassan
Memon](https://www.linkedin.com/in/hassan-memon-a109b3257/)
Add tests and docs:

Hi [LangChain Team Member’s Name],

I hope you're doing well! I’m thrilled to share that I recently made my
second contribution to the LangChain project. If possible, could you
give me a shoutout on LinkedIn? It would mean a lot to me and could help
inspire others to contribute to the community as well.

Here’s my LinkedIn profile: [Hassan
Memon](https://www.linkedin.com/in/hassan-memon-a109b3257/).

Thank you so much for your support and for creating such a great
platform for learning and collaboration. I'm looking forward to
contributing more in the future!

Best regards,
Hassan Memon
----------------------------------------

Commit: 1adc161642c3fbe4488e5dd8a366d8fc3951258e
Author: Ben Chambers
Date: 2024-08-12 18:01:29+00:00
Message: community: kwargs for CassandraGraphVectorStore (#25300)

- **Description:** pass kwargs from CassandraGraphVectorStore to
underlying store

Co-authored-by: ccurme <chester.curme@gmail.com>
----------------------------------------

Commit: 056c7c298366c7d2ddd529f40d76eda6acb98880
Author: Eugene Yurtsev
Date: 2024-08-12 19:40:05+00:00
Message: core[patch]: Update API reference for fake embeddings (#25313)

Issue: https://github.com/langchain-ai/langchain/issues/24856

Using the same template for the fake embeddings in langchain_core as
used in the integrations.
----------------------------------------

Commit: 217a915b29319425c19d1eb39b591dc5f5902852
Author: Eugene Yurtsev
Date: 2024-08-12 19:41:18+00:00
Message: openai: Update API Reference docs for AzureOpenAI Embeddings (#25312)

Update AzureOpenAI Embeddings docs
----------------------------------------

Commit: 252f0877d1e18887c30f59f70d4118f4c08124c0
Author: Erick Friis
Date: 2024-08-12 22:01:24+00:00
Message: core: release 0.2.30 (#25321)
----------------------------------------

Commit: 06f8bd9946f8b42e15766fbffdbf205466d91bf9
Author: Erick Friis
Date: 2024-08-12 22:24:06+00:00
Message: langchain: release 0.2.13 (#25323)
----------------------------------------

Commit: 2907ab2297a98ea128a99046bbddf3af2c568b53
Author: Erick Friis
Date: 2024-08-12 23:30:27+00:00
Message: community: release 0.2.12 (#25324)
----------------------------------------

Commit: f679ed72ca7ec366ccee070899a41058d6c52b31
Author: Eugene Yurtsev
Date: 2024-08-13 01:31:48+00:00
Message: ollama[patch]: Update API Reference for ollama embeddings (#25315)

Update API reference for OllamaEmbeddings
Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

Commit: ebbe609193e801f38a04ebac9234066fc59b66b3
Author: Christophe Bornet
Date: 2024-08-13 13:17:23+00:00
Message: Add README for astradb package (#25345)

Similar to
https://github.com/langchain-ai/langchain/blob/master/libs/partners/ibm/README.md
----------------------------------------

Commit: 24155aa1acaad34726fce0650774c7461dbf4640
Author: Chen Xiabin
Date: 2024-08-13 13:24:41+00:00
Message: qianfan generate/agenerate with usage_metadata (#25332)
----------------------------------------

Commit: 35e2230f56286a5f4b7ace9ac951c9da0718c661
Author: Leonid Ganeline
Date: 2024-08-13 13:29:51+00:00
Message: docs: `integrations`references update (#25322)

Added missed provider pages. Fixed formats and added descriptions and
links.
----------------------------------------

Commit: 089f5e6cad4092185798a045c39c017ae790a8f2
Author: maang-h
Date: 2024-08-13 13:50:12+00:00
Message: Standardize SparkLLM (#25239)

- **Description:** Standardize SparkLLM, include:
  - docs, the issue #24803 
  - to support stream
  - update api url
  - model init arg names, the issue #20085
----------------------------------------

Commit: b6df3405fb56b9f61c4d383034936ab9cb4013ac
Author: Matt Kandler
Date: 2024-08-13 18:18:19+00:00
Message: docs: Fix broken link to Runhouse documentation (#25349)

- **Description:** Runhouse recently migrated from Read the Docs to a
self-hosted solution. This PR updates a broken link from the old docs to
www.run.house/docs. Also changed "The Runhouse" to "Runhouse" (it's
cleaner).
- **Issue:** None
- **Dependencies:** None
----------------------------------------

Commit: 2b15518c5fbecd25489d64ccad1223d94e4dfadd
Author: Fedor Nikolaev
Date: 2024-08-13 18:26:09+00:00
Message: community: add args_schema to SearxSearchResults tool (#25350)

This adds `args_schema` member to `SearxSearchResults` tool. This member
is already present in the `SearxSearchRun` tool in the same file.

I was having `TypeError: Type is not JSON serializable:
AsyncCallbackManagerForToolRun` being thrown in langserve playground
when I was using `SearxSearchResults` tool as a part of chain there.
This fixes the issue, so the error is not raised anymore.

This is a example langserve app that was giving me the error, but it
works properly after the proposed fix:
```python
#!/usr/bin/env python

from fastapi import FastAPI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SearxSearchWrapper
from langchain_community.tools.searx_search.tool import SearxSearchResults
from langserve import add_routes

template = """Answer the question based only on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
model = ChatOpenAI()

s = SearxSearchWrapper(searx_host="http://localhost:8080")

search = SearxSearchResults(wrapper=s)

search_chain = (
    {"context": search, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

app = FastAPI()

add_routes(
    app,
    search_chain,
    path="/chain",
)

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="localhost", port=8000)
```
----------------------------------------

Commit: 6bc451b942d255cadab8afa7b64c3d9c7595eff0
Author: Isaac Francisco
Date: 2024-08-13 19:19:17+00:00
Message: [docs]: merge tool/toolkit duplicates (#25197)
----------------------------------------

Commit: 9d083694428a2e44c7261a4c9b9a469d8defffe6
Author: thedavgar
Date: 2024-08-13 21:20:51+00:00
Message: community: fix AzureSearch vectorstore asyncronous methods (#24921)

**Description**
Fix the asyncronous methods to retrieve documents from AzureSearch
VectorStore. The previous changes from [this
commit](https://github.com/langchain-ai/langchain/commit/ffe6ca986ee5b439e85c82781c1d8ce3578a3e88)
create a similar code for the syncronous methods and the asyncronous
ones but the asyncronous client return an asyncronous iterator
"AsyncSearchItemPaged" as said in the issue #24740.
To solve this issue, the syncronous iterators in asyncronous methods
where changed to asyncronous iterators.

@chrislrobert said in [this
comment](https://github.com/langchain-ai/langchain/issues/24740#issuecomment-2254168302)
that there was a still a flaw due to `with` blocks that close the client
after each call. I removed this `with` blocks in the `async_client`
following the same pattern as the sync `client`.

In order to close up the connections, a __del__ method is included to
gently close up clients once the vectorstore object is destroyed.

**Issue:** #24740 and #24064
**Dependencies:** No new dependencies for this change

**Example notebook:** I created a notebook just to test the changes work
and gives the same results as the syncronous methods for vector and
hybrid search. With these changes, the asyncronous methods in the
retriever work as well.

![image](https://github.com/user-attachments/assets/697e431b-9d7f-4d0d-b205-59d051ac2b67)


**Lint and test**: Passes the tests and the linter
----------------------------------------

Commit: 0478f7f5e4461d224b1d817ffd8cae67c9f7f8a7
Author: Isaac Francisco
Date: 2024-08-13 21:50:45+00:00
Message: [docs]: LLM integration pages (#25005)
----------------------------------------

Commit: d5b548b4ced7364fbf060a72f42a9d6d0bec5d6f
Author: Erick Friis
Date: 2024-08-13 22:52:51+00:00
Message: docs: index pages, sidebars (#25316)
----------------------------------------

Commit: e0bbb81d041938a91dae2b09bc02146966abdb94
Author: Isaac Francisco
Date: 2024-08-13 23:10:00+00:00
Message: [docs]: standardize tool docstrings (#25351)
----------------------------------------

Commit: f4ffd692a3548681b4d05c0f255a9b83c07a2e0b
Author: Isaac Francisco
Date: 2024-08-13 23:18:56+00:00
Message: [docs]: standardize doc loader doc strings (#25325)
----------------------------------------

Commit: b1aed44540e41a75d77b0970deb5169a6ab4f05d
Author: Eugene Yurtsev
Date: 2024-08-14 00:04:18+00:00
Message: docs: Updating integration docs for Fireworks Embeddings (#25247)

Providers:
* fireworks

See related issue:
* https://github.com/langchain-ai/langchain/issues/24856

Features:

```json
[
   {
      "provider": "fireworks",
      "js":  true,
      "local": false,
     "serializable": false,
   }



]


```

---------

Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
----------------------------------------

Commit: a4ef8304807f929731b0fa12bad661e4a06283ef
Author: Eugene Yurtsev
Date: 2024-08-14 00:21:36+00:00
Message: docs: update integration docs for openai embeddings (#25249)

Related issue: https://github.com/langchain-ai/langchain/issues/24856

```json
   {
      "provider": "openai",
      "js":  true,
      "local": false,
     "serializable": false,
"async_native": true
  }
```

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: 8645a49f310c7b3fda057e75f6092d0f0d64d0aa
Author: Eugene Yurtsev
Date: 2024-08-14 00:23:05+00:00
Message: docs: Update integration docs for OllamaEmbeddingsModel (#25314)

Issue: https://github.com/langchain-ai/langchain/issues/24856

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: 0f6217f507e3c208921f95d4812c3f49567a9419
Author: Eugene Yurtsev
Date: 2024-08-14 00:24:02+00:00
Message: docs: together ai embeddings integration docs (#25252)

Update together AI embedding integration docs

Related issue: https://github.com/langchain-ai/langchain/issues/24856

```json
[
   {
      "provider": "together",
      "js":  true,
      "local": false,
     "serializable": false,
   }
]
```

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: d55d99222b1d497bbc8463796b163784a3d14dd4
Author: Eugene Yurtsev
Date: 2024-08-14 00:25:36+00:00
Message: docs: update integration docs for mistral ai embedding model (#25253)

Related issue: https://github.com/langchain-ai/langchain/issues/24856

```json
[
   {
      "provider": "mistralai",
      "js":  true,
      "local": false,
     "serializable": false,
    "native_async": true
   }
]
```

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: f82c3f622a8053d8e7b5e204c3a57d5445278bdf
Author: Eugene Yurtsev
Date: 2024-08-14 00:30:16+00:00
Message: docs: Update AI21Embeddings Integration docs (#25298)

Update AI21 Integration docs

Issue: https://github.com/langchain-ai/langchain/issues/24856

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: b4e3bdb7146cdf3fe8dbd37cbfa224894adef74f
Author: Eugene Yurtsev
Date: 2024-08-14 00:32:07+00:00
Message: docs: Update nomic AI embeddings integration docs (#25308)

Issue: https://github.com/langchain-ai/langchain/issues/24856

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: 27def6bddb2e055d0f706e7f025aceb84b3dfee6
Author: Eugene Yurtsev
Date: 2024-08-14 00:33:13+00:00
Message: docs[patch]: Update integration docs for AzureOpenAIEmbeddings (#25311)

https://github.com/langchain-ai/langchain/issues/24856

---------

Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
----------------------------------------

Commit: 93dcc47463e53ad3e1611e1abd94fd1f82f0733c
Author: Eugene Yurtsev
Date: 2024-08-14 00:53:13+00:00
Message: docs: Partial integration update for cohere embeddings (#25250)

This can be finished after the following issue is resolved:

https://github.com/langchain-ai/langchain-cohere/issues/81

Related to: https://github.com/langchain-ai/langchain/issues/24856

```json
[
   {
      "provider": "cohere",
      "js":  true,
      "local": false,
     "serializable": false,
   }
]
```

---------

Co-authored-by: isaac hershenson <ihershenson@hmc.edu>
Co-authored-by: Isaac Francisco <78627776+isahers1@users.noreply.github.com>
----------------------------------------

Commit: d6c180996ff46a63da1792782c074b59924a81cc
Author: Eugene Yurtsev
Date: 2024-08-14 01:18:54+00:00
Message: docs[patch]: Fix typo in CohereEmbeddings integration docs (#25367)

Fix typo
----------------------------------------

Commit: 4a78be78619fdb0e84092d9fc7be3f48488975ab
Author: Erick Friis
Date: 2024-08-14 01:47:12+00:00
Message: docs: remove sidebar comment (#25369)
----------------------------------------

Commit: 967b6f21f6462f16f0ba4dc38ed914ec4ca550ce
Author: Harrison Chase
Date: 2024-08-14 01:48:48+00:00
Message: docs: improve document loaders index (#25365)

Co-authored-by: Erick Friis <erick@langchain.dev>
----------------------------------------

Commit: 10e6725a7e33f9bc88956a8e2e0a7c9cdaf96893
Author: Erick Friis
Date: 2024-08-14 02:38:03+00:00
Message: docs: tools index table (#25370)
----------------------------------------

Commit: 4029f5650cfed8b585f520aa64ee2be3cfb58f5d
Author: Ikko Eltociear Ashimine
Date: 2024-08-14 13:20:17+00:00
Message: docs: update clarifai.ipynb (#25373)

Intialize -> Initialize
----------------------------------------

Commit: 27690506d0b65a425d3fd9b73a0a77eec5520ad3
Author: ccurme
Date: 2024-08-14 13:50:39+00:00
Message: multiple: update removal targets (#25361)
----------------------------------------

Commit: dc51cc569036bc4a5f510f87437d91bcc5f3dc25
Author: Eugene Yurtsev
Date: 2024-08-14 13:54:31+00:00
Message: core[minor]: Prevent PydanticOutputParser from encoding schema as ASCII (#25386)

This allows users to provide parameter descriptions in the pydantic
models in other languages.

Continuing this PR: https://github.com/langchain-ai/langchain/pull/24809
----------------------------------------

Commit: d00176e52382e102f249fb5899c23e6426515785
Author: Eugene Yurtsev
Date: 2024-08-14 13:55:18+00:00
Message: openai[patch]: Update extra to match pydantic 2 (#25382)

Backwards compatible change that converts pydantic extras to literals
which is consistent with pydantic 2 usage.
----------------------------------------

Commit: 5f5e8c9a60e49058cd82d80966f88c499179453d
Author: Eugene Yurtsev
Date: 2024-08-14 13:55:30+00:00
Message: huggingface[patch], pinecone[patch], fireworks[patch], mistralai[patch], voyageai[patch], togetherai[path]: convert Pydantic extras to literals (#25384)

Backwards compatible change that converts pydantic extras to literals
which is consistent with pydantic 2 usage.

- fireworks
- voyage ai
- mistralai
- mistral ai
- together ai
- huggigng face
- pinecone
----------------------------------------

Commit: 4a812e319313cca80fc98b00a4de3317e5c2842a
Author: Leonid Ganeline
Date: 2024-08-14 13:58:38+00:00
Message: docs: `integrations` references update (#25217)

Added missed provider pages. Fixed formats and added descriptions and
links.

---------

Co-authored-by: Chester Curme <chester.curme@gmail.com>
----------------------------------------

Commit: 493e474063817b9a4c2521586b2dbc34d20b4cf1
Author: Bagatur
Date: 2024-08-14 14:00:17+00:00
Message: docs: udpated api reference (#25172)

- Move the API reference into the vercel build
- Update api reference organization and styling
----------------------------------------

Commit: ddd7919f6a46959e887c8bba719155001b56f0d0
Author: Jacob Lee
Date: 2024-08-14 14:14:24+00:00
Message: docs[patch]: Add conceptual guide links to integration index pages (#25387)
----------------------------------------

Commit: d0ad71393736d2fe0e8ed1a16fb5f64495b97c7a
Author: Chengyu Yan
Date: 2024-08-14 14:26:22+00:00
Message: core: fix issue#24660, slove error messages about `ValueError` when use model with history (#25183)

- **Description:**
This PR will slove error messages about `ValueError` when use model with
history.
Detail in #24660.
#22933 causes that
`langchain_core.runnables.history.RunnableWithMessageHistory._get_output_messages`
miss type check of `output_val` if `output_val` is `False`. After
running `RunnableWithMessageHistory._is_not_async`, `output` is `False`.

https://github.com/langchain-ai/langchain/blob/249945a572a58a307cab1ae79e199e85b2707ff0/libs/core/langchain_core/runnables/history.py#L323-L334

https://github.com/langchain-ai/langchain/blob/15a36dd0a2bce0ec07090350c39de2fbaf3f05bc/libs/core/langchain_core/runnables/history.py#L461-L471
~~I suggest that `_get_output_messages` return empty list when
`output_val == False`.~~

- **Issue**:
  - #24660

- **Dependencies:**: No Change.

---------

Co-authored-by: Bagatur <baskaryan@gmail.com>
Co-authored-by: Eugene Yurtsev <eyurtsev@gmail.com>
----------------------------------------

Commit: f4196f1fb8d31950ca42fb068a21519d1aee1970
Author: Eugene Yurtsev
Date: 2024-08-14 14:30:01+00:00
Message: ollama[patch]: Update extra in ollama package (#25383)

Backwards compatible change that converts pydantic extras to literals
which is consistent with pydantic 2 usage.
----------------------------------------

Commit: f0f125dac7f58528d02efd248ba7f2aaf6af7c05
Author: Flávio Knob
Date: 2024-08-14 15:07:42+00:00
Message: Update document_loader_custom.ipynb (#25391)

Fix typo and some `callout` tags

Thank you for contributing to LangChain!

- [ ] **PR title**: "package: description"
- Where "package" is whichever of langchain, community, core,
experimental, etc. is being modified. Use "docs: ..." for purely docs
changes, "templates: ..." for template changes, "infra: ..." for CI
changes.
  - Example: "community: add foobar LLM"


- [ ] **PR message**: ***Delete this entire checklist*** and replace
with
    - **Description:** a description of the change
    - **Issue:** the issue # it fixes, if applicable
    - **Dependencies:** any dependencies required for this change
- **Twitter handle:** if your PR gets announced, and you'd like a
mention, we'll gladly shout you out!


- [ ] **Add tests and docs**: If you're adding a new integration, please
include
1. a test for the integration, preferably unit tests that do not rely on
network access,
2. an example notebook showing its use. It lives in
`docs/docs/integrations` directory.


- [ ] **Lint and test**: Run `make format`, `make lint` and `make test`
from the root of the package(s) you've modified. See contribution
guidelines for more: https://python.langchain.com/docs/contributing/

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional
ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in
langchain.

If no one reviews your PR within a few days, please @-mention one of
baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.
----------------------------------------

Commit: eec7bb4f5126d1682cde120fbc074595f80b943e
Author: Bagatur
Date: 2024-08-14 16:03:39+00:00
Message: anthropic[patch]: Release 0.1.23 (#25394)
----------------------------------------

Commit: 63c483ea01167a1ed6eded7a074793ad46569eaa
Author: Bagatur
Date: 2024-08-14 16:13:56+00:00
Message: standard-tests: import fix (#25395)
----------------------------------------

Commit: 012929551cb93d62e1800e8cb9c3480973cf4412
Author: Jacob Lee
Date: 2024-08-14 16:17:39+00:00
Message: docs[patch]: Hide deprecated integration pages (#25389)
----------------------------------------

Commit: 94c9cb732110e4a87310a5b4c2340561dfb41938
Author: Flávio Knob
Date: 2024-08-14 16:33:21+00:00
Message: Update document_loader_custom.ipynb (#25393)

Fix typo

Thank you for contributing to LangChain!

- [ ] **PR title**: "package: description"
- Where "package" is whichever of langchain, community, core,
experimental, etc. is being modified. Use "docs: ..." for purely docs
changes, "templates: ..." for template changes, "infra: ..." for CI
changes.
  - Example: "community: add foobar LLM"


- [ ] **PR message**: ***Delete this entire checklist*** and replace
with
    - **Description:** a description of the change
    - **Issue:** the issue # it fixes, if applicable
    - **Dependencies:** any dependencies required for this change
- **Twitter handle:** if your PR gets announced, and you'd like a
mention, we'll gladly shout you out!


- [ ] **Add tests and docs**: If you're adding a new integration, please
include
1. a test for the integration, preferably unit tests that do not rely on
network access,
2. an example notebook showing its use. It lives in
`docs/docs/integrations` directory.


- [ ] **Lint and test**: Run `make format`, `make lint` and `make test`
from the root of the package(s) you've modified. See contribution
guidelines for more: https://python.langchain.com/docs/contributing/

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional
ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in
langchain.

If no one reviews your PR within a few days, please @-mention one of
baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.
----------------------------------------

Commit: 414154fa59d73e62241140a43996cadc01e1ff7a
Author: Bagatur
Date: 2024-08-14 17:09:43+00:00
Message: experimental[patch]: refactor rl chain structure (#25398)

can't have a class and function with same name but different
capitalization in same file for api reference building
----------------------------------------

Commit: d178fb9dc36de2642439304f3620a5df70d92468
Author: Bagatur
Date: 2024-08-14 17:40:16+00:00
Message: docs: fix api ref package tables (#25400)
----------------------------------------

Commit: a58d4ba3406f01a4aae9ea3b35f1845ba6dbe2cb
Author: Bagatur
Date: 2024-08-14 18:26:49+00:00
Message: core[patch]: Release 0.2.31 (#25388)
----------------------------------------

Commit: 1d3f7231b8ee8a2bc6b18305eaaa12cfa30b08cd
Author: Werner van der Merwe
Date: 2024-08-14 18:36:25+00:00
Message: fix: typo where github should be gitlab (#25397)

**PR title**: "GitLabToolkit: fix typo"
    - **Description:** fix typo where GitHub should have been GitLab
    - **Dependencies:** None
----------------------------------------

Commit: ab29ee79a3f982a059edfa273555bb44d1cb59d3
Author: Erick Friis
Date: 2024-08-14 18:36:41+00:00
Message: docs: fix tool index (#25404)
----------------------------------------

Commit: dc80be5efe70f13947169f37e4abe17ba54c8137
Author: Bagatur
Date: 2024-08-14 19:25:39+00:00
Message: docs: fix deprecated functions table (#25409)
----------------------------------------

Commit: 63aba3fe5b9f851d211f769ae054333f6401b58e
Author: Isaac Francisco
Date: 2024-08-14 20:58:54+00:00
Message: [docs]: link fix directory loader (#25411)
----------------------------------------

Commit: 0a999357943d0fc22d1eb37b9f01089958b3561f
Author: gbaian10
Date: 2024-08-14 22:07:15+00:00
Message: docs: remove the extra period in docstring (#25414)

Remove the period after the hyperlink in the docstring of
BaseChatOpenAI.with_structured_output.

I have repeatedly copied the extra period at the end of the hyperlink,
which results in a "Page not found" page when pasted into the browser.
----------------------------------------

Commit: c4779f5b9c5a44938b86ce5ab408ffdb24f13a60
Author: Isaac Francisco
Date: 2024-08-14 22:27:40+00:00
Message: [docs]: sitemaploader update (#25363)
----------------------------------------

Commit: 1050e890c6e31d7ad3583c0ab03ef8ef5b2aa223
Author: ccurme
Date: 2024-08-14 22:29:39+00:00
Message: langchain: release 0.2.14 (#25416)

Fixes https://github.com/langchain-ai/langchain/issues/25413
----------------------------------------

Commit: df632b8cdecfc2803058970c7889a768e83ee400
Author: ccurme
Date: 2024-08-14 22:51:35+00:00
Message: langchain: bump min core version (#25418)
----------------------------------------

Commit: 2494cecabf6f241969a20215c0685c078d4e5633
Author: Bagatur
Date: 2024-08-14 22:54:13+00:00
Message: core[patch]: tool import fix (#25419)
----------------------------------------

Commit: ec8ffc8f40bc10fa7dd1c1ff08e49a847609587f
Author: Bagatur
Date: 2024-08-14 22:56:56+00:00
Message: core[patch]: Release 0.2.32 (#25420)
----------------------------------------

Commit: bd261456f6b8f183f0f95fe92da941cb5b46226d
Author: ccurme
Date: 2024-08-15 00:00:42+00:00
Message: langchain: bump core to 0.2.32 (#25421)
----------------------------------------

Commit: 966b40863436cbe88e1852d5f5d85f52d0aefe0e
Author: Isaac Francisco
Date: 2024-08-15 02:46:33+00:00
Message: [docs]: doc loader changes (#25417)
----------------------------------------

Commit: f18b77fd5964b5baabca66078af51b2e2662a6df
Author: Isaac Francisco
Date: 2024-08-15 04:44:57+00:00
Message: [docs]: pdf loaders (#25425)
----------------------------------------

Commit: 44f69063b14e26e716265b801782816ecbe758da
Author: Eugene Yurtsev
Date: 2024-08-15 13:48:36+00:00
Message: docs[patch]: Fix a few typos in the chat integration docs for TogetherAI (#25424)

Fix a few minor typos
----------------------------------------

Commit: ba167dc15852043f185c12103fde00f28b14a29c
Author: ccurme
Date: 2024-08-15 14:07:54+00:00
Message: community[patch]: update connection string in azure cosmos integration test (#25438)
----------------------------------------

Commit: 66e30efa61f94d2ea4ea23276c03ca1585d8b817
Author: Luke
Date: 2024-08-15 14:46:30+00:00
Message: experimental: Fix divide by 0 error (#25439)

Within the semantic chunker, when calling `_threshold_from_clusters`
there is the possibility for a divide by 0 error if the
`number_of_chunks` is equal to the length of `distances`.

Fix simply implements a check if these values match to prevent the error
and enable chunking to continue.
----------------------------------------

Commit: 8afbab4cf6adc5342556dd8c64db4feef1bdd5a6
Author: ccurme
Date: 2024-08-15 14:49:26+00:00
Message: langchain[patch]: deprecate various chains (#25310)

- [x] NatbotChain: move to community, deprecate langchain version.
Update to use `prompt | llm | output_parser` instead of LLMChain.
- [x] LLMMathChain: deprecate + add langgraph replacement example to API
ref
- [x] HypotheticalDocumentEmbedder (retriever): update to use `prompt |
llm | output_parser` instead of LLMChain
- [x] FlareChain: update to use `prompt | llm | output_parser` instead
of LLMChain
- [x] ConstitutionalChain: deprecate + add langgraph replacement example
to API ref
- [x] LLMChainExtractor (document compressor): update to use `prompt |
llm | output_parser` instead of LLMChain
- [x] LLMChainFilter (document compressor): update to use `prompt | llm
| output_parser` instead of LLMChain
- [x] RePhraseQueryRetriever (retriever): update to use `prompt | llm |
output_parser` instead of LLMChain
----------------------------------------

Commit: 6f68c8d6ab2af23849f92d307df3e9ffd2ca4e0f
Author: Eugene Yurtsev
Date: 2024-08-15 15:26:24+00:00
Message: mistralai[patch]: Update root validator for compatibility with pydantic 2 (#25403)
----------------------------------------

Commit: a114255b822f5dd41dd1f9fb48aa72e1969c89e9
Author: Eugene Yurtsev
Date: 2024-08-15 15:26:44+00:00
Message: ai21[patch]: Update @root_validators for pydantic2 migration (#25401)

Update @root_validators for pydantic 2 migration.
----------------------------------------

Commit: 831708beb7309b6acdf58b67328eb48c04cb63c0
Author: Eugene Yurtsev
Date: 2024-08-15 15:27:42+00:00
Message: together[patch]: Update @root_validator for pydantic 2 compatibility (#25423)

This PR updates usage of @root_validator to be compatible with pydantic 2.
----------------------------------------

Commit: 6910b0b3aa305dc49e0c87130e29ece4c591a77c
Author: Eugene Yurtsev
Date: 2024-08-15 16:42:33+00:00
Message: docs[patch]: Fix integration notebook for Fireworks llm (#25442)

Fix integration notebook
----------------------------------------

Commit: 2ef9d12372786337fd32b18b69cdb91bf8fbd539
Author: Eugene Yurtsev
Date: 2024-08-15 16:44:42+00:00
Message: mistralai[patch]: Update more @root_validators for pydantic 2 compatibility (#25446)

Update @root_validators in mistralai integration for pydantic 2 compatibility
----------------------------------------

Commit: 60b65528c5e3c7d8ea326428d92bc1a5e9160ada
Author: Bagatur
Date: 2024-08-15 16:52:12+00:00
Message: docs: fix api ref mod links in pkg page (#25447)
----------------------------------------

Commit: b7c070d4379db46f64b25062a47c542efd6f643c
Author: Eugene Yurtsev
Date: 2024-08-15 16:52:37+00:00
Message: docs[patch]: Update code that checks API keys (#25444)

Check whether the API key is already in the environment

Update:

```python
import getpass
import os

os.environ["DATABRICKS_HOST"] = "https://your-workspace.cloud.databricks.com"
os.environ["DATABRICKS_TOKEN"] = getpass.getpass("Enter your Databricks access token: ")
```

To:

```python
import getpass
import os

os.environ["DATABRICKS_HOST"] = "https://your-workspace.cloud.databricks.com"
if "DATABRICKS_TOKEN" not in os.environ:
    os.environ["DATABRICKS_TOKEN"] = getpass.getpass(
        "Enter your Databricks access token: "
    )
```

grit migration:

```
engine marzano(0.1)
language python

`os.environ[$Q] = getpass.getpass("$X")` as $CHECK where {
    $CHECK <: ! within if_statement(),
    $CHECK => `if $Q not in os.environ:\n    $CHECK`
}
```
----------------------------------------

Commit: 75ae585deb4143e2c5f9774c74f10aa963fc0b3d
Author: William FH
Date: 2024-08-15 16:56:31+00:00
Message: Merge support for group manager (#25360)
----------------------------------------

Commit: eb3870e9d83ec6efc2c1486fc742f309cb923619
Author: Eugene Yurtsev
Date: 2024-08-15 16:56:48+00:00
Message: fireworks[patch]: Upgrade @root_validators to be pydantic 2 compliant  (#25443)

Update @root_validators to be pydantic 2 compliant
----------------------------------------

Commit: 2b4fbcb4b4f20a1169f7cd3a3b6e4398b9c8b942
Author: Bagatur
Date: 2024-08-15 16:57:54+00:00
Message: docs: format oai embeddings docstring (#25448)
----------------------------------------

Commit: 5150ec3a04a27e6498e7c4a4eb1f7dd7b4809eb5
Author: Isaac Francisco
Date: 2024-08-15 17:50:57+00:00
Message: [experimental]: minor fix to open assistants code (#24682)
----------------------------------------

Commit: 8eb63a609e2e4e9ef394496625dfc36ca5b4e0a8
Author: Leonid Ganeline
Date: 2024-08-15 18:30:35+00:00
Message: docs: `arxiv` page update (#25450)

Added `arxive` papers that use `LangGraph` or `LangSmith`. Improved the
page formatting.
----------------------------------------

Commit: d72a08a60d70b271e6b37d5d82bffd174b2b5265
Author: Eugene Yurtsev
Date: 2024-08-15 18:46:52+00:00
Message: groq[patch]: Update root validators for pydantic 2 migration (#25402)
----------------------------------------

Commit: 4cdaca67dc51dba887289f56c6fead3c1a52f97d
Author: Eugene Yurtsev
Date: 2024-08-15 18:54:08+00:00
Message: ai21[patch]: Upgrade @root_validators for pydantic 2 migration (#25454)

Upgrade @root_validators usage to match pydantic 2 semantics
----------------------------------------

Commit: b297af5482ae7c6d26779513d637ec657a1cd552
Author: Eugene Yurtsev
Date: 2024-08-15 19:30:41+00:00
Message: voyageai[patch]: Upgrade root validators for pydantic 2 (#25455)

Update @root_validators to be consistent with pydantic 2 semantics
----------------------------------------

Commit: 34da8be60b6afe2544bb7e45ead0a4fe43bdf75a
Author: Eugene Yurtsev
Date: 2024-08-15 19:45:14+00:00
Message: pinecone[patch]: Upgrade @root_validators to be consistent with pydantic 2 (#25453)

Upgrade root validators for pydantic 2 migration
----------------------------------------

Commit: e18511bb22647201e6b766582df382be65c98a12
Author: Eugene Yurtsev
Date: 2024-08-15 20:09:34+00:00
Message: core[minor], anthropic[patch]: Upgrade @root_validator usage to be consistent with pydantic 2 (#25457)

anthropic: Upgrade `@root_validator` usage to be consistent with
pydantic 2
core: support looking up multiple keys from env in from_env factory
----------------------------------------

Commit: 253ceca76a027a9c70b51f3ccf5ad5bfad4cf672
Author: Bagatur
Date: 2024-08-15 23:16:52+00:00
Message: docs: fix mimetype parser docstring (#25463)
----------------------------------------

Commit: 1fd1c1dca5bc0434422f23664cad99c8d385b198
Author: Eugene Yurtsev
Date: 2024-08-16 15:59:18+00:00
Message: docs: use .invoke rather than __call__ in openai integration notebook (#25494)

Documentation should be using .invoke()
----------------------------------------

Commit: 01ecd0acba22f8bf84c56a603c3e277ce5bc7ae6
Author: ccurme
Date: 2024-08-16 16:50:50+00:00
Message: openai[patch]: fix json mode for Azure (#25488)

https://github.com/langchain-ai/langchain/issues/25479
https://github.com/langchain-ai/langchain/issues/25485

---------

Co-authored-by: Bagatur <baskaryan@gmail.com>
----------------------------------------

Commit: 9f0c76bf89e0837254516fe2a57281f827a89beb
Author: Bagatur
Date: 2024-08-16 16:53:04+00:00
Message: openai[patch]: Release 0.1.22 (#25496)
----------------------------------------

Commit: b83f1eb0d56dbf99605a1fce93953ee09d77aabf
Author: ccurme
Date: 2024-08-16 17:18:09+00:00
Message: core, partners: implement standard tracing params for LLMs (#25410)
----------------------------------------

Commit: df98552b6f1e3f81c153703b9a47c0d7e62890d6
Author: Bagatur
Date: 2024-08-16 18:18:54+00:00
Message: core[patch]: Release 0.2.33 (#25498)
----------------------------------------

Commit: a06818a6543793e1b21f5896135244949e02c8e1
Author: Bagatur
Date: 2024-08-16 18:30:17+00:00
Message: openai[patch]: update core dep (#25502)
----------------------------------------


PULL REQUESTS
--------------------------------------------------------------------------------

PR #24921: community: fix AzureSearch vectorstore asyncronous methods
Author: thedavgar
Merged at: 2024-08-13 21:20:51+00:00
URL: https://github.com/langchain-ai/langchain/pull/24921
Description:
**Description**
Fix the asyncronous methods to retrieve documents from AzureSearch VectorStore. The previous changes from [this commit](https://github.com/langchain-ai/langchain/commit/ffe6ca986ee5b439e85c82781c1d8ce3578a3e88) create a similar code for the syncronous methods and the asyncronous ones but the asyncronous client return an asyncronous iterator "AsyncSearchItemPaged" as said in the issue #24740.
To solve this issue, the syncronous iterators in asyncronous methods where changed to asyncronous iterators.

@chrislrobert said in [this comment](https://github.com/langchain-ai/langchain/issues/24740#issuecomment-2254168302) that there was a still a flaw due to `with` blocks that close the client after each call. I removed this `with` blocks in the `async_client` following the same pattern as the sync `client`.

In order to close up the connections, a __del__ method is included to gently close up clients once the vectorstore object is destroyed.

**Issue:** #24740 and #24064
**Dependencies:** No new dependencies for this change

**Example notebook:** I created a notebook just to test the changes work and gives the same results as the syncronous methods for vector and hybrid search. With these changes, the asyncronous methods in the retriever work as well.
![image](https://github.com/user-attachments/assets/697e431b-9d7f-4d0d-b205-59d051ac2b67)


**Lint and test**: Passes the tests and the linter

----------------------------------------

PR #25350: community: add args_schema to SearxSearchResults tool
Author: fedorn
Merged at: 2024-08-13 18:26:09+00:00
URL: https://github.com/langchain-ai/langchain/pull/25350
Description:
This adds `args_schema` member to `SearxSearchResults` tool. This member is already present in the `SearxSearchRun` tool in the same file.

I was having `TypeError: Type is not JSON serializable: AsyncCallbackManagerForToolRun` being thrown in langserve playground when I was using `SearxSearchResults` tool as a part of chain there. This fixes the issue, so the error is not raised anymore.

This is a example langserve app that was giving me the error, but it works properly after the proposed fix:
```python
#!/usr/bin/env python

from fastapi import FastAPI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI
from langchain_community.utilities import SearxSearchWrapper
from langchain_community.tools.searx_search.tool import SearxSearchResults
from langserve import add_routes

template = """Answer the question based only on the following context:
{context}

Question: {question}
"""
prompt = ChatPromptTemplate.from_template(template)
model = ChatOpenAI()

s = SearxSearchWrapper(searx_host="http://localhost:8080")

search = SearxSearchResults(wrapper=s)

search_chain = (
    {"context": search, "question": RunnablePassthrough()}
    | prompt
    | model
    | StrOutputParser()
)

app = FastAPI()

add_routes(
    app,
    search_chain,
    path="/chain",
)

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(app, host="localhost", port=8000)
```
----------------------------------------

PR #25414: docs: remove the extra period in docstring
Author: gbaian10
Merged at: 2024-08-14 22:07:15+00:00
URL: https://github.com/langchain-ai/langchain/pull/25414
Description:
Remove the period after the hyperlink in the docstring of BaseChatOpenAI.with_structured_output.

I have repeatedly copied the extra period at the end of the hyperlink, which results in a "Page not found" page when pasted into the browser.
----------------------------------------

PR #25498: core[patch]: Release 0.2.33
Author: baskaryan
Merged at: 2024-08-16 18:18:54+00:00
URL: https://github.com/langchain-ai/langchain/pull/25498
Description:
None
----------------------------------------

PR #25410: core, partners: implement standard tracing params for LLMs
Author: ccurme
Merged at: 2024-08-16 17:18:09+00:00
URL: https://github.com/langchain-ai/langchain/pull/25410
Description:
None
----------------------------------------

PR #25496: openai[patch]: Release 0.1.22
Author: baskaryan
Merged at: 2024-08-16 16:53:04+00:00
URL: https://github.com/langchain-ai/langchain/pull/25496
Description:
None
----------------------------------------

PR #25488: openai[patch]: fix json mode for Azure
Author: ccurme
Merged at: 2024-08-16 16:50:51+00:00
URL: https://github.com/langchain-ai/langchain/pull/25488
Description:
https://github.com/langchain-ai/langchain/issues/25479
https://github.com/langchain-ai/langchain/issues/25485
----------------------------------------

PR #25494: docs: use .invoke rather than __call__ in openai integration notebook
Author: eyurtsev
Merged at: 2024-08-16 15:59:18+00:00
URL: https://github.com/langchain-ai/langchain/pull/25494
Description:
Documentation should be using .invoke()

----------------------------------------

PR #25463: docs: fix mimetype parser docstring
Author: baskaryan
Merged at: 2024-08-15 23:16:53+00:00
URL: https://github.com/langchain-ai/langchain/pull/25463
Description:
None
----------------------------------------

PR #25457: core[minor], anthropic[patch]: Upgrade @root_validator usage to be consistent with pydantic 2
Author: eyurtsev
Merged at: 2024-08-15 20:09:35+00:00
URL: https://github.com/langchain-ai/langchain/pull/25457
Description:
anthropic: Upgrade `@root_validator` usage to be consistent with pydantic 2
core: support looking up multiple keys from env in from_env factory

----------------------------------------

PR #25453: pinecone[patch]: Upgrade @root_validators to be consistent with pydantic 2
Author: eyurtsev
Merged at: 2024-08-15 19:45:15+00:00
URL: https://github.com/langchain-ai/langchain/pull/25453
Description:
Upgrade root validators for pydantic 2 migration

----------------------------------------

PR #25455: voyageai[patch]: Upgrade root validators for pydantic 2
Author: eyurtsev
Merged at: 2024-08-15 19:30:41+00:00
URL: https://github.com/langchain-ai/langchain/pull/25455
Description:
Update @root_validators to be consistent with pydantic 2 semantics
----------------------------------------

PR #25454: ai21[patch]: Upgrade @root_validators for pydantic 2 migration
Author: eyurtsev
Merged at: 2024-08-15 18:54:09+00:00
URL: https://github.com/langchain-ai/langchain/pull/25454
Description:
None
----------------------------------------

PR #25402: groq[patch]: Update root validators for pydantic 2 migration
Author: eyurtsev
Merged at: 2024-08-15 18:46:53+00:00
URL: https://github.com/langchain-ai/langchain/pull/25402
Description:
None
----------------------------------------

PR #25450: docs: `arxiv` page update
Author: leo-gan
Merged at: 2024-08-15 18:30:36+00:00
URL: https://github.com/langchain-ai/langchain/pull/25450
Description:
Added `arxive` papers that use `LangGraph` or `LangSmith`. Improved the page formatting.
----------------------------------------

PR #24682: [experimental]: minor fix to open assistants code
Author: isahers1
Merged at: 2024-08-15 17:50:57+00:00
URL: https://github.com/langchain-ai/langchain/pull/24682
Description:
None
----------------------------------------

PR #25448: docs: format oai embeddings docstring
Author: baskaryan
Merged at: 2024-08-15 16:57:55+00:00
URL: https://github.com/langchain-ai/langchain/pull/25448
Description:
None
----------------------------------------

PR #25443: fireworks[patch]: Upgrade @root_validators to be pydantic 2 compliant 
Author: eyurtsev
Merged at: 2024-08-15 16:56:48+00:00
URL: https://github.com/langchain-ai/langchain/pull/25443
Description:
Update @root_validators to be pydantic 2 compliant

----------------------------------------

PR #25360: Merge support for group manager
Author: hinthornw
Merged at: 2024-08-15 16:56:31+00:00
URL: https://github.com/langchain-ai/langchain/pull/25360
Description:
None
----------------------------------------

PR #25444: docs[patch]: Update code that checks API keys
Author: eyurtsev
Merged at: 2024-08-15 16:52:37+00:00
URL: https://github.com/langchain-ai/langchain/pull/25444
Description:
Check whether the API key is already in the environment

Update:

```python
import getpass
import os

os.environ["DATABRICKS_HOST"] = "https://your-workspace.cloud.databricks.com"
os.environ["DATABRICKS_TOKEN"] = getpass.getpass("Enter your Databricks access token: ")
```

To:

```python
import getpass
import os

os.environ["DATABRICKS_HOST"] = "https://your-workspace.cloud.databricks.com"
if "DATABRICKS_TOKEN" not in os.environ:
    os.environ["DATABRICKS_TOKEN"] = getpass.getpass(
        "Enter your Databricks access token: "
    )
```

grit migration:

```
engine marzano(0.1)
language python

`os.environ[$Q] = getpass.getpass("$X")` as $CHECK where {
    $CHECK <: ! within if_statement(),
    $CHECK => `if $Q not in os.environ:\n    $CHECK`
}
```
----------------------------------------

PR #25447: docs: fix api ref mod links in pkg page
Author: baskaryan
Merged at: 2024-08-15 16:52:12+00:00
URL: https://github.com/langchain-ai/langchain/pull/25447
Description:
None
----------------------------------------

PR #25446: mistralai[patch]: Update more @root_validators for pydantic 2 compatibility
Author: eyurtsev
Merged at: 2024-08-15 16:44:42+00:00
URL: https://github.com/langchain-ai/langchain/pull/25446
Description:
Update @root_validators in mistralai integration for pydantic 2 compatibility
----------------------------------------

PR #25442: docs[patch]: Fix integration notebook for Fireworks llm
Author: eyurtsev
Merged at: 2024-08-15 16:42:33+00:00
URL: https://github.com/langchain-ai/langchain/pull/25442
Description:
Fix example that uses model_kwargs that need to be passed as top level arguments
----------------------------------------

PR #25217: docs: `integrations` references update 7
Author: leo-gan
Merged at: 2024-08-14 13:58:38+00:00
URL: https://github.com/langchain-ai/langchain/pull/25217
Description:
Added missed provider pages. Fixed formats and added descriptions and links.
----------------------------------------

PR #25322: docs: `integrations`references update 8
Author: leo-gan
Merged at: 2024-08-13 13:29:51+00:00
URL: https://github.com/langchain-ai/langchain/pull/25322
Description:
Added missed provider pages. Fixed formats and added descriptions and links.
----------------------------------------

PR #25423: together[patch]: Update @root_validator for pydantic 2 compatibility
Author: eyurtsev
Merged at: 2024-08-15 15:27:42+00:00
URL: https://github.com/langchain-ai/langchain/pull/25423
Description:
This PR updates usage of @root_validator to be compatible with pydantic 2.

----------------------------------------

PR #25401: ai21[patch]: Update @root_validators for pydantic2 migration
Author: eyurtsev
Merged at: 2024-08-15 15:26:45+00:00
URL: https://github.com/langchain-ai/langchain/pull/25401
Description:
Update @root_validators for pydantic 2 migration.

----------------------------------------

PR #25403: mistralai[patch]: Update root validator for compatibility with pydantic 2
Author: eyurtsev
Merged at: 2024-08-15 15:26:25+00:00
URL: https://github.com/langchain-ai/langchain/pull/25403
Description:
None
----------------------------------------

PR #25310: langchain[patch]: deprecate various chains
Author: ccurme
Merged at: 2024-08-15 14:49:26+00:00
URL: https://github.com/langchain-ai/langchain/pull/25310
Description:
- [x] NatbotChain: move to community, deprecate langchain version. Update to use `prompt | llm | output_parser` instead of LLMChain.
- [x] LLMMathChain: deprecate + add langgraph replacement example to API ref
- [x] HypotheticalDocumentEmbedder (retriever): update to use `prompt | llm | output_parser` instead of LLMChain
- [x] FlareChain: update to use `prompt | llm | output_parser` instead of LLMChain
- [x] ConstitutionalChain: deprecate + add langgraph replacement example to API ref
- [x] LLMChainExtractor (document compressor): update to use `prompt | llm | output_parser` instead of LLMChain
- [x] LLMChainFilter (document compressor): update to use `prompt | llm | output_parser` instead of LLMChain
- [x] RePhraseQueryRetriever (retriever): update to use `prompt | llm | output_parser` instead of LLMChain
----------------------------------------

PR #25439: experimental: Fix divide by 0 error
Author: munday-tech
Merged at: 2024-08-15 14:46:30+00:00
URL: https://github.com/langchain-ai/langchain/pull/25439
Description:
Within the semantic chunker, when calling `_threshold_from_clusters` there is the possibility for a divide by 0 error if the `number_of_chunks` is equal to the length of `distances`.

Fix simply implements a check if these values match to prevent the error and enable chunking to continue. 

----------------------------------------

PR #25438: community[patch]: update connection string in azure cosmos integration test
Author: ccurme
Merged at: 2024-08-15 14:07:54+00:00
URL: https://github.com/langchain-ai/langchain/pull/25438
Description:
https://github.com/langchain-ai/langchain/issues/25415
----------------------------------------

PR #25424: docs[patch]: Fix a few typos in the chat integration docs for TogetherAI
Author: eyurtsev
Merged at: 2024-08-15 13:48:37+00:00
URL: https://github.com/langchain-ai/langchain/pull/25424
Description:
Fix a few minor typos

----------------------------------------

PR #25425: [docs]: pdf loaders
Author: isahers1
Merged at: 2024-08-15 04:44:57+00:00
URL: https://github.com/langchain-ai/langchain/pull/25425
Description:
None
----------------------------------------

PR #25417: [docs]: doc loader changes
Author: isahers1
Merged at: 2024-08-15 02:46:33+00:00
URL: https://github.com/langchain-ai/langchain/pull/25417
Description:
None
----------------------------------------

PR #25421: langchain: bump core to 0.2.32
Author: ccurme
Merged at: 2024-08-15 00:00:43+00:00
URL: https://github.com/langchain-ai/langchain/pull/25421
Description:
None
----------------------------------------

PR #25420: core[patch]: Release 0.2.32
Author: baskaryan
Merged at: 2024-08-14 22:56:56+00:00
URL: https://github.com/langchain-ai/langchain/pull/25420
Description:
None
----------------------------------------

PR #25419: core[patch]: tool import fix
Author: baskaryan
Merged at: 2024-08-14 22:54:13+00:00
URL: https://github.com/langchain-ai/langchain/pull/25419
Description:
None
----------------------------------------

PR #25418: langchain: bump min core version
Author: ccurme
Merged at: 2024-08-14 22:51:35+00:00
URL: https://github.com/langchain-ai/langchain/pull/25418
Description:
None
----------------------------------------

PR #25416: langchain: release 0.2.14
Author: ccurme
Merged at: 2024-08-14 22:29:39+00:00
URL: https://github.com/langchain-ai/langchain/pull/25416
Description:
Fixes https://github.com/langchain-ai/langchain/issues/25413
----------------------------------------

PR #25363: [docs]: sitemaploader update
Author: isahers1
Merged at: 2024-08-14 22:27:40+00:00
URL: https://github.com/langchain-ai/langchain/pull/25363
Description:
None
----------------------------------------

PR #25172: Bagatur/api styling
Author: baskaryan
Merged at: 2024-08-14 14:00:17+00:00
URL: https://github.com/langchain-ai/langchain/pull/25172
Description:
None
----------------------------------------

PR #25263: docs: update "Build an Agent" Installation Hint in agents.ipynb
Author: gbaian10
Merged at: 2024-08-11 20:51:35+00:00
URL: https://github.com/langchain-ai/langchain/pull/25263
Description:
fix #25257
----------------------------------------

PR #25411: [docs]: link fix directory loader
Author: isahers1
Merged at: 2024-08-14 20:58:54+00:00
URL: https://github.com/langchain-ai/langchain/pull/25411
Description:
None
----------------------------------------

PR #25409: docs: fix deprecated functions table
Author: baskaryan
Merged at: 2024-08-14 19:25:40+00:00
URL: https://github.com/langchain-ai/langchain/pull/25409
Description:
None
----------------------------------------

PR #25404: docs: fix tool index
Author: efriis
Merged at: 2024-08-14 18:36:42+00:00
URL: https://github.com/langchain-ai/langchain/pull/25404
Description:
None
----------------------------------------

PR #25397: fix: typo where github should be gitlab
Author: wvdm1217
Merged at: 2024-08-14 18:36:25+00:00
URL: https://github.com/langchain-ai/langchain/pull/25397
Description:
**PR title**: "GitLabToolkit: fix typo"
    - **Description:** fix typo where GitHub should have been GitLab
    - **Dependencies:** None

----------------------------------------

PR #25183: core: fix issue#24660, slove error messages about `ValueError` when use model with history
Author: CheneyYin
Merged at: 2024-08-14 14:26:22+00:00
URL: https://github.com/langchain-ai/langchain/pull/25183
Description:
- **Description:**
This PR will slove error messages about `ValueError` when use model with history. 
Detail in #24660.
#22933 causes that `langchain_core.runnables.history.RunnableWithMessageHistory._get_output_messages`  miss type check of `output_val` if `output_val` is `False`. After running `RunnableWithMessageHistory._is_not_async`, `output` is `False`.
https://github.com/langchain-ai/langchain/blob/249945a572a58a307cab1ae79e199e85b2707ff0/libs/core/langchain_core/runnables/history.py#L323-L334
https://github.com/langchain-ai/langchain/blob/15a36dd0a2bce0ec07090350c39de2fbaf3f05bc/libs/core/langchain_core/runnables/history.py#L461-L471
~~I suggest that `_get_output_messages` return empty list when `output_val == False`.~~

- **Issue**:
  - #24660

- **Dependencies:**: No Change.



----------------------------------------

PR #25388: core[patch]: Release 0.2.31
Author: baskaryan
Merged at: 2024-08-14 18:26:49+00:00
URL: https://github.com/langchain-ai/langchain/pull/25388
Description:
None
----------------------------------------

PR #25400: docs: fix api ref package tables
Author: baskaryan
Merged at: 2024-08-14 17:40:16+00:00
URL: https://github.com/langchain-ai/langchain/pull/25400
Description:
None
----------------------------------------

PR #25398: experimental[patch]: refactor rl chain structure
Author: baskaryan
Merged at: 2024-08-14 17:09:44+00:00
URL: https://github.com/langchain-ai/langchain/pull/25398
Description:
can't have a class and function with same name but different capitalization in same file for api reference building
----------------------------------------

PR #25393: Update document_loader_custom.ipynb
Author: ffknob
Merged at: 2024-08-14 16:33:21+00:00
URL: https://github.com/langchain-ai/langchain/pull/25393
Description:
Fix typo

Thank you for contributing to LangChain!

- [ ] **PR title**: "package: description"
  - Where "package" is whichever of langchain, community, core, experimental, etc. is being modified. Use "docs: ..." for purely docs changes, "templates: ..." for template changes, "infra: ..." for CI changes.
  - Example: "community: add foobar LLM"


- [ ] **PR message**: ***Delete this entire checklist*** and replace with
    - **Description:** a description of the change
    - **Issue:** the issue # it fixes, if applicable
    - **Dependencies:** any dependencies required for this change
    - **Twitter handle:** if your PR gets announced, and you'd like a mention, we'll gladly shout you out!


- [ ] **Add tests and docs**: If you're adding a new integration, please include
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use. It lives in `docs/docs/integrations` directory.


- [ ] **Lint and test**: Run `make format`, `make lint` and `make test` from the root of the package(s) you've modified. See contribution guidelines for more: https://python.langchain.com/docs/contributing/

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in langchain.

If no one reviews your PR within a few days, please @-mention one of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.

----------------------------------------

PR #25389: docs[patch]: Hide deprecated integration pages
Author: jacoblee93
Merged at: 2024-08-14 16:17:39+00:00
URL: https://github.com/langchain-ai/langchain/pull/25389
Description:
None
----------------------------------------

PR #25395: standard-tests: import fix
Author: baskaryan
Merged at: 2024-08-14 16:13:56+00:00
URL: https://github.com/langchain-ai/langchain/pull/25395
Description:
None
----------------------------------------

PR #25394: anthropic[patch]: Release 0.1.23
Author: baskaryan
Merged at: 2024-08-14 16:03:39+00:00
URL: https://github.com/langchain-ai/langchain/pull/25394
Description:
None
----------------------------------------

PR #25391: Update document_loader_custom.ipynb
Author: ffknob
Merged at: 2024-08-14 15:07:42+00:00
URL: https://github.com/langchain-ai/langchain/pull/25391
Description:
Fix typo and some `callout` tags

Thank you for contributing to LangChain!

- [ ] **PR title**: "package: description"
  - Where "package" is whichever of langchain, community, core, experimental, etc. is being modified. Use "docs: ..." for purely docs changes, "templates: ..." for template changes, "infra: ..." for CI changes.
  - Example: "community: add foobar LLM"


- [ ] **PR message**: ***Delete this entire checklist*** and replace with
    - **Description:** a description of the change
    - **Issue:** the issue # it fixes, if applicable
    - **Dependencies:** any dependencies required for this change
    - **Twitter handle:** if your PR gets announced, and you'd like a mention, we'll gladly shout you out!


- [ ] **Add tests and docs**: If you're adding a new integration, please include
  1. a test for the integration, preferably unit tests that do not rely on network access,
  2. an example notebook showing its use. It lives in `docs/docs/integrations` directory.


- [ ] **Lint and test**: Run `make format`, `make lint` and `make test` from the root of the package(s) you've modified. See contribution guidelines for more: https://python.langchain.com/docs/contributing/

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in langchain.

If no one reviews your PR within a few days, please @-mention one of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.

----------------------------------------

PR #25383: ollama[patch]: Update extra in ollama package
Author: eyurtsev
Merged at: 2024-08-14 14:30:01+00:00
URL: https://github.com/langchain-ai/langchain/pull/25383
Description:
Backwards compatible change that converts pydantic extras to literals which is consistent with pydantic 2 usage.
----------------------------------------

PR #25387: docs[patch]: Add conceptual guide links to integration index pages
Author: jacoblee93
Merged at: 2024-08-14 14:14:25+00:00
URL: https://github.com/langchain-ai/langchain/pull/25387
Description:
None
----------------------------------------

PR #25384: huggingface[patch], pinecone[patch], fireworks[patch], mistralai[patch], voyageai[patch], togetherai[path]: convert Pydantic extras to literals
Author: eyurtsev
Merged at: 2024-08-14 13:55:31+00:00
URL: https://github.com/langchain-ai/langchain/pull/25384
Description:
Backwards compatible change that converts pydantic extras to literals which is consistent with pydantic 2 usage.

- fireworks
- voyage ai
- mistralai
- mistral ai
- together ai
- huggigng face
- pinecone
----------------------------------------

PR #25382: openai[patch]: Update extra to match pydantic 2
Author: eyurtsev
Merged at: 2024-08-14 13:55:18+00:00
URL: https://github.com/langchain-ai/langchain/pull/25382
Description:
Backwards compatible change that converts pydantic extras to literals which is consistent with pydantic 2 usage.
----------------------------------------

PR #25386: core[minor]: Prevent PydanticOutputParser from encoding schema as ASCII
Author: eyurtsev
Merged at: 2024-08-14 13:54:31+00:00
URL: https://github.com/langchain-ai/langchain/pull/25386
Description:
This allows users to provide parameter descriptions in the pydantic models in other languages.

Continuing this PR: https://github.com/langchain-ai/langchain/pull/24809
----------------------------------------

PR #25361: multiple: update removal targets
Author: ccurme
Merged at: 2024-08-14 13:50:39+00:00
URL: https://github.com/langchain-ai/langchain/pull/25361
Description:
None
----------------------------------------

PR #25373: docs: update clarifai.ipynb
Author: eltociear
Merged at: 2024-08-14 13:20:17+00:00
URL: https://github.com/langchain-ai/langchain/pull/25373
Description:
Intialize -> Initialize


----------------------------------------

PR #25370: docs: tools index table
Author: efriis
Merged at: 2024-08-14 02:38:03+00:00
URL: https://github.com/langchain-ai/langchain/pull/25370
Description:
None
----------------------------------------

PR #25365: docs: improve document loaders index
Author: hwchase17
Merged at: 2024-08-14 01:48:49+00:00
URL: https://github.com/langchain-ai/langchain/pull/25365
Description:
None
----------------------------------------

PR #25369: docs: remove sidebar comment
Author: efriis
Merged at: 2024-08-14 01:47:13+00:00
URL: https://github.com/langchain-ai/langchain/pull/25369
Description:
None
----------------------------------------

PR #25367: docs[patch]: Fix typo in CohereEmbeddings integration docs
Author: eyurtsev
Merged at: 2024-08-14 01:18:55+00:00
URL: https://github.com/langchain-ai/langchain/pull/25367
Description:
Fix typo

----------------------------------------

PR #25250: docs: Partial integration update for cohere embeddings
Author: eyurtsev
Merged at: 2024-08-14 00:53:14+00:00
URL: https://github.com/langchain-ai/langchain/pull/25250
Description:
This can be finished after the following issue is resolved:

https://github.com/langchain-ai/langchain-cohere/issues/81

Related to: https://github.com/langchain-ai/langchain/issues/24856

```json
[
   {
      "provider": "cohere",
      "js":  true,
      "local": false,
     "serializable": false,
   }
]
```


----------------------------------------

PR #25311: docs[patch]: Update integration docs for AzureOpenAIEmbeddings
Author: eyurtsev
Merged at: 2024-08-14 00:33:14+00:00
URL: https://github.com/langchain-ai/langchain/pull/25311
Description:
https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25308: docs: Update nomic AI embeddings integration docs
Author: eyurtsev
Merged at: 2024-08-14 00:32:08+00:00
URL: https://github.com/langchain-ai/langchain/pull/25308
Description:
Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25298: docs: Update AI21Embeddings Integration docs
Author: eyurtsev
Merged at: 2024-08-14 00:30:16+00:00
URL: https://github.com/langchain-ai/langchain/pull/25298
Description:
Update AI21 Integration docs

Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25253: docs: update integration docs for mistral ai embedding model
Author: eyurtsev
Merged at: 2024-08-14 00:25:36+00:00
URL: https://github.com/langchain-ai/langchain/pull/25253
Description:
Related issue: https://github.com/langchain-ai/langchain/issues/24856

```json
[
   {
      "provider": "mistralai",
      "js":  true,
      "local": false,
     "serializable": false,
    "native_async": true
   }
]
```
----------------------------------------

PR #25252: docs: together ai embeddings integration docs
Author: eyurtsev
Merged at: 2024-08-14 00:24:02+00:00
URL: https://github.com/langchain-ai/langchain/pull/25252
Description:
Update together AI embedding integration docs

Related issue: https://github.com/langchain-ai/langchain/issues/24856

```json
[
   {
      "provider": "together",
      "js":  true,
      "local": false,
     "serializable": false,
   }
]
```
----------------------------------------

PR #25314: docs: Update integration docs for OllamaEmbeddingsModel
Author: eyurtsev
Merged at: 2024-08-14 00:23:06+00:00
URL: https://github.com/langchain-ai/langchain/pull/25314
Description:
Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25249: docs: update integration docs for openai embeddings
Author: eyurtsev
Merged at: 2024-08-14 00:21:36+00:00
URL: https://github.com/langchain-ai/langchain/pull/25249
Description:
Related issue: https://github.com/langchain-ai/langchain/issues/24856

```json
   {
      "provider": "openai",
      "js":  true,
      "local": false,
     "serializable": false,
"async_native": true
  }
```
----------------------------------------

PR #25247: docs: Updating integration docs for Fireworks Embeddings
Author: eyurtsev
Merged at: 2024-08-14 00:04:19+00:00
URL: https://github.com/langchain-ai/langchain/pull/25247
Description:
Providers:
* fireworks

See related issue:
* https://github.com/langchain-ai/langchain/issues/24856

Features:

```json
[
   {
      "provider": "fireworks",
      "js":  true,
      "local": false,
     "serializable": false,
   }



]


```
----------------------------------------

PR #25325: [docs]: standardize doc loader doc strings
Author: isahers1
Merged at: 2024-08-13 23:18:57+00:00
URL: https://github.com/langchain-ai/langchain/pull/25325
Description:
None
----------------------------------------

PR #25351: [docs]: standardize tool docstrings
Author: isahers1
Merged at: 2024-08-13 23:10:00+00:00
URL: https://github.com/langchain-ai/langchain/pull/25351
Description:
None
----------------------------------------

PR #25316: docs: index pages, sidebars
Author: efriis
Merged at: 2024-08-13 22:52:52+00:00
URL: https://github.com/langchain-ai/langchain/pull/25316
Description:
None
----------------------------------------

PR #25005: [docs]: LLM integration pages
Author: isahers1
Merged at: 2024-08-13 21:50:45+00:00
URL: https://github.com/langchain-ai/langchain/pull/25005
Description:
None
----------------------------------------

PR #25345: Add README for astradb package
Author: cbornet
Merged at: 2024-08-13 13:17:24+00:00
URL: https://github.com/langchain-ai/langchain/pull/25345
Description:
Similar to https://github.com/langchain-ai/langchain/blob/master/libs/partners/ibm/README.md

----------------------------------------

PR #25197: [docs]: merge tool/toolkit duplicates
Author: isahers1
Merged at: 2024-08-13 19:19:17+00:00
URL: https://github.com/langchain-ai/langchain/pull/25197
Description:
None
----------------------------------------

PR #25349: docs: Fix broken link to Runhouse documentation
Author: mkandler
Merged at: 2024-08-13 18:18:19+00:00
URL: https://github.com/langchain-ai/langchain/pull/25349
Description:
- **Description:** Runhouse recently migrated from Read the Docs to a self-hosted solution. This PR updates a broken link from the old docs to www.run.house/docs. Also changed "The Runhouse" to "Runhouse" (it's cleaner).
- **Issue:** None
- **Dependencies:** None
----------------------------------------

PR #25245: qdrant: Update API reference link and install command
Author: Anush008
Merged at: 2024-08-11 20:54:15+00:00
URL: https://github.com/langchain-ai/langchain/pull/25245
Description:
## Description

As the title goes. The current API reference links to the deprecated class.
----------------------------------------

PR #25239: Standardize SparkLLM
Author: maang-h
Merged at: 2024-08-13 13:50:12+00:00
URL: https://github.com/langchain-ai/langchain/pull/25239
Description:
- **Description:** Standardize SparkLLM, include:
  - docs, the issue #24803 
  - to support stream
  - update api url
  - model init arg names, the issue #20085 



----------------------------------------

PR #25332: qianfan generate/agenerate with usage_metadata
Author: bimslab
Merged at: 2024-08-13 13:24:41+00:00
URL: https://github.com/langchain-ai/langchain/pull/25332
Description:
None
----------------------------------------

PR #25315: ollama[patch]: Update API Reference for ollama embeddings
Author: eyurtsev
Merged at: 2024-08-13 01:31:49+00:00
URL: https://github.com/langchain-ai/langchain/pull/25315
Description:
Update API reference for OllamaEmbeddings
Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25324: community: release 0.2.12
Author: efriis
Merged at: 2024-08-12 23:30:28+00:00
URL: https://github.com/langchain-ai/langchain/pull/25324
Description:
None
----------------------------------------

PR #25323: langchain: release 0.2.13
Author: efriis
Merged at: 2024-08-12 22:24:06+00:00
URL: https://github.com/langchain-ai/langchain/pull/25323
Description:
None
----------------------------------------

PR #25321: core: release 0.2.30
Author: efriis
Merged at: 2024-08-12 22:01:24+00:00
URL: https://github.com/langchain-ai/langchain/pull/25321
Description:
None
----------------------------------------

PR #25312: openai: Update API Reference docs for AzureOpenAI Embeddings
Author: eyurtsev
Merged at: 2024-08-12 19:41:19+00:00
URL: https://github.com/langchain-ai/langchain/pull/25312
Description:
Update AzureOpenAI Embeddings docs


----------------------------------------

PR #25313: core[patch]: Update API reference for fake embeddings
Author: eyurtsev
Merged at: 2024-08-12 19:40:05+00:00
URL: https://github.com/langchain-ai/langchain/pull/25313
Description:
Issue: https://github.com/langchain-ai/langchain/issues/24856

Using the same template for the fake embeddings in langchain_core as used in the integrations.
----------------------------------------

PR #25300: community: kwargs for CassandraGraphVectorStore
Author: bjchambers
Merged at: 2024-08-12 18:01:29+00:00
URL: https://github.com/langchain-ai/langchain/pull/25300
Description:
- **Description:** pass kwargs from CassandraGraphVectorStore to underlying store
----------------------------------------

PR #25306: docs: Change SqliteSaver to MemorySaver
Author: gbaian10
Merged at: 2024-08-12 17:45:32+00:00
URL: https://github.com/langchain-ai/langchain/pull/25306
Description:
fix: #25137

`SqliteSaver.from_conn_string()` has been changed to a `contextmanager` method in `langgraph >= 0.2.0`, the original usage is no longer applicable.

Refer to <https://github.com/langchain-ai/langgraph/pull/1271#issue-2454736415> modification method to replace `SqliteSaver` with `MemorySaver`.

----------------------------------------

PR #25297: docs: remove unused imports in Conversational RAG tutorial
Author: Hassan-Memon
Merged at: 2024-08-12 17:49:55+00:00
URL: https://github.com/langchain-ai/langchain/pull/25297
Description:
Cleaned up the "Tying it Together" section of the Conversational RAG tutorial by removing unnecessary imports that were not used. This reduces confusion and makes the code more concise.

Thank you for contributing to LangChain!

PR title: docs: remove unused imports in Conversational RAG tutorial

PR message:

Description: Removed unnecessary imports from the "Tying it Together" section of the Conversational RAG tutorial. These imports were not used in the code and created confusion. The updated code is now more concise and easier to understand.
Issue: N/A
Dependencies: None
LinkedIn handle: [Hassan Memon](https://www.linkedin.com/in/hassan-memon-a109b3257/)
Add tests and docs:

Hi [LangChain Team Member’s Name],

I hope you're doing well! I’m thrilled to share that I recently made my second contribution to the LangChain project. If possible, could you give me a shoutout on LinkedIn? It would mean a lot to me and could help inspire others to contribute to the community as well.

Here’s my LinkedIn profile: [Hassan Memon](https://www.linkedin.com/in/hassan-memon-a109b3257/).

Thank you so much for your support and for creating such a great platform for learning and collaboration. I'm looking forward to contributing more in the future!

Best regards,
Hassan Memon
----------------------------------------

PR #25304: fireworks[patch]: Fix doc-string for API Referenmce
Author: eyurtsev
Merged at: 2024-08-12 17:16:13+00:00
URL: https://github.com/langchain-ai/langchain/pull/25304
Description:
None
----------------------------------------

PR #25302: ai21[patch]: Update API reference documentation
Author: eyurtsev
Merged at: 2024-08-12 17:15:27+00:00
URL: https://github.com/langchain-ai/langchain/pull/25302
Description:
Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25292: fireworks: Add APIReference for the FireworksEmbeddings model
Author: eyurtsev
Merged at: 2024-08-12 17:13:44+00:00
URL: https://github.com/langchain-ai/langchain/pull/25292
Description:
Add API Reference documentation for the FireworksEmbedding model.

Issue: https://github.com/langchain-ai/langchain/issues/24856

----------------------------------------

PR #25295: togetherai[patch]: Update API Reference for together AI embeddings model
Author: eyurtsev
Merged at: 2024-08-12 17:12:28+00:00
URL: https://github.com/langchain-ai/langchain/pull/25295
Description:
Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25289: docs: document upstash vector namespaces
Author: yunusemreozdemir
Merged at: 2024-08-12 13:17:11+00:00
URL: https://github.com/langchain-ai/langchain/pull/25289
Description:
**Description:** This PR rearranges the examples in Upstash Vector integration documentation to describe how to use namespaces and improve the description of metadata filtering.
----------------------------------------

PR #25285: docs: Replaced SqliteSaver with MemorySaver and updated installation instru…
Author: Hassan-Memon
Merged at: 2024-08-12 13:24:51+00:00
URL: https://github.com/langchain-ai/langchain/pull/25285
Description:
…ctions to match LangGraph v2 documentation. Corrected code snippet to prevent validation errors.

Here's how you can fill out the provided template for your pull request:

---

**Thank you for contributing to LangChain!**

- [ ] **PR title**: `docs: update checkpointer example in Conversational RAG tutorial`

- [ ] **PR message**:
    - **Description:** Updated the Conversational RAG tutorial to correct the checkpointer example by replacing `SqliteSaver` with `MemorySaver`. Added installation instructions for `langgraph-checkpoint-memory` to match LangGraph v2 documentation and prevent validation errors.
    - **Issue:** N/A
    - **Dependencies:** `langgraph-checkpoint-memory`
    - **Twitter handle:** N/A

- [ ] **Add tests and docs**: 
  1. No new integration tests are required.
  2. Updated documentation in the Conversational RAG tutorial.

- [ ] **Lint and test**: Run `make format`, `make lint` and `make test` from the root of the package(s) you've modified. See contribution guidelines for more: [LangChain Contribution Guidelines](https://python.langchain.com/docs/contributing/)

Additional guidelines:
- Make sure optional dependencies are imported within a function.
- Please do not add dependencies to pyproject.toml files (even optional ones) unless they are required for unit tests.
- Most PRs should not touch more than one package.
- Changes should be backwards compatible.
- If you are adding something to community, do not re-import it in langchain.

If no one reviews your PR within a few days, please @-mention one of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.
----------------------------------------

PR #25294: mistralai[patch]: Docs Update APIReference for MistralAIEmbeddings
Author: eyurtsev
Merged at: 2024-08-12 15:25:37+00:00
URL: https://github.com/langchain-ai/langchain/pull/25294
Description:
Update API Reference for MistralAI embeddings

Issue: https://github.com/langchain-ai/langchain/issues/24856
----------------------------------------

PR #25293: openai[patch]: Docs fix RST formatting in OpenAIEmbeddings
Author: eyurtsev
Merged at: 2024-08-12 15:24:36+00:00
URL: https://github.com/langchain-ai/langchain/pull/25293
Description:
None
----------------------------------------

PR #25290: openai[patch]: Add API Reference docs to OpenAIEmbeddings
Author: eyurtsev
Merged at: 2024-08-12 14:53:51+00:00
URL: https://github.com/langchain-ai/langchain/pull/25290
Description:
Issue: [24856](https://github.com/langchain-ai/langchain/issues/24856)
----------------------------------------

PR #25240: core[patch]: add standard tracing params for retrievers
Author: ccurme
Merged at: 2024-08-12 14:52:00+00:00
URL: https://github.com/langchain-ai/langchain/pull/25240
Description:
None
----------------------------------------

PR #23887: [Community] - Added bind_tools and with_structured_output for ChatZhipuAI
Author: keenborder786
Merged at: 2024-08-12 14:11:43+00:00
URL: https://github.com/langchain-ai/langchain/pull/23887
Description:
- **Description:** This PR implements the `bind_tool` functionality for ChatZhipuAI as requested by the user. ChatZhipuAI models support tool calling according to the `OpenAI` tool format, as outlined in their official documentation [here](https://open.bigmodel.cn/dev/api#glm-4).
- **Issue:**  ##23868

----------------------------------------

PR #25287: cookbook: pip install bug fixed
Author: JasonJ2021
Merged at: 2024-08-12 05:12:45+00:00
URL: https://github.com/langchain-ai/langchain/pull/25287
Description:
Thank you for contributing to LangChain!
- **Description:** Fixing package install bug in cookbook
- **Issue:** zsh:1: no matches found: unstructured[all-docs]
- **Dependencies:** N/A
- **Twitter handle:** if your PR gets announced, and you'd like a mention, we'll gladly shout you out!



If no one reviews your PR within a few days, please @-mention one of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.

----------------------------------------

PR #25286: docs: Fix link for API reference of Gmail Toolkit
Author: soichisumi
Merged at: 2024-08-12 05:12:31+00:00
URL: https://github.com/langchain-ai/langchain/pull/25286
Description:
- **Description:** Fix link for API reference of Gmail Toolkit
- **Issue:** I've just found this issue while I'm reading the doc
- **Dependencies:** N/A
- **Twitter handle:** [@soichisumi](https://x.com/soichisumi)

TODO: If no one reviews your PR within a few days, please @-mention one of baskaryan, efriis, eyurtsev, ccurme, vbarda, hwchase17.

----------------------------------------

PR #25267: docs: update numbering of items in docstring
Author: gbaian10
Merged at: 2024-08-11 20:50:24+00:00
URL: https://github.com/langchain-ai/langchain/pull/25267
Description:
A problem similar to #25093 .
----------------------------------------

PR #25255: docs: Fixed grammer error in functions.ipynb
Author: aryankrsingh004
Merged at: 2024-08-11 20:53:27+00:00
URL: https://github.com/langchain-ai/langchain/pull/25255
Description:
**Description**: Grammer Error in functions.ipynb
**Issue**: #25222
----------------------------------------

PR #24156: langchain: default to langsmith sdk for pulling prompts, fallback to langchainhub
Author: madams0013
Merged at: 2024-08-11 20:30:52+00:00
URL: https://github.com/langchain-ai/langchain/pull/24156
Description:
**Description:** Deprecating langchainhub, replacing with langsmith sdk
----------------------------------------

PR #25265: docs: Fix ChatBaichuan, QianfanChatEndpoint, ChatSparkLLM, ChatZhipuAI docs
Author: maang-h
Merged at: 2024-08-11 20:23:55+00:00
URL: https://github.com/langchain-ai/langchain/pull/25265
Description:
- **Description:** Fix some chat models docs, include:
  - ChatBaichuan
  - QianfanChatEndpoint
  - ChatSparkLLM
  - ChatZhipuAI

----------------------------------------

PR #25274: Improvement[Embeddings] Add dimension support to `ZhipuAIEmbeddings`
Author: ZhangShenao
Merged at: 2024-08-11 20:20:37+00:00
URL: https://github.com/langchain-ai/langchain/pull/25274
Description:
- In the in ` embedding-3 ` and later models of Zhipu AI, it is supported to specify the dimensions parameter of Embedding. Ref: https://bigmodel.cn/dev/api#text_embedding-3 .
- Add test case for `embedding-3` model by assigning dimensions.
----------------------------------------

PR #25280: docs: Standardize OpenAI Docs
Author: maang-h
Merged at: 2024-08-11 20:20:16+00:00
URL: https://github.com/langchain-ai/langchain/pull/25280
Description:
- **Description:** Standardize OpenAI Docs
- **Issue:** the issue #24803 

----------------------------------------

PR #25269: openai[patch]: Release 0.1.21
Author: baskaryan
Merged at: 2024-08-10 23:37:31+00:00
URL: https://github.com/langchain-ai/langchain/pull/25269
Description:
None
----------------------------------------


FILE CHANGES
--------------------------------------------------------------------------------

File: .gitignore
Status: modified
Changes: +2 -0
Diff:
@@ -172,6 +172,8 @@ docs/api_reference/*/
 !docs/api_reference/_static/
 !docs/api_reference/templates/
 !docs/api_reference/themes/
+!docs/api_reference/_extensions/
+!docs/api_reference/scripts/
 docs/docs/build
 docs/docs/node_modules
 docs/docs/yarn.lock

----------------------------------------

File: Makefile
Status: modified
Changes: +4 -1
Diff:
@@ -31,19 +31,22 @@ docs_linkcheck:
 api_docs_build:
 	poetry run python docs/api_reference/create_api_rst.py
 	cd docs/api_reference && poetry run make html
+	poetry run python docs/api_reference/scripts/custom_formatter.py docs/api_reference/_build/html/
 
 API_PKG ?= text-splitters
 
 api_docs_quick_preview:
 	poetry run pip install "pydantic<2"

----------------------------------------

File: cookbook/Semi_Structured_RAG.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -39,7 +39,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "! pip install langchain langchain-chroma unstructured[all-docs] pydantic lxml langchainhub"
+    "! pip install langchain langchain-chroma \"unstructured[all-docs]\" pydantic lxml langchainhub"
    ]
   },
   {

----------------------------------------

File: cookbook/Semi_structured_and_multi_modal_RAG.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -59,7 +59,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "! pip install langchain langchain-chroma unstructured[all-docs] pydantic lxml"
+    "! pip install langchain langchain-chroma \"unstructured[all-docs]\" pydantic lxml"
    ]
   },
   {

----------------------------------------

File: cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -59,7 +59,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "! pip install langchain langchain-chroma unstructured[all-docs] pydantic lxml"
+    "! pip install langchain langchain-chroma \"unstructured[all-docs]\" pydantic lxml"
    ]
   },
   {

----------------------------------------

File: docs/Makefile
Status: modified
Changes: +5 -5
Diff:
@@ -41,12 +41,8 @@ generate-files:
 	cp -r $(SOURCE_DIR)/* $(INTERMEDIATE_DIR)
 	mkdir -p $(INTERMEDIATE_DIR)/templates
 
-	$(PYTHON) scripts/model_feat_table.py $(INTERMEDIATE_DIR)
-
 	$(PYTHON) scripts/tool_feat_table.py $(INTERMEDIATE_DIR)
 
-	$(PYTHON) scripts/document_loader_feat_table.py $(INTERMEDIATE_DIR)
-

----------------------------------------

File: docs/api_reference/_extensions/gallery_directive.py
Status: added
Changes: +144 -0
Diff:
@@ -0,0 +1,144 @@
+"""A directive to generate a gallery of images from structured data.
+
+Generating a gallery of images that are all the same size is a common
+pattern in documentation, and this can be cumbersome if the gallery is
+generated programmatically. This directive wraps this particular use-case
+in a helper-directive to generate it with a single YAML configuration file.
+
+It currently exists for maintainers of the pydata-sphinx-theme,
+but might be abstracted into a standalone package if it proves useful.
+"""
+
+from pathlib import Path
+from typing import Any, ClassVar, Dict, List
+
+from docutils import nodes
+from docutils.parsers.rst import directives
+from sphinx.application import Sphinx
+from sphinx.util import logging
+from sphinx.util.docutils import SphinxDirective
+from yaml import safe_load
+
+logger = logging.getLogger(__name__)
+
+
+TEMPLATE_GRID = """
+`````{{grid}} {columns}
+{options}
+
+{content}
+
+`````
+"""
+
+GRID_CARD = """
+````{{grid-item-card}} {title}
+{options}
+
+{content}
+````
+"""
+
+
+class GalleryGridDirective(SphinxDirective):
+    """A directive to show a gallery of images and links in a Bootstrap grid.
+
+    The grid can be generated from a YAML file that contains a list of items, or
+    from the content of the directive (also formatted in YAML). Use the parameter

----------------------------------------

File: docs/api_reference/_static/css/custom.css
Status: modified
Changes: +402 -17
Diff:
@@ -1,26 +1,411 @@
-pre {
-  white-space: break-spaces;
+@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;700&display=swap');
+
+/*******************************************************************************
+* master color map. Only the colors that actually differ between light and dark
+* themes are specified separately.
+*
+* To see the full list of colors see https://www.figma.com/file/rUrrHGhUBBIAAjQ82x6pz9/PyData-Design-system---proposal-for-implementation-(2)?node-id=1234%3A765&t=ifcFT1JtnrSshGfi-1
+*/
+/**
+* Function to get items from nested maps
+*/
+/* Assign base colors for the PyData theme */
+:root {
+  --pst-teal-50: #f4fbfc;
+  --pst-teal-100: #e9f6f8;
+  --pst-teal-200: #d0ecf1;
+  --pst-teal-300: #abdde6;
+  --pst-teal-400: #3fb1c5;
+  --pst-teal-500: #0a7d91;
+  --pst-teal-600: #085d6c;
+  --pst-teal-700: #064752;
+  --pst-teal-800: #042c33;
+  --pst-teal-900: #021b1f;
+  --pst-violet-50: #f4eefb;
+  --pst-violet-100: #e0c7ff;
+  --pst-violet-200: #d5b4fd;
+  --pst-violet-300: #b780ff;
+  --pst-violet-400: #9c5ffd;
+  --pst-violet-500: #8045e5;
+  --pst-violet-600: #6432bd;
+  --pst-violet-700: #4b258f;
+  --pst-violet-800: #341a61;
+  --pst-violet-900: #1e0e39;
+  --pst-gray-50: #f9f9fa;
+  --pst-gray-100: #f3f4f5;
+  --pst-gray-200: #e5e7ea;
+  --pst-gray-300: #d1d5da;
+  --pst-gray-400: #9ca4af;
+  --pst-gray-500: #677384;
+  --pst-gray-600: #48566b;
+  --pst-gray-700: #29313d;
+  --pst-gray-800: #222832;
+  --pst-gray-900: #14181e;
+  --pst-pink-50: #fcf8fd;
+  --pst-pink-100: #fcf0fa;
+  --pst-pink-200: #f8dff5;
+  --pst-pink-300: #f3c7ee;
+  --pst-pink-400: #e47fd7;
+  --pst-pink-500: #c132af;
+  --pst-pink-600: #912583;
+  --pst-pink-700: #6e1c64;
+  --pst-pink-800: #46123f;
+  --pst-pink-900: #2b0b27;
+  --pst-foundation-white: #ffffff;
+  --pst-foundation-black: #14181e;
+  --pst-green-10: #f1fdfd;
+  --pst-green-50: #E0F7F6;
+  --pst-green-100: #B3E8E6;
+  --pst-green-200: #80D6D3;
+  --pst-green-300: #4DC4C0;
+  --pst-green-400: #4FB2AD;
+  --pst-green-500: #287977;
+  --pst-green-600: #246161;
+  --pst-green-700: #204F4F;
+  --pst-green-800: #1C3C3C;
+  --pst-green-900: #0D2427;
+  --pst-lilac-50: #f4eefb;
+  --pst-lilac-100: #DAD6FE;
+  --pst-lilac-200: #BCB2FD;
+  --pst-lilac-300: #9F8BFA;
+  --pst-lilac-400: #7F5CF6;
+  --pst-lilac-500: #6F3AED;
+  --pst-lilac-600: #6028D9;
+  --pst-lilac-700: #5021B6;
+  --pst-lilac-800: #431D95;
+  --pst-lilac-900: #1e0e39;
+  --pst-header-height: 2.5rem;
+}
+
+html {
+    --pst-font-family-base: 'Inter';
+    --pst-font-family-heading: 'Inter Tight', sans-serif;
+}
+
+/*******************************************************************************
+* write the color rules for each theme (light/dark)
+*/
+/* NOTE:
+ * Mixins enable us to reuse the same definitions for the different modes
+ * https://sass-lang.com/documentation/at-rules/mixin
+ * something inserts a variable into a CSS selector or property name
+ * https://sass-lang.com/documentation/interpolation
+ */
+/* Defaults to light mode if data-theme is not set */
+html:not([data-theme]) {
+  --pst-color-primary: #287977;
+  --pst-color-primary-bg: #80D6D3;
+  --pst-color-secondary: #6F3AED;
+  --pst-color-secondary-bg: #DAD6FE;
+  --pst-color-accent: #c132af;
+  --pst-color-accent-bg: #f8dff5;
+  --pst-color-info: #276be9;
+  --pst-color-info-bg: #dce7fc;
+  --pst-color-warning: #f66a0a;
+  --pst-color-warning-bg: #f8e3d0;
+  --pst-color-success: #00843f;
+  --pst-color-success-bg: #d6ece1;
+  --pst-color-attention: var(--pst-color-warning);
+  --pst-color-attention-bg: var(--pst-color-warning-bg);
+  --pst-color-danger: #d72d47;
+  --pst-color-danger-bg: #f9e1e4;
+  --pst-color-text-base: #222832;
+  --pst-color-text-muted: #48566b;
+  --pst-color-heading-color: #ffffff;
+  --pst-color-shadow: rgba(0, 0, 0, 0.1);
+  --pst-color-border: #d1d5da;
+  --pst-color-border-muted: rgba(23, 23, 26, 0.2);
+  --pst-color-inline-code: #912583;
+  --pst-color-inline-code-links: #246161;
+  --pst-color-target: #f3cf95;
+  --pst-color-background: #ffffff;
+  --pst-color-on-background: #F4F9F8;
+  --pst-color-surface: #F4F9F8;
+  --pst-color-on-surface: #222832;
+}
+html:not([data-theme]) {
+  --pst-color-link: var(--pst-color-primary);
+  --pst-color-link-hover: var(--pst-color-secondary);
+}
+html:not([data-theme]) .only-dark,
+html:not([data-theme]) .only-dark ~ figcaption {
+  display: none !important;
+}
+
+/* NOTE: @each {...} is like a for-loop
+ * https://sass-lang.com/documentation/at-rules/control/each
+ */
+html[data-theme=light] {
+  --pst-color-primary: #287977;
+  --pst-color-primary-bg: #80D6D3;

----------------------------------------

File: docs/api_reference/_static/img/brand/favicon.png
Status: added
Changes: +0 -0

----------------------------------------

File: docs/api_reference/_static/wordmark-api-dark.svg
Status: added
Changes: +11 -0
Diff:
@@ -0,0 +1,11 @@
+<svg width="72" height="19" viewBox="0 0 72 19" fill="none" xmlns="http://www.w3.org/2000/svg">
+<g clip-path="url(#clip0_4019_2020)">
+<path d="M29.4038 5.84477C30.1256 6.56657 30.1256 7.74117 29.4038 8.46296L27.7869 10.0538L27.7704 9.96259C27.6524 9.30879 27.3415 8.71552 26.8723 8.24627C26.5189 7.8936 26.1012 7.63282 25.6305 7.47143C25.3383 7.76508 25.1777 8.14989 25.1777 8.55487C25.1777 8.63706 25.1851 8.72224 25.2001 8.80742C25.4593 8.90082 25.6887 9.04503 25.8815 9.23781C26.6033 9.9596 26.6033 11.1342 25.8815 11.856L24.4738 13.2637C24.1129 13.6246 23.6392 13.8047 23.1647 13.8047C22.6902 13.8047 22.2165 13.6246 21.8556 13.2637C21.1338 12.5419 21.1338 11.3673 21.8556 10.6455L23.4725 9.05549L23.489 9.14665C23.6063 9.79896 23.9171 10.3922 24.3879 10.8622C24.742 11.2164 25.1343 11.4518 25.6043 11.6124L25.691 11.5257C25.954 11.2627 26.0982 10.913 26.0982 10.5402C26.0982 10.4572 26.0907 10.3743 26.0765 10.2929C25.8053 10.2032 25.5819 10.0754 25.3786 9.87218C25.0857 9.57928 24.9034 9.20493 24.8526 8.79024C24.8489 8.76035 24.8466 8.73121 24.8437 8.70132C24.8033 8.16109 24.9983 7.63357 25.3786 7.25399L26.7864 5.84627C27.1353 5.49733 27.6001 5.30455 28.0955 5.30455C28.5909 5.30455 29.0556 5.49658 29.4046 5.84627L29.4038 5.84477ZM36.7548 9.56583C36.7548 14.7163 32.5645 18.9058 27.4148 18.9058H9.34C4.1903 18.9058 0 14.7163 0 9.56583C0 4.41538 4.1903 0.22583 9.34 0.22583H27.4148C32.5652 0.22583 36.7548 4.41613 36.7548 9.56583ZM18 14.25C18.1472 14.0714 17.4673 13.5686 17.3283 13.384C17.0459 13.0777 17.0444 12.6368 16.8538 12.2789C16.3876 11.1985 15.8518 10.1262 15.1024 9.21166C14.3104 8.21116 13.333 7.38326 12.4745 6.44403C11.8371 5.78873 11.6668 4.85548 11.1041 4.15087C10.3285 3.00541 7.87624 2.69308 7.51683 4.31077C7.51833 4.36158 7.50264 4.39371 7.45855 4.42584C7.2598 4.57005 7.08271 4.73518 6.93402 4.93468C6.57013 5.44129 6.51409 6.30057 6.96839 6.75561C6.98333 6.51576 6.99155 6.28936 7.18134 6.1175C7.53252 6.41862 8.06304 6.52547 8.47026 6.30057C9.36989 7.585 9.14573 9.36184 9.86005 10.7457C10.0573 11.0729 10.2561 11.4069 10.5094 11.6939C10.7148 12.0137 11.4247 12.391 11.4665 12.6869C11.474 13.195 11.4142 13.7502 11.7475 14.1753C11.9044 14.4936 11.5188 14.8134 11.208 14.7738C10.8045 14.8291 10.3121 14.5026 9.95868 14.7036C9.8339 14.8388 9.58957 14.6894 9.48197 14.8769C9.44461 14.9741 9.24286 15.1108 9.36316 15.2042C9.49691 15.1026 9.62095 14.9965 9.80102 15.057C9.77412 15.2035 9.88994 15.2244 9.98184 15.267C9.97886 15.3663 9.92057 15.468 9.99679 15.5524C10.0857 15.4627 10.1388 15.3357 10.28 15.2983C10.7492 15.9238 11.2267 14.6655 12.2421 15.2318C12.0359 15.2214 11.8528 15.2475 11.7139 15.4172C11.6795 15.4553 11.6503 15.5001 11.7109 15.5494C12.2586 15.196 12.2556 15.6705 12.6112 15.5248C12.8847 15.382 13.1567 15.2035 13.4817 15.2543C13.1657 15.3454 13.153 15.5995 12.9677 15.8139C12.9363 15.8468 12.9213 15.8842 12.9579 15.9387C13.614 15.8834 13.6678 15.6652 14.1975 15.3977C14.5928 15.1564 14.9866 15.7414 15.3288 15.4082C15.4043 15.3357 15.5074 15.3604 15.6008 15.3507C15.4812 14.7133 14.1669 15.4672 14.1878 14.6124C14.6107 14.3247 14.5136 13.7741 14.542 13.3295C15.0284 13.5992 15.5694 13.7561 16.0461 14.0139C16.2867 14.4025 16.6641 14.9158 17.1669 14.8822C17.1804 14.8433 17.1923 14.8089 17.2065 14.7693C17.359 14.7955 17.5547 14.8964 17.6384 14.7036C17.8663 14.9419 18.201 14.93 18.4992 14.8687C18.7196 14.6894 18.0845 14.4338 17.9993 14.2493L18 14.25ZM31.3458 7.15387C31.3458 6.28413 31.0081 5.46744 30.3946 4.85399C29.7812 4.24054 28.9645 3.9028 28.094 3.9028C27.2235 3.9028 26.4068 4.24054 25.7933 4.85399L24.3856 6.26171C24.0569 6.59048 23.8073 6.97678 23.6436 7.40941L23.6339 7.43407L23.6085 7.44154C23.0974 7.5992 22.6469 7.86969 22.2696 8.24702L20.8618 9.65475C19.5938 10.9235 19.5938 12.9873 20.8618 14.2553C21.4753 14.8687 22.292 15.2064 23.1617 15.2064C24.0314 15.2064 24.8489 14.8687 25.4623 14.2553L26.8701 12.8475C27.1973 12.5203 27.4454 12.1355 27.609 11.7036L27.6188 11.6789L27.6442 11.6707C28.1463 11.5168 28.6095 11.2373 28.9854 10.8622L30.3931 9.4545C31.0066 8.84105 31.3443 8.02436 31.3443 7.15387H31.3458ZM12.8802 13.1972C12.7592 13.6695 12.7196 14.4742 12.1054 14.4974C12.0546 14.7701 12.2944 14.8724 12.5119 14.785C12.7278 14.6856 12.8302 14.8635 12.9026 15.0406C13.2359 15.0891 13.7291 14.9292 13.7477 14.5347C13.2501 14.2478 13.0962 13.7023 12.8795 13.1972H12.8802Z" fill="#F4F3FF"/>
+<path d="M43.5142 15.2258L47.1462 3.70583H49.9702L53.6022 15.2258H51.6182L48.3222 4.88983H48.7542L45.4982 15.2258H43.5142ZM45.5382 12.7298V10.9298H51.5862V12.7298H45.5382ZM55.0486 15.2258V3.70583H59.8086C59.9206 3.70583 60.0646 3.71116 60.2406 3.72183C60.4166 3.72716 60.5792 3.74316 60.7286 3.76983C61.3952 3.87116 61.9446 4.0925 62.3766 4.43383C62.8139 4.77516 63.1366 5.20716 63.3446 5.72983C63.5579 6.24716 63.6646 6.82316 63.6646 7.45783C63.6646 8.08716 63.5579 8.66316 63.3446 9.18583C63.1312 9.70316 62.8059 10.1325 62.3686 10.4738C61.9366 10.8152 61.3899 11.0365 60.7286 11.1378C60.5792 11.1592 60.4139 11.1752 60.2326 11.1858C60.0566 11.1965 59.9152 11.2018 59.8086 11.2018H56.9766V15.2258H55.0486ZM56.9766 9.40183H59.7286C59.8352 9.40183 59.9552 9.3965 60.0886 9.38583C60.2219 9.37516 60.3446 9.35383 60.4566 9.32183C60.7766 9.24183 61.0272 9.1005 61.2086 8.89783C61.3952 8.69516 61.5259 8.46583 61.6006 8.20983C61.6806 7.95383 61.7206 7.70316 61.7206 7.45783C61.7206 7.2125 61.6806 6.96183 61.6006 6.70583C61.5259 6.4445 61.3952 6.2125 61.2086 6.00983C61.0272 5.80716 60.7766 5.66583 60.4566 5.58583C60.3446 5.55383 60.2219 5.53516 60.0886 5.52983C59.9552 5.51916 59.8352 5.51383 59.7286 5.51383H56.9766V9.40183ZM65.4273 15.2258V3.70583H67.3553V15.2258H65.4273Z" fill="#F4F3FF"/>
+</g>
+<defs>
+<clipPath id="clip0_4019_2020">
+<rect width="71.0711" height="18.68" fill="white" transform="translate(0 0.22583)"/>
+</clipPath>

----------------------------------------

File: docs/api_reference/_static/wordmark-api.svg
Status: added
Changes: +11 -0
Diff:
@@ -0,0 +1,11 @@
+<svg width="72" height="20" viewBox="0 0 72 20" fill="none" xmlns="http://www.w3.org/2000/svg">
+<g clip-path="url(#clip0_4019_689)">
+<path d="M29.4038 5.97905C30.1256 6.70085 30.1256 7.87545 29.4038 8.59724L27.7869 10.188L27.7704 10.0969C27.6524 9.44307 27.3415 8.84979 26.8723 8.38055C26.5189 8.02787 26.1012 7.7671 25.6305 7.60571C25.3383 7.89936 25.1777 8.28416 25.1777 8.68915C25.1777 8.77134 25.1851 8.85652 25.2001 8.9417C25.4593 9.0351 25.6887 9.17931 25.8815 9.37209C26.6033 10.0939 26.6033 11.2685 25.8815 11.9903L24.4738 13.398C24.1129 13.7589 23.6392 13.939 23.1647 13.939C22.6902 13.939 22.2165 13.7589 21.8556 13.398C21.1338 12.6762 21.1338 11.5016 21.8556 10.7798L23.4725 9.18977L23.489 9.28093C23.6063 9.93323 23.9171 10.5265 24.3879 10.9965C24.742 11.3507 25.1343 11.586 25.6043 11.7467L25.691 11.66C25.954 11.397 26.0982 11.0473 26.0982 10.6745C26.0982 10.5915 26.0907 10.5086 26.0765 10.4271C25.8053 10.3375 25.5819 10.2097 25.3786 10.0065C25.0857 9.71356 24.9034 9.33921 24.8526 8.92451C24.8489 8.89463 24.8466 8.86549 24.8437 8.8356C24.8033 8.29537 24.9983 7.76785 25.3786 7.38827L26.7864 5.98055C27.1353 5.6316 27.6001 5.43883 28.0955 5.43883C28.5909 5.43883 29.0556 5.63086 29.4046 5.98055L29.4038 5.97905ZM36.7548 9.70011C36.7548 14.8506 32.5645 19.0401 27.4148 19.0401H9.34C4.1903 19.0401 0 14.8506 0 9.70011C0 4.54966 4.1903 0.360107 9.34 0.360107H27.4148C32.5652 0.360107 36.7548 4.55041 36.7548 9.70011ZM18 14.3843C18.1472 14.2057 17.4673 13.7029 17.3283 13.5183C17.0459 13.2119 17.0444 12.7711 16.8538 12.4132C16.3876 11.3327 15.8518 10.2605 15.1024 9.34594C14.3104 8.34543 13.333 7.51754 12.4745 6.57831C11.8371 5.92301 11.6668 4.98976 11.1041 4.28515C10.3285 3.13969 7.87624 2.82736 7.51683 4.44505C7.51833 4.49586 7.50264 4.52799 7.45855 4.56012C7.2598 4.70433 7.08271 4.86946 6.93402 5.06896C6.57013 5.57556 6.51409 6.43484 6.96839 6.88989C6.98333 6.65004 6.99155 6.42364 7.18134 6.25178C7.53252 6.5529 8.06304 6.65975 8.47026 6.43484C9.36989 7.71928 9.14573 9.49612 9.86005 10.8799C10.0573 11.2072 10.2561 11.5412 10.5094 11.8281C10.7148 12.1479 11.4247 12.5253 11.4665 12.8212C11.474 13.3293 11.4142 13.8844 11.7475 14.3096C11.9044 14.6279 11.5188 14.9477 11.208 14.9081C10.8045 14.9634 10.3121 14.6369 9.95868 14.8379C9.8339 14.9731 9.58957 14.8237 9.48197 15.0112C9.44461 15.1083 9.24286 15.2451 9.36316 15.3385C9.49691 15.2369 9.62095 15.1308 9.80102 15.1913C9.77412 15.3377 9.88994 15.3587 9.98184 15.4012C9.97886 15.5006 9.92057 15.6022 9.99679 15.6867C10.0857 15.597 10.1388 15.47 10.28 15.4326C10.7492 16.058 11.2267 14.7997 12.2421 15.3661C12.0359 15.3557 11.8528 15.3818 11.7139 15.5514C11.6795 15.5895 11.6503 15.6344 11.7109 15.6837C12.2586 15.3303 12.2556 15.8047 12.6112 15.659C12.8847 15.5163 13.1567 15.3377 13.4817 15.3885C13.1657 15.4797 13.153 15.7337 12.9677 15.9482C12.9363 15.9811 12.9213 16.0184 12.9579 16.073C13.614 16.0177 13.6678 15.7995 14.1975 15.532C14.5928 15.2907 14.9866 15.8757 15.3288 15.5425C15.4043 15.47 15.5074 15.4946 15.6008 15.4849C15.4812 14.8476 14.1669 15.6015 14.1878 14.7467C14.6107 14.459 14.5136 13.9083 14.542 13.4638C15.0284 13.7335 15.5694 13.8904 16.0461 14.1482C16.2867 14.5367 16.6641 15.0501 17.1669 15.0164C17.1804 14.9776 17.1923 14.9432 17.2065 14.9036C17.359 14.9298 17.5547 15.0306 17.6384 14.8379C17.8663 15.0762 18.201 15.0643 18.4992 15.003C18.7196 14.8237 18.0845 14.5681 17.9993 14.3836L18 14.3843ZM31.3458 7.28815C31.3458 6.41841 31.0081 5.60172 30.3946 4.98826C29.7812 4.37481 28.9645 4.03708 28.094 4.03708C27.2235 4.03708 26.4068 4.37481 25.7933 4.98826L24.3856 6.39599C24.0569 6.72476 23.8073 7.11106 23.6436 7.54369L23.6339 7.56835L23.6085 7.57582C23.0974 7.73348 22.6469 8.00396 22.2696 8.3813L20.8618 9.78902C19.5938 11.0578 19.5938 13.1215 20.8618 14.3895C21.4753 15.003 22.292 15.3407 23.1617 15.3407C24.0314 15.3407 24.8489 15.003 25.4623 14.3895L26.8701 12.9818C27.1973 12.6545 27.4454 12.2697 27.609 11.8378L27.6188 11.8132L27.6442 11.805C28.1463 11.651 28.6095 11.3716 28.9854 10.9965L30.3931 9.58878C31.0066 8.97532 31.3443 8.15863 31.3443 7.28815H31.3458ZM12.8802 13.3315C12.7592 13.8037 12.7196 14.6085 12.1054 14.6316C12.0546 14.9044 12.2944 15.0067 12.5119 14.9193C12.7278 14.8199 12.8302 14.9978 12.9026 15.1748C13.2359 15.2234 13.7291 15.0635 13.7477 14.669C13.2501 14.3821 13.0962 13.8366 12.8795 13.3315H12.8802Z" fill="#246161"/>
+<path d="M43.5142 15.3601L47.1462 3.84011H49.9702L53.6022 15.3601H51.6182L48.3222 5.02411H48.7542L45.4982 15.3601H43.5142ZM45.5382 12.8641V11.0641H51.5862V12.8641H45.5382ZM55.0486 15.3601V3.84011H59.8086C59.9206 3.84011 60.0646 3.84544 60.2406 3.85611C60.4166 3.86144 60.5792 3.87744 60.7286 3.90411C61.3952 4.00544 61.9446 4.22677 62.3766 4.56811C62.8139 4.90944 63.1366 5.34144 63.3446 5.86411C63.5579 6.38144 63.6646 6.95744 63.6646 7.59211C63.6646 8.22144 63.5579 8.79744 63.3446 9.32011C63.1312 9.83744 62.8059 10.2668 62.3686 10.6081C61.9366 10.9494 61.3899 11.1708 60.7286 11.2721C60.5792 11.2934 60.4139 11.3094 60.2326 11.3201C60.0566 11.3308 59.9152 11.3361 59.8086 11.3361H56.9766V15.3601H55.0486ZM56.9766 9.53611H59.7286C59.8352 9.53611 59.9552 9.53077 60.0886 9.52011C60.2219 9.50944 60.3446 9.48811 60.4566 9.45611C60.7766 9.37611 61.0272 9.23477 61.2086 9.03211C61.3952 8.82944 61.5259 8.60011 61.6006 8.34411C61.6806 8.08811 61.7206 7.83744 61.7206 7.59211C61.7206 7.34677 61.6806 7.09611 61.6006 6.84011C61.5259 6.57877 61.3952 6.34677 61.2086 6.14411C61.0272 5.94144 60.7766 5.80011 60.4566 5.72011C60.3446 5.68811 60.2219 5.66944 60.0886 5.66411C59.9552 5.65344 59.8352 5.64811 59.7286 5.64811H56.9766V9.53611ZM65.4273 15.3601V3.84011H67.3553V15.3601H65.4273Z" fill="#246161"/>
+</g>
+<defs>
+<clipPath id="clip0_4019_689">
+<rect width="71.0711" height="18.68" fill="white" transform="translate(0 0.360107)"/>
+</clipPath>

----------------------------------------

File: docs/api_reference/conf.py
Status: modified
Changes: +92 -31
Diff:
@@ -62,7 +62,7 @@ def run(self):
             item_node.append(para_node)
             list_node.append(item_node)
         if list_node.children:
-            title_node = nodes.title()
+            title_node = nodes.rubric()
             title_node.append(nodes.Text(f"Examples using {class_or_func_name}"))
             return [title_node, list_node]
         return [list_node]
@@ -75,7 +75,10 @@ class Beta(BaseAdmonition):
     def run(self):
         self.content = self.content or StringList(
             [
-                "This feature is in beta. It is actively being worked on, so the API may change."
+                (
+                    "This feature is in beta. It is actively being worked on, so the "
+                    "API may change."
+                )
             ]
         )
         self.arguments = self.arguments or ["Beta"]
@@ -90,13 +93,10 @@ def setup(app):
 # -- Project information -----------------------------------------------------
 
 project = "🦜🔗 LangChain"
-copyright = "2023, LangChain, Inc."
-author = "LangChain, Inc."
+copyright = "2023, LangChain Inc"
+author = "LangChain, Inc"
 
-version = data["tool"]["poetry"]["version"]
-release = version
-
-html_title = project + " " + version
+html_favicon = "_static/img/brand/favicon.png"
 html_last_updated_fmt = "%b %d, %Y"
 
 
@@ -112,11 +112,13 @@ def setup(app):
     "sphinx.ext.napoleon",
     "sphinx.ext.viewcode",
     "sphinxcontrib.autodoc_pydantic",
-    "sphinx_copybutton",
-    "sphinx_panels",
     "IPython.sphinxext.ipython_console_highlighting",
+    "myst_parser",
+    "_extensions.gallery_directive",
+    "sphinx_design",
+    "sphinx_copybutton",
 ]
-source_suffix = [".rst"]
+source_suffix = [".rst", ".md"]
 
 # some autodoc pydantic options are repeated in the actual template.
 # potentially user error, but there may be bugs in the sphinx extension
@@ -148,32 +150,91 @@ def setup(app):
 # The theme to use for HTML and HTML Help pages.  See the documentation for
 # a list of builtin themes.
 #
-html_theme = "scikit-learn-modern"

----------------------------------------

File: docs/api_reference/create_api_rst.py
Status: modified
Changes: +203 -33
Diff:
@@ -239,7 +239,7 @@ def _construct_doc(
     package_namespace: str,
     members_by_namespace: Dict[str, ModuleMembers],
     package_version: str,
-) -> str:
+) -> List[typing.Tuple[str, str]]:
     """Construct the contents of the reference.rst file for the given package.
 
     Args:
@@ -251,15 +251,38 @@ def _construct_doc(
     Returns:
         The contents of the reference.rst file.
     """
-    full_doc = f"""\
-=======================
-``{package_namespace}`` {package_version}
-=======================
+    docs = []
+    index_doc = f"""\
+:html_theme.sidebar_secondary.remove:
 
+.. currentmodule:: {package_namespace}
+
+.. _{package_namespace}:
+
+======================================
+{package_namespace.replace('_', '-')}: {package_version}
+======================================
+
+.. automodule:: {package_namespace}
+    :no-members:
+    :no-inherited-members:
+
+.. toctree::
+    :hidden:
+    :maxdepth: 2
+    
+"""
+    index_autosummary = """
 """
     namespaces = sorted(members_by_namespace)
 
     for module in namespaces:
+        index_doc += f"    {module}\n"
+        module_doc = f"""\
+.. currentmodule:: {package_namespace}
+
+.. _{package_namespace}_{module}:
+"""
         _members = members_by_namespace[module]
         classes = [
             el
@@ -281,26 +304,36 @@ def _construct_doc(
         ]
         if not (classes or functions):
             continue
-        section = f":mod:`{package_namespace}.{module}`"
+        section = f":mod:`{module}`"
         underline = "=" * (len(section) + 1)
-        full_doc += f"""\
+        module_doc += f"""
 {section}
 {underline}
 
 .. automodule:: {package_namespace}.{module}
     :no-members:
     :no-inherited-members:
 
+"""
+
+        index_autosummary += f"""
+:ref:`{package_namespace}_{module}`
+{'^' * (len(module) + 5)}
 """
 
         if classes:
-            full_doc += f"""\
-Classes
---------------
+            module_doc += f"""\
+**Classes**
+
 .. currentmodule:: {package_namespace}
 
 .. autosummary::
     :toctree: {module}
+"""
+            index_autosummary += """
+**Classes**
+
+.. autosummary::
 """
 
             for class_ in sorted(classes, key=lambda c: c["qualified_name"]):
@@ -317,19 +350,22 @@ def _construct_doc(
                 else:
                     template = "class.rst"
 
-                full_doc += f"""\
+                module_doc += f"""\
     :template: {template}
     
     {class_["qualified_name"]}
     
+"""
+                index_autosummary += f"""
+    {class_['qualified_name']}
 """
 
         if functions:
             _functions = [f["qualified_name"] for f in functions]
             fstring = "\n    ".join(sorted(_functions))
-            full_doc += f"""\
-Functions
---------------
+            module_doc += f"""\
+**Functions**
+

----------------------------------------

File: docs/api_reference/index.rst
Status: removed
Changes: +0 -8
Diff:
@@ -1,8 +0,0 @@
-=============
-LangChain API
-=============
-
-.. toctree::
-    :maxdepth: 2
-
-    api_reference.rst

----------------------------------------

File: docs/api_reference/requirements.txt
Status: modified
Changes: +11 -17
Diff:
@@ -1,17 +1,11 @@
--e libs/experimental
--e libs/langchain
--e libs/core
--e libs/community
-pydantic<2
-autodoc_pydantic==1.8.0
-myst_parser
-nbsphinx==0.8.9
-sphinx>=5

----------------------------------------

File: docs/api_reference/scripts/custom_formatter.py
Status: added
Changes: +41 -0
Diff:
@@ -0,0 +1,41 @@
+import sys
+from glob import glob
+from pathlib import Path
+
+from bs4 import BeautifulSoup
+
+CUR_DIR = Path(__file__).parents[1]
+
+
+def process_toc_h3_elements(html_content: str) -> str:
+    """Update Class.method() TOC headers to just method()."""
+    # Create a BeautifulSoup object
+    soup = BeautifulSoup(html_content, "html.parser")

----------------------------------------

File: docs/api_reference/templates/class.rst
Status: modified
Changes: +4 -4
Diff:
@@ -1,4 +1,4 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
 .. currentmodule:: {{ module }}
@@ -11,7 +11,7 @@
 
    .. autosummary::
    {% for item in attributes %}

----------------------------------------

File: docs/api_reference/templates/enum.rst
Status: modified
Changes: +1 -1
Diff:
@@ -1,4 +1,4 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
 .. currentmodule:: {{ module }}

----------------------------------------

File: docs/api_reference/templates/function.rst
Status: modified
Changes: +1 -1
Diff:
@@ -1,4 +1,4 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
 .. currentmodule:: {{ module }}

----------------------------------------

File: docs/api_reference/templates/langchain_docs.html
Status: added
Changes: +12 -0
Diff:
@@ -0,0 +1,12 @@
+<!-- This will display a link to LangChain docs -->
+<head>
+    <style>
+        .text-link {
+            text-decoration: none; /* Remove underline */
+            color: inherit;        /* Inherit color from parent element */
+        }
+    </style>
+</head>

----------------------------------------

File: docs/api_reference/templates/pydantic.rst
Status: modified
Changes: +1 -1
Diff:
@@ -1,4 +1,4 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
 .. currentmodule:: {{ module }}

----------------------------------------

File: docs/api_reference/templates/runnable_non_pydantic.rst
Status: modified
Changes: +8 -8
Diff:
@@ -1,21 +1,21 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
-.. NOTE:: {{objname}} implements the standard :py:class:`Runnable Interface <langchain_core.runnables.base.Runnable>`. 🏃
-
-    The :py:class:`Runnable Interface <langchain_core.runnables.base.Runnable>` has additional methods that are available on runnables, such as :py:meth:`with_types <langchain_core.runnables.base.Runnable.with_types>`, :py:meth:`with_retry <langchain_core.runnables.base.Runnable.with_retry>`, :py:meth:`assign <langchain_core.runnables.base.Runnable.assign>`, :py:meth:`bind <langchain_core.runnables.base.Runnable.bind>`, :py:meth:`get_graph <langchain_core.runnables.base.Runnable.get_graph>`, and more.
-
 .. currentmodule:: {{ module }}
 
 .. autoclass:: {{ objname }}
 
+.. NOTE:: {{objname}} implements the standard :py:class:`Runnable Interface <langchain_core.runnables.base.Runnable>`. 🏃

----------------------------------------

File: docs/api_reference/templates/runnable_pydantic.rst
Status: modified
Changes: +6 -6
Diff:
@@ -1,10 +1,6 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
-.. NOTE:: {{objname}} implements the standard :py:class:`Runnable Interface <langchain_core.runnables.base.Runnable>`. 🏃
-
-    The :py:class:`Runnable Interface <langchain_core.runnables.base.Runnable>` has additional methods that are available on runnables, such as :py:meth:`with_types <langchain_core.runnables.base.Runnable.with_types>`, :py:meth:`with_retry <langchain_core.runnables.base.Runnable.with_retry>`, :py:meth:`assign <langchain_core.runnables.base.Runnable.assign>`, :py:meth:`bind <langchain_core.runnables.base.Runnable.bind>`, :py:meth:`get_graph <langchain_core.runnables.base.Runnable.get_graph>`, and more.
-
 .. currentmodule:: {{ module }}

----------------------------------------

File: docs/api_reference/templates/typeddict.rst
Status: modified
Changes: +1 -1
Diff:
@@ -1,4 +1,4 @@
-:mod:`{{module}}`.{{objname}}
+{{ objname }}
 {{ underline }}==============
 
 .. currentmodule:: {{ module }}

----------------------------------------

File: docs/api_reference/themes/COPYRIGHT.txt
Status: removed
Changes: +0 -27
Diff:
@@ -1,27 +0,0 @@
-Copyright (c) 2007-2023 The scikit-learn developers.
-All rights reserved.
-
-Redistribution and use in source and binary forms, with or without
-modification, are permitted provided that the following conditions are met:
-
-* Redistributions of source code must retain the above copyright notice, this
-  list of conditions and the following disclaimer.
-

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/javascript.html
Status: removed
Changes: +0 -67
Diff:
@@ -1,67 +0,0 @@
-<script>
-$(document).ready(function() {
-    /* Add a [>>>] button on the top-right corner of code samples to hide
-     * the >>> and ... prompts and the output and thus make the code
-     * copyable. */
-    var div = $('.highlight-python .highlight,' +
-                '.highlight-python3 .highlight,' +
-                '.highlight-pycon .highlight,' +
-		'.highlight-default .highlight')
-    var pre = div.find('pre');
-
-    // get the styles from the current theme
-    pre.parent().parent().css('position', 'relative');
-    var hide_text = 'Hide prompts and outputs';
-    var show_text = 'Show prompts and outputs';
-
-    // create and add the button to all the code blocks that contain >>>
-    div.each(function(index) {
-        var jthis = $(this);
-        if (jthis.find('.gp').length > 0) {
-            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/layout.html
Status: removed
Changes: +0 -132
Diff:
@@ -1,132 +0,0 @@
-{# TEMPLATE VAR SETTINGS #}
-{%- set url_root = pathto('', 1) %}
-{%- if url_root == '#' %}{% set url_root = '' %}{% endif %}
-{%- if not embedded and docstitle %}
-    {%- set titlesuffix = " &mdash; "|safe + docstitle|e %}
-{%- else %}
-    {%- set titlesuffix = "" %}
-{%- endif %}
-{%- set lang_attr = 'en' %}
-
-<!DOCTYPE html>
-<!--[if IE 8]><html class="no-js lt-ie9" lang="{{ lang_attr }}" > <![endif]-->
-<!--[if gt IE 8]><!-->
-<html class="no-js" lang="{{ lang_attr }}"> <!--<![endif]-->
-<head>
-    <meta charset="utf-8">
-    {{ metatags }}
-    <meta name="viewport" content="width=device-width, initial-scale=1.0">
-
-    {% block htmltitle %}
-        <title>{{ title|striptags|e }}{{ titlesuffix }}</title>
-    {% endblock %}
-    <link rel="canonical"
-          href="https://api.python.langchain.com/en/latest/{{ pagename }}.html"/>
-
-    {% if favicon_url %}
-        <link rel="shortcut icon" href="{{ favicon_url|e }}"/>
-    {% endif %}
-
-    <link rel="stylesheet"
-          href="{{ pathto('_static/css/vendor/bootstrap.min.css', 1) }}"
-          type="text/css"/>
-    {%- for css in css_files %}
-        {%- if css|attr("rel") %}
-            <link rel="{{ css.rel }}" href="{{ pathto(css.filename, 1) }}"
-                  type="text/css"{% if css.title is not none %}
-                  title="{{ css.title }}"{% endif %} />
-        {%- else %}
-            <link rel="stylesheet" href="{{ pathto(css, 1) }}" type="text/css"/>
-        {%- endif %}
-    {%- endfor %}
-    <link rel="stylesheet" href="{{ pathto('_static/' + style, 1) }}" type="text/css"/>
-    <script id="documentation_options" data-url_root="{{ pathto('', 1) }}"

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/nav.html
Status: removed
Changes: +0 -78
Diff:
@@ -1,78 +0,0 @@
-{%- if pagename != 'index' and pagename != 'documentation' %}
-  {%- set nav_bar_class = "sk-docs-navbar" %}
-  {%- set top_container_cls = "sk-docs-container" %}
-{%- else %}
-  {%- set nav_bar_class = "sk-landing-navbar" %}
-  {%- set top_container_cls = "sk-landing-container" %}
-{%- endif %}
-
-<nav id="navbar" class="{{ nav_bar_class }} navbar navbar-expand-md navbar-light bg-light py-0">
-  <div class="container-fluid {{ top_container_cls }} px-0">
-    {%- if logo_url %}
-      <a class="navbar-brand py-0" href="{{ pathto('index') }}">
-        <img
-          class="sk-brand-img"
-          src="{{ logo_url|e }}"
-          alt="logo"/>
-      </a>
-    {%- endif %}
-    <button
-      id="sk-navbar-toggler"
-      class="navbar-toggler"
-      type="button"
-      data-toggle="collapse"
-      data-target="#navbarSupportedContent"
-      aria-controls="navbarSupportedContent"

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/search.html
Status: removed
Changes: +0 -16
Diff:
@@ -1,16 +0,0 @@
-{%- extends "basic/search.html" %}
-{% block extrahead %}
-  <script type="text/javascript" src="{{ pathto('_static/underscore.js', 1) }}"></script>
-  <script type="text/javascript" src="{{ pathto('searchindex.js', 1) }}" defer></script>
-  <script type="text/javascript" src="{{ pathto('_static/doctools.js', 1) }}"></script>
-  <script type="text/javascript" src="{{ pathto('_static/language_data.js', 1) }}"></script>
-  <script type="text/javascript" src="{{ pathto('_static/searchtools.js', 1) }}"></script>
-  <script type="text/javascript" src="{{ pathto('_static/sphinx_highlight.js', 1) }}"></script>
-  <script type="text/javascript">

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/static/css/theme.css
Status: removed
Changes: +0 -1431
Diff:
@@ -1,1431 +0,0 @@
-/* Elements */
-a {
-  color: #2878A2;
-  word-wrap: break-word;
-}
-
-a:focus {
-  outline: none;
-}
-
-/* Anchor links */
-
-a.headerlink {
-  color: #c60f0f;
-  font-size: 0.8em;
-  padding: 0 4px 0 4px;
-  text-decoration: none;
-  visibility: hidden;
-}
-
-a.headerlink:hover {
-  background-color: #c60f0f;
-  color: white;
-}
-
-p {
-  word-break: break-word;
-  hyphens: auto;
-}
-
-input:focus {
-  outline: none;
-}
-
-code {
-  color: #222;
-  background-color: #ecf0f3;
-  border-radius: 0.2rem;
-  padding: 0.15rem;
-  word-break: normal;
-}
-
-nav {
-  z-index: 3;
-}
-
-h1 code, h2 code, h3 code, h4 code, h5 code, h6 code {
-  background-color: transparent;
-}
-
-h4 .section-number, h5 .section-number, h6 .section-number {
-  display: none;
-}
-
-h1:hover a.headerlink,
-h2:hover a.headerlink,
-h3:hover a.headerlink,
-h4:hover a.headerlink,
-h5:hover a.headerlink,
-h6:hover a.headerlink,
-dt:hover a.headerlink {
-  visibility: visible;
-}
-
-strong {
-  font-weight: bold;
-}
-
-a code {
-  color: inherit;
-}
-
-a code {
-  background-color: transparent;
-  font-weight: bold;
-  color: #2878A2;
-  border-radius: 0;
-  padding: 0;
-  white-space: nowrap;
-}
-
-img {
-   max-width: 100%;
-}
-
-span.highlighted {
-    background-color: #fbe54e;
-}
-
-div.highlight {
-  border: 1px solid #ddd;
-  margin-bottom: 1rem;
-}
-
-div.highlight pre {
-  padding: 0.2rem 0.5rem;
-  margin-bottom: 0;
-  line-height: 1.2rem;
-}
-
-div.highlight a {
-  text-decoration: underline;
-}
-
-.versionmodified {
-  font-style: italic;
-}
-
-a.sk-landing-btn {
-  background-color: #ff9c34;
-  color: black;
-  cursor: pointer;
-  font-size: 1.1rem;
-  font-weight: 500;
-}
-
-a.sk-landing-btn:hover {
-  background-color: #45bf7b;
-}
-
-.sk-donate-btn {
-  cursor: pointer;
-}
-
-.sk-page-content div.logo {
-  float: left;
-  width: 200px;
-}
-
-@media screen and (min-width: 992px) {
-  .sk-page-content {
-    padding-left: 2rem!important;
-    padding-right: 2rem!important;
-  }
-}
-
-@media screen and (min-width: 1200px) {
-  .sk-px-xl-4 {
-    padding-left: 1.3rem!important;
-    padding-right: 1.3rem!important;
-  }
-}
-
-/* clearfix */
-
-div.clearer {
-  clear: both;
-}
-
-/* details / summary */
-
-div.sk-page-content details {
-    margin: 4ex 0pt;
-}
-
-div.sk-page-content summary.btn {
-    display: list-item;
-    padding: 6px 20px;
-    border: 1pt solid #999;
-}
-
-div.sk-page-content details div.card {
-    padding: 0pt .5ex;
-    margin: 1ex 0pt;
-    border: 1px solid #e9ecef;
-    border-left-width: .25rem;
-    border-radius: .25rem;
-    background: rgb(250, 252, 253)
-}
-
-div.sk-page-content summary {
-  position: relative; /* Needed for the tooltips */
-}
-
-div.sk-page-content summary .tooltiptext {
-  visibility: hidden;
-  width: 120px;
-  background-color: black;
-  color: #fff;
-  text-align: center;
-  border-radius: 6px;
-  padding: 5px 0;
-  position: absolute;
-  z-index: 1;
-  bottom: 150%;
-  left: 50%;
-  margin-left: -60px;
-}
-
-div.sk-page-content summary .tooltiptext::after {
-  content: "";
-  position: absolute;
-  top: 100%;
-  left: 50%;
-  margin-left: -5px;
-  border-width: 5px;
-  border-style: solid;
-  border-color: black transparent transparent transparent;
-}
-
-div.sk-page-content summary:hover .tooltiptext {
-  visibility: visible;
-}
-
-/* Button */
-
-.sk-btn-primary {
-  background-color: #30799C;
-  border-color: #30799C;
-  color: white;
-}
-
-.sk-btn-primary:hover,
-.sk-btn-primary:active {
-  background-color: #3499cd;
-  border-color: #3499cd;
-}
-
-/* Quote */
-
-.quote {
-  text-align: right;
-  line-height: 1.5em;
-  font-style: italic;
-  margin: 2em 3em 1em 3em;
-}
-
-.line-block {
-  display: block;
-  margin-top: 1em;
-  margin-bottom: 1em;
-}
-
-/* Search */
-
-#search-results {
-  margin-top: 1rem;
-}
-
-#searchbox {
-  padding-top: 0.1rem;
-}
-
-.sk-search-text-input {
-  width: 12rem;
-}
-
-.sk-search-text-btn {
-  padding-left: 0.2rem;
-  padding-right: 0.2rem;
-}
-
-ul.search li div.context {
-  color: #888;
-  margin: 0.1rem 0 0 0;
-  text-align: left;
-}
-
-@media screen and (min-width: 768px) {
-  ul.search li div.context {
-    margin-left: 1rem;
-  }
-
-  .sk-search-text-input {
-    width: 5rem;
-  }
-}
-
-@media screen and (min-width: 806px) {
-  .sk-search-text-input {
-    width: 7rem;
-  }
-}
-
-@media screen and (min-width: 820px) {
-  .sk-search-text-input {
-    width: 8rem;
-  }
-}
-
-@media screen and (min-width: 886px) {
-  .sk-search-text-input {
-    width: 12rem;
-  }
-}
-
-ul.search li a {
-  font-weight: bold;
-}
-/* navbar */
-
-img.sk-brand-img {
-  height: 48px;
-}
-
-.navbar-light .navbar-nav a.nav-link, a.sk-dropdown-item  {
-  color: rgba(77, 77, 77, 1);
-  font-weight: 500;
-}
-
-.navbar-light .navbar-nav a.nav-link:hover, a.sk-dropdown-item:hover {
-  color: rgba(246, 126, 0, 1);
-}
-
-a.sk-nav-dropdown-item:active {
-  color: white;
-  background-color: rgba(246, 126, 0, 1);
-}
-
-.nav-more-item-mobile-items {
-  display: inherit;
-}
-
-.nav-more-item-dropdown {
-  display: none;
-}
-
-@media screen and (min-width: 768px) {
-  .nav-more-item-dropdown {
-    display: inherit;
-  }
-
-  .nav-more-item-mobile-items {
-    display: none;
-  }
-}
-/* LANDING PAGE STYLE */
-
-div.sk-landing-container {
-  max-width: 1400px;
-}
-
-div.sk-landing-container .text-white {
-    text-shadow: 0px 0px 8px rgb(42, 98, 128);
-}
-
-ul.sk-landing-header-body {
-  margin-top: auto;
-  margin-bottom: auto;
-  font-size: 1.2rem;
-  font-weight: 500;
-}
-
-div.sk-landing-bg-more-info dd {
-  padding-left: 0;
-}
-
-div.sk-landing-bg {
-  background-image: linear-gradient(160deg, rgba(42,98,128,1) 0%, rgba(52,153,205,1) 17%, rgba(255,243,211,1) 59%, rgba(255,178,96,1) 100%);
-}
-
-div.sk-landing-bg-more-info {
-  background-color: #f8f8f8;
-  font-size: 0.96rem;
-}
-
-.sk-card-title {
-  font-weight: 700;
-}
-
-.sk-landing-header {
-  font-size: 3.2rem;
-}
-
-.sk-landing-subheader {
-  letter-spacing: 0.17rem;
-}
-
-.sk-landing-call-header {
-  color: #E07200;
-  font-weight: 700;
-}
-
-img.sk-index-img {
-  max-height: 240px;
-  margin: auto;
-  margin-bottom: 1em;
-  width: auto;
-}
-
-@media screen and (min-width: 768px) {
-  img.sk-index-img {
-    width: 100%
-  }
-}
-
-img.sk-who-uses-carousel-img {
-  max-height: 100px;
-  max-width: 50%;
-}
-
-div#carouselExampleSlidesOnly {
-  min-height: 200px;
-}
-
-ul.sk-landing-call-list li {
-  margin-bottom: 0.25rem;
-}
-
-img.sk-footer-funding-logo {
-  max-height: 36px;
-  max-width: 80px;
-  margin: 0 8px;
-  margin-bottom: 8px;
-}
-
-a.sk-footer-funding-link:hover {
-  text-decoration: none;
-}
-/* DOCS STYLE */
-
-.navbar > .sk-docs-container {
-  max-width: 1400px;
-  margin: 0 auto;
-}
-
-#sk-sidebar-wrapper {
-  height: 100%;
-  overflow-y: hidden;
-  overflow-x: hidden;
-  position: fixed;
-  margin-left: -240px;
-  width: 240px;
-  -webkit-transition: margin 0.25s ease-out, opacity 0.25s ease-out;
-  -moz-transition: margin 0.25s ease-out, opacity 0.25s ease-out;
-  -o-transition: margin 0.25s ease-out, opacity 0.25s ease-out;
-  transition: margin 0.25s ease-out, opacity 0.25s ease-out;
-  background-color: white;
-  opacity: 0;
-  top: 0;
-  padding: 0 0.5rem 0.5rem 0.5rem;
-  z-index: 2;
-}
-
-#sk-toggle-checkbox {
-  display: none;
-}
-
-#sk-toggle-checkbox:checked ~ #sk-sidebar-wrapper {
-  margin-left: 0;
-  opacity: 1;
-}
-
-#sk-doc-wrapper {
-  max-width: 1400px;
-  margin: 0 auto;
-}
-
-#sk-page-content-wrapper {
-  width: 100%;
-}
-
-/* Enables section links to be visible when anchor-linked */
-section[id]::before {
-  display: block;
-  height: 52px;
-  margin-top: -52px;
-  visibility: hidden;
-  content: "";
-}
-
-div.sk-page-content {
-  background-color: white;
-  position: relative;
-  margin-top: 0.5rem;
-}
-
-div.sk-page-content {
-  table-layout: fixed;
-  max-width: 100%;
-}
-
-div.section h2,
-div.section h3,
-div.section h4,
-div.section h5,

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/static/css/vendor/bootstrap.min.css
Status: removed
Changes: +0 -6

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/static/js/vendor/bootstrap.min.js
Status: removed
Changes: +0 -6
Diff:
@@ -1,6 +0,0 @@
-/*!
-  * Bootstrap v4.3.1 (https://getbootstrap.com/)
-  * Copyright 2011-2019 The Bootstrap Authors (https://github.com/twbs/bootstrap/graphs/contributors)
-  * Licensed under MIT (https://github.com/twbs/bootstrap/blob/master/LICENSE)
-  */
-!function(t,e){"object"==typeof exports&&"undefined"!=typeof module?e(exports,require("jquery"),require("popper.js")):"function"==typeof define&&define.amd?define(["exports","jquery","popper.js"],e):e((t=t||self).bootstrap={},t.jQuery,t.Popper)}(this,function(t,g,u){"use strict";function i(t,e){for(var n=0;n<e.length;n++){var i=e[n];i.enumerable=i.enumerable||!1,i.configurable=!0,"value"in i&&(i.writable=!0),Object.defineProperty(t,i.key,i)}}function s(t,e,n){return e&&i(t.prototype,e),n&&i(t,n),t}function l(o){for(var t=1;t<arguments.length;t++){var r=null!=arguments[t]?arguments[t]:{},e=Object.keys(r);"function"==typeof Object.getOwnPropertySymbols&&(e=e.concat(Object.getOwnPropertySymbols(r).filter(function(t){return Object.getOwnPropertyDescriptor(r,t).enumerable}))),e.forEach(function(t){var e,n,i;e=o,i=r[n=t],n in e?Object.defineProperty(e,n,{value:i,enumerable:!0,configurable:!0,writable:!0}):e[n]=i})}return o}g=g&&g.hasOwnProperty("default")?g.default:g,u=u&&u.hasOwnProperty("default")?u.default:u;var e="transitionend";function n(t){var e=this,n=!1;return g(this).one(_.TRANSITION_END,function(){n=!0}),setTimeout(function(){n||_.triggerTransitionEnd(e)},t),this}var _={TRANSITION_END:"bsTransitionEnd",getUID:function(t){for(;t+=~~(1e6*Math.random()),document.getElementById(t););return t},getSelectorFromElement:function(t){var e=t.getAttribute("data-target");if(!e||"#"===e){var n=t.getAttribute("href");e=n&&"#"!==n?n.trim():""}try{return document.querySelector(e)?e:null}catch(t){return null}},getTransitionDurationFromElement:function(t){if(!t)return 0;var e=g(t).css("transition-duration"),n=g(t).css("transition-delay"),i=parseFloat(e),o=parseFloat(n);return i||o?(e=e.split(",")[0],n=n.split(",")[0],1e3*(parseFloat(e)+parseFloat(n))):0},reflow:function(t){return t.offsetHeight},triggerTransitionEnd:function(t){g(t).trigger(e)},supportsTransitionEnd:function(){return Boolean(e)},isElement:function(t){return(t[0]||t).nodeType},typeCheckConfig:function(t,e,n){for(var i in n)if(Object.prototype.hasOwnProperty.call(n,i)){var o=n[i],r=e[i],s=r&&_.isElement(r)?"element":(a=r,{}.toString.call(a).match(/\s([a-z]+)/i)[1].toLowerCase());if(!new RegExp(o).test(s))throw new Error(t.toUpperCase()+': Option "'+i+'" provided type "'+s+'" but expected type "'+o+'".')}var a},findShadowRoot:function(t){if(!document.documentElement.attachShadow)return null;if("function"!=typeof t.getRootNode)return t instanceof ShadowRoot?t:t.parentNode?_.findShadowRoot(t.parentNode):null;var e=t.getRootNode();return e instanceof ShadowRoot?e:null}};g.fn.emulateTransitionEnd=n,g.event.special[_.TRANSITION_END]={bindType:e,delegateType:e,handle:function(t){if(g(t.target).is(this))return t.handleObj.handler.apply(this,arguments)}};var o="alert",r="bs.alert",a="."+r,c=g.fn[o],h={CLOSE:"close"+a,CLOSED:"closed"+a,CLICK_DATA_API:"click"+a+".data-api"},f="alert",d="fade",m="show",p=function(){function i(t){this._element=t}var t=i.prototype;return t.close=function(t){var e=this._element;t&&(e=this._getRootElement(t)),this._triggerCloseEvent(e).isDefaultPrevented()||this._removeElement(e)},t.dispose=function(){g.removeData(this._element,r),this._element=null},t._getRootElement=function(t){var e=_.getSelectorFromElement(t),n=!1;return e&&(n=document.querySelector(e)),n||(n=g(t).closest("."+f)[0]),n},t._triggerCloseEvent=function(t){var e=g.Event(h.CLOSE);return g(t).trigger(e),e},t._removeElement=function(e){var n=this;if(g(e).removeClass(m),g(e).hasClass(d)){var t=_.getTransitionDurationFromElement(e);g(e).one(_.TRANSITION_END,function(t){return n._destroyElement(e,t)}).emulateTransitionEnd(t)}else this._destroyElement(e)},t._destroyElement=function(t){g(t).detach().trigger(h.CLOSED).remove()},i._jQueryInterface=function(n){return this.each(function(){var t=g(this),e=t.data(r);e||(e=new i(this),t.data(r,e)),"close"===n&&e[n](this)})},i._handleDismiss=function(e){return function(t){t&&t.preventDefault(),e.close(this)}},s(i,null,[{key:"VERSION",get:function(){return"4.3.1"}}]),i}();g(document).on(h.CLICK_DATA_API,'[data-dismiss="alert"]',p._handleDismiss(new p)),g.fn[o]=p._jQueryInterface,g.fn[o].Constructor=p,g.fn[o].noConflict=function(){return g.fn[o]=c,p._jQueryInterface};var v="button",y="bs.button",E="."+y,C=".data-api",T=g.fn[v],S="active",b="btn",I="focus",D='[data-toggle^="button"]',w='[data-toggle="buttons"]',A='input:not([type="hidden"])',N=".active",O=".btn",k={CLICK_DATA_API:"click"+E+C,FOCUS_BLUR_DATA_API:"focus"+E+C+" blur"+E+C},P=function(){function n(t){this._element=t}var t=n.prototype;return t.toggle=function(){var t=!0,e=!0,n=g(this._element).closest(w)[0];if(n){var i=this._element.querySelector(A);if(i){if("radio"===i.type)if(i.checked&&this._element.classList.contains(S))t=!1;else{var o=n.querySelector(N);o&&g(o).removeClass(S)}if(t){if(i.hasAttribute("disabled")||n.hasAttribute("disabled")||i.classList.contains("disabled")||n.classList.contains("disabled"))return;i.checked=!this._element.classList.contains(S),g(i).trigger("change")}i.focus(),e=!1}}e&&this._element.setAttribute("aria-pressed",!this._element.classList.contains(S)),t&&g(this._element).toggleClass(S)},t.dispose=function(){g.removeData(this._element,y),this._element=null},n._jQueryInterface=function(e){return this.each(function(){var t=g(this).data(y);t||(t=new n(this),g(this).data(y,t)),"toggle"===e&&t[e]()})},s(n,null,[{key:"VERSION",get:function(){return"4.3.1"}}]),n}();g(document).on(k.CLICK_DATA_API,D,function(t){t.preventDefault();var e=t.target;g(e).hasClass(b)||(e=g(e).closest(O)),P._jQueryInterface.call(g(e),"toggle")}).on(k.FOCUS_BLUR_DATA_API,D,function(t){var e=g(t.target).closest(O)[0];g(e).toggleClass(I,/^focus(in)?$/.test(t.type))}),g.fn[v]=P._jQueryInterface,g.fn[v].Constructor=P,g.fn[v].noConflict=function(){return g.fn[v]=T,P._jQueryInterface};var L="carousel",j="bs.carousel",H="."+j,R=".data-api",x=g.fn[L],F={interval:5e3,keyboard:!0,slide:!1,pause:"hover",wrap:!0,touch:!0},U={interval:"(number|boolean)",keyboard:"boolean",slide:"(boolean|string)",pause:"(string|boolean)",wrap:"boolean",touch:"boolean"},W="next",q="prev",M="left",K="right",Q={SLIDE:"slide"+H,SLID:"slid"+H,KEYDOWN:"keydown"+H,MOUSEENTER:"mouseenter"+H,MOUSELEAVE:"mouseleave"+H,TOUCHSTART:"touchstart"+H,TOUCHMOVE:"touchmove"+H,TOUCHEND:"touchend"+H,POINTERDOWN:"pointerdown"+H,POINTERUP:"pointerup"+H,DRAG_START:"dragstart"+H,LOAD_DATA_API:"load"+H+R,CLICK_DATA_API:"click"+H+R},B="carousel",V="active",Y="slide",z="carousel-item-right",X="carousel-item-left",$="carousel-item-next",G="carousel-item-prev",J="pointer-event",Z=".active",tt=".active.carousel-item",et=".carousel-item",nt=".carousel-item img",it=".carousel-item-next, .carousel-item-prev",ot=".carousel-indicators",rt="[data-slide], [data-slide-to]",st='[data-ride="carousel"]',at={TOUCH:"touch",PEN:"pen"},lt=function(){function r(t,e){this._items=null,this._interval=null,this._activeElement=null,this._isPaused=!1,this._isSliding=!1,this.touchTimeout=null,this.touchStartX=0,this.touchDeltaX=0,this._config=this._getConfig(e),this._element=t,this._indicatorsElement=this._element.querySelector(ot),this._touchSupported="ontouchstart"in document.documentElement||0<navigator.maxTouchPoints,this._pointerEvent=Boolean(window.PointerEvent||window.MSPointerEvent),this._addEventListeners()}var t=r.prototype;return t.next=function(){this._isSliding||this._slide(W)},t.nextWhenVisible=function(){!document.hidden&&g(this._element).is(":visible")&&"hidden"!==g(this._element).css("visibility")&&this.next()},t.prev=function(){this._isSliding||this._slide(q)},t.pause=function(t){t||(this._isPaused=!0),this._element.querySelector(it)&&(_.triggerTransitionEnd(this._element),this.cycle(!0)),clearInterval(this._interval),this._interval=null},t.cycle=function(t){t||(this._isPaused=!1),this._interval&&(clearInterval(this._interval),this._interval=null),this._config.interval&&!this._isPaused&&(this._interval=setInterval((document.visibilityState?this.nextWhenVisible:this.next).bind(this),this._config.interval))},t.to=function(t){var e=this;this._activeElement=this._element.querySelector(tt);var n=this._getItemIndex(this._activeElement);if(!(t>this._items.length-1||t<0))if(this._isSliding)g(this._element).one(Q.SLID,function(){return e.to(t)});else{if(n===t)return this.pause(),void this.cycle();var i=n<t?W:q;this._slide(i,this._items[t])}},t.dispose=function(){g(this._element).off(H),g.removeData(this._element,j),this._items=null,this._config=null,this._element=null,this._interval=null,this._isPaused=null,this._isSliding=null,this._activeElement=null,this._indicatorsElement=null},t._getConfig=function(t){return t=l({},F,t),_.typeCheckConfig(L,t,U),t},t._handleSwipe=function(){var t=Math.abs(this.touchDeltaX);if(!(t<=40)){var e=t/this.touchDeltaX;0<e&&this.prev(),e<0&&this.next()}},t._addEventListeners=function(){var e=this;this._config.keyboard&&g(this._element).on(Q.KEYDOWN,function(t){return e._keydown(t)}),"hover"===this._config.pause&&g(this._element).on(Q.MOUSEENTER,function(t){return e.pause(t)}).on(Q.MOUSELEAVE,function(t){return e.cycle(t)}),this._config.touch&&this._addTouchEventListeners()},t._addTouchEventListeners=function(){var n=this;if(this._touchSupported){var e=function(t){n._pointerEvent&&at[t.originalEvent.pointerType.toUpperCase()]?n.touchStartX=t.originalEvent.clientX:n._pointerEvent||(n.touchStartX=t.originalEvent.touches[0].clientX)},i=function(t){n._pointerEvent&&at[t.originalEvent.pointerType.toUpperCase()]&&(n.touchDeltaX=t.originalEvent.clientX-n.touchStartX),n._handleSwipe(),"hover"===n._config.pause&&(n.pause(),n.touchTimeout&&clearTimeout(n.touchTimeout),n.touchTimeout=setTimeout(function(t){return n.cycle(t)},500+n._config.interval))};g(this._element.querySelectorAll(nt)).on(Q.DRAG_START,function(t){return t.preventDefault()}),this._pointerEvent?(g(this._element).on(Q.POINTERDOWN,function(t){return e(t)}),g(this._element).on(Q.POINTERUP,function(t){return i(t)}),this._element.classList.add(J)):(g(this._element).on(Q.TOUCHSTART,function(t){return e(t)}),g(this._element).on(Q.TOUCHMOVE,function(t){var e;(e=t).originalEvent.touches&&1<e.originalEvent.touches.length?n.touchDeltaX=0:n.touchDeltaX=e.originalEvent.touches[0].clientX-n.touchStartX}),g(this._element).on(Q.TOUCHEND,function(t){return i(t)}))}},t._keydown=function(t){if(!/input|textarea/i.test(t.target.tagName))switch(t.which){case 37:t.preventDefault(),this.prev();break;case 39:t.preventDefault(),this.next()}},t._getItemIndex=function(t){return this._items=t&&t.parentNode?[].slice.call(t.parentNode.querySelectorAll(et)):[],this._items.indexOf(t)},t._getItemByDirection=function(t,e){var n=t===W,i=t===q,o=this._getItemIndex(e),r=this._items.length-1;if((i&&0===o||n&&o===r)&&!this._config.wrap)return e;var s=(o+(t===q?-1:1))%this._items.length;return-1===s?this._items[this._items.length-1]:this._items[s]},t._triggerSlideEvent=function(t,e){var n=this._getItemIndex(t),i=this._getItemIndex(this._element.querySelector(tt)),o=g.Event(Q.SLIDE,{relatedTarget:t,direction:e,from:i,to:n});return g(this._element).trigger(o),o},t._setActiveIndicatorElement=function(t){if(this._indicatorsElement){var e=[].slice.call(this._indicatorsElement.querySelectorAll(Z));g(e).removeClass(V);var n=this._indicatorsElement.children[this._getItemIndex(t)];n&&g(n).addClass(V)}},t._slide=function(t,e){var n,i,o,r=this,s=this._element.querySelector(tt),a=this._getItemIndex(s),l=e||s&&this._getItemByDirection(t,s),c=this._getItemIndex(l),h=Boolean(this._interval);if(o=t===W?(n=X,i=$,M):(n=z,i=G,K),l&&g(l).hasClass(V))this._isSliding=!1;else if(!this._triggerSlideEvent(l,o).isDefaultPrevented()&&s&&l){this._isSliding=!0,h&&this.pause(),this._setActiveIndicatorElement(l);var u=g.Event(Q.SLID,{relatedTarget:l,direction:o,from:a,to:c});if(g(this._element).hasClass(Y)){g(l).addClass(i),_.reflow(l),g(s).addClass(n),g(l).addClass(n);var f=parseInt(l.getAttribute("data-interval"),10);this._config.interval=f?(this._config.defaultInterval=this._config.defaultInterval||this._config.interval,f):this._config.defaultInterval||this._config.interval;var d=_.getTransitionDurationFromElement(s);g(s).one(_.TRANSITION_END,function(){g(l).removeClass(n+" "+i).addClass(V),g(s).removeClass(V+" "+i+" "+n),r._isSliding=!1,setTimeout(function(){return g(r._element).trigger(u)},0)}).emulateTransitionEnd(d)}else g(s).removeClass(V),g(l).addClass(V),this._isSliding=!1,g(this._element).trigger(u);h&&this.cycle()}},r._jQueryInterface=function(i){return this.each(function(){var t=g(this).data(j),e=l({},F,g(this).data());"object"==typeof i&&(e=l({},e,i));var n="string"==typeof i?i:e.slide;if(t||(t=new r(this,e),g(this).data(j,t)),"number"==typeof i)t.to(i);else if("string"==typeof n){if("undefined"==typeof t[n])throw new TypeError('No method named "'+n+'"');t[n]()}else e.interval&&e.ride&&(t.pause(),t.cycle())})},r._dataApiClickHandler=function(t){var e=_.getSelectorFromElement(this);if(e){var n=g(e)[0];if(n&&g(n).hasClass(B)){var i=l({},g(n).data(),g(this).data()),o=this.getAttribute("data-slide-to");o&&(i.interval=!1),r._jQueryInterface.call(g(n),i),o&&g(n).data(j).to(o),t.preventDefault()}}},s(r,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return F}}]),r}();g(document).on(Q.CLICK_DATA_API,rt,lt._dataApiClickHandler),g(window).on(Q.LOAD_DATA_API,function(){for(var t=[].slice.call(document.querySelectorAll(st)),e=0,n=t.length;e<n;e++){var i=g(t[e]);lt._jQueryInterface.call(i,i.data())}}),g.fn[L]=lt._jQueryInterface,g.fn[L].Constructor=lt,g.fn[L].noConflict=function(){return g.fn[L]=x,lt._jQueryInterface};var ct="collapse",ht="bs.collapse",ut="."+ht,ft=g.fn[ct],dt={toggle:!0,parent:""},gt={toggle:"boolean",parent:"(string|element)"},_t={SHOW:"show"+ut,SHOWN:"shown"+ut,HIDE:"hide"+ut,HIDDEN:"hidden"+ut,CLICK_DATA_API:"click"+ut+".data-api"},mt="show",pt="collapse",vt="collapsing",yt="collapsed",Et="width",Ct="height",Tt=".show, .collapsing",St='[data-toggle="collapse"]',bt=function(){function a(e,t){this._isTransitioning=!1,this._element=e,this._config=this._getConfig(t),this._triggerArray=[].slice.call(document.querySelectorAll('[data-toggle="collapse"][href="#'+e.id+'"],[data-toggle="collapse"][data-target="#'+e.id+'"]'));for(var n=[].slice.call(document.querySelectorAll(St)),i=0,o=n.length;i<o;i++){var r=n[i],s=_.getSelectorFromElement(r),a=[].slice.call(document.querySelectorAll(s)).filter(function(t){return t===e});null!==s&&0<a.length&&(this._selector=s,this._triggerArray.push(r))}this._parent=this._config.parent?this._getParent():null,this._config.parent||this._addAriaAndCollapsedClass(this._element,this._triggerArray),this._config.toggle&&this.toggle()}var t=a.prototype;return t.toggle=function(){g(this._element).hasClass(mt)?this.hide():this.show()},t.show=function(){var t,e,n=this;if(!this._isTransitioning&&!g(this._element).hasClass(mt)&&(this._parent&&0===(t=[].slice.call(this._parent.querySelectorAll(Tt)).filter(function(t){return"string"==typeof n._config.parent?t.getAttribute("data-parent")===n._config.parent:t.classList.contains(pt)})).length&&(t=null),!(t&&(e=g(t).not(this._selector).data(ht))&&e._isTransitioning))){var i=g.Event(_t.SHOW);if(g(this._element).trigger(i),!i.isDefaultPrevented()){t&&(a._jQueryInterface.call(g(t).not(this._selector),"hide"),e||g(t).data(ht,null));var o=this._getDimension();g(this._element).removeClass(pt).addClass(vt),this._element.style[o]=0,this._triggerArray.length&&g(this._triggerArray).removeClass(yt).attr("aria-expanded",!0),this.setTransitioning(!0);var r="scroll"+(o[0].toUpperCase()+o.slice(1)),s=_.getTransitionDurationFromElement(this._element);g(this._element).one(_.TRANSITION_END,function(){g(n._element).removeClass(vt).addClass(pt).addClass(mt),n._element.style[o]="",n.setTransitioning(!1),g(n._element).trigger(_t.SHOWN)}).emulateTransitionEnd(s),this._element.style[o]=this._element[r]+"px"}}},t.hide=function(){var t=this;if(!this._isTransitioning&&g(this._element).hasClass(mt)){var e=g.Event(_t.HIDE);if(g(this._element).trigger(e),!e.isDefaultPrevented()){var n=this._getDimension();this._element.style[n]=this._element.getBoundingClientRect()[n]+"px",_.reflow(this._element),g(this._element).addClass(vt).removeClass(pt).removeClass(mt);var i=this._triggerArray.length;if(0<i)for(var o=0;o<i;o++){var r=this._triggerArray[o],s=_.getSelectorFromElement(r);if(null!==s)g([].slice.call(document.querySelectorAll(s))).hasClass(mt)||g(r).addClass(yt).attr("aria-expanded",!1)}this.setTransitioning(!0);this._element.style[n]="";var a=_.getTransitionDurationFromElement(this._element);g(this._element).one(_.TRANSITION_END,function(){t.setTransitioning(!1),g(t._element).removeClass(vt).addClass(pt).trigger(_t.HIDDEN)}).emulateTransitionEnd(a)}}},t.setTransitioning=function(t){this._isTransitioning=t},t.dispose=function(){g.removeData(this._element,ht),this._config=null,this._parent=null,this._element=null,this._triggerArray=null,this._isTransitioning=null},t._getConfig=function(t){return(t=l({},dt,t)).toggle=Boolean(t.toggle),_.typeCheckConfig(ct,t,gt),t},t._getDimension=function(){return g(this._element).hasClass(Et)?Et:Ct},t._getParent=function(){var t,n=this;_.isElement(this._config.parent)?(t=this._config.parent,"undefined"!=typeof this._config.parent.jquery&&(t=this._config.parent[0])):t=document.querySelector(this._config.parent);var e='[data-toggle="collapse"][data-parent="'+this._config.parent+'"]',i=[].slice.call(t.querySelectorAll(e));return g(i).each(function(t,e){n._addAriaAndCollapsedClass(a._getTargetFromElement(e),[e])}),t},t._addAriaAndCollapsedClass=function(t,e){var n=g(t).hasClass(mt);e.length&&g(e).toggleClass(yt,!n).attr("aria-expanded",n)},a._getTargetFromElement=function(t){var e=_.getSelectorFromElement(t);return e?document.querySelector(e):null},a._jQueryInterface=function(i){return this.each(function(){var t=g(this),e=t.data(ht),n=l({},dt,t.data(),"object"==typeof i&&i?i:{});if(!e&&n.toggle&&/show|hide/.test(i)&&(n.toggle=!1),e||(e=new a(this,n),t.data(ht,e)),"string"==typeof i){if("undefined"==typeof e[i])throw new TypeError('No method named "'+i+'"');e[i]()}})},s(a,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return dt}}]),a}();g(document).on(_t.CLICK_DATA_API,St,function(t){"A"===t.currentTarget.tagName&&t.preventDefault();var n=g(this),e=_.getSelectorFromElement(this),i=[].slice.call(document.querySelectorAll(e));g(i).each(function(){var t=g(this),e=t.data(ht)?"toggle":n.data();bt._jQueryInterface.call(t,e)})}),g.fn[ct]=bt._jQueryInterface,g.fn[ct].Constructor=bt,g.fn[ct].noConflict=function(){return g.fn[ct]=ft,bt._jQueryInterface};var It="dropdown",Dt="bs.dropdown",wt="."+Dt,At=".data-api",Nt=g.fn[It],Ot=new RegExp("38|40|27"),kt={HIDE:"hide"+wt,HIDDEN:"hidden"+wt,SHOW:"show"+wt,SHOWN:"shown"+wt,CLICK:"click"+wt,CLICK_DATA_API:"click"+wt+At,KEYDOWN_DATA_API:"keydown"+wt+At,KEYUP_DATA_API:"keyup"+wt+At},Pt="disabled",Lt="show",jt="dropup",Ht="dropright",Rt="dropleft",xt="dropdown-menu-right",Ft="position-static",Ut='[data-toggle="dropdown"]',Wt=".dropdown form",qt=".dropdown-menu",Mt=".navbar-nav",Kt=".dropdown-menu .dropdown-item:not(.disabled):not(:disabled)",Qt="top-start",Bt="top-end",Vt="bottom-start",Yt="bottom-end",zt="right-start",Xt="left-start",$t={offset:0,flip:!0,boundary:"scrollParent",reference:"toggle",display:"dynamic"},Gt={offset:"(number|string|function)",flip:"boolean",boundary:"(string|element)",reference:"(string|element)",display:"string"},Jt=function(){function c(t,e){this._element=t,this._popper=null,this._config=this._getConfig(e),this._menu=this._getMenuElement(),this._inNavbar=this._detectNavbar(),this._addEventListeners()}var t=c.prototype;return t.toggle=function(){if(!this._element.disabled&&!g(this._element).hasClass(Pt)){var t=c._getParentFromElement(this._element),e=g(this._menu).hasClass(Lt);if(c._clearMenus(),!e){var n={relatedTarget:this._element},i=g.Event(kt.SHOW,n);if(g(t).trigger(i),!i.isDefaultPrevented()){if(!this._inNavbar){if("undefined"==typeof u)throw new TypeError("Bootstrap's dropdowns require Popper.js (https://popper.js.org/)");var o=this._element;"parent"===this._config.reference?o=t:_.isElement(this._config.reference)&&(o=this._config.reference,"undefined"!=typeof this._config.reference.jquery&&(o=this._config.reference[0])),"scrollParent"!==this._config.boundary&&g(t).addClass(Ft),this._popper=new u(o,this._menu,this._getPopperConfig())}"ontouchstart"in document.documentElement&&0===g(t).closest(Mt).length&&g(document.body).children().on("mouseover",null,g.noop),this._element.focus(),this._element.setAttribute("aria-expanded",!0),g(this._menu).toggleClass(Lt),g(t).toggleClass(Lt).trigger(g.Event(kt.SHOWN,n))}}}},t.show=function(){if(!(this._element.disabled||g(this._element).hasClass(Pt)||g(this._menu).hasClass(Lt))){var t={relatedTarget:this._element},e=g.Event(kt.SHOW,t),n=c._getParentFromElement(this._element);g(n).trigger(e),e.isDefaultPrevented()||(g(this._menu).toggleClass(Lt),g(n).toggleClass(Lt).trigger(g.Event(kt.SHOWN,t)))}},t.hide=function(){if(!this._element.disabled&&!g(this._element).hasClass(Pt)&&g(this._menu).hasClass(Lt)){var t={relatedTarget:this._element},e=g.Event(kt.HIDE,t),n=c._getParentFromElement(this._element);g(n).trigger(e),e.isDefaultPrevented()||(g(this._menu).toggleClass(Lt),g(n).toggleClass(Lt).trigger(g.Event(kt.HIDDEN,t)))}},t.dispose=function(){g.removeData(this._element,Dt),g(this._element).off(wt),this._element=null,(this._menu=null)!==this._popper&&(this._popper.destroy(),this._popper=null)},t.update=function(){this._inNavbar=this._detectNavbar(),null!==this._popper&&this._popper.scheduleUpdate()},t._addEventListeners=function(){var e=this;g(this._element).on(kt.CLICK,function(t){t.preventDefault(),t.stopPropagation(),e.toggle()})},t._getConfig=function(t){return t=l({},this.constructor.Default,g(this._element).data(),t),_.typeCheckConfig(It,t,this.constructor.DefaultType),t},t._getMenuElement=function(){if(!this._menu){var t=c._getParentFromElement(this._element);t&&(this._menu=t.querySelector(qt))}return this._menu},t._getPlacement=function(){var t=g(this._element.parentNode),e=Vt;return t.hasClass(jt)?(e=Qt,g(this._menu).hasClass(xt)&&(e=Bt)):t.hasClass(Ht)?e=zt:t.hasClass(Rt)?e=Xt:g(this._menu).hasClass(xt)&&(e=Yt),e},t._detectNavbar=function(){return 0<g(this._element).closest(".navbar").length},t._getOffset=function(){var e=this,t={};return"function"==typeof this._config.offset?t.fn=function(t){return t.offsets=l({},t.offsets,e._config.offset(t.offsets,e._element)||{}),t}:t.offset=this._config.offset,t},t._getPopperConfig=function(){var t={placement:this._getPlacement(),modifiers:{offset:this._getOffset(),flip:{enabled:this._config.flip},preventOverflow:{boundariesElement:this._config.boundary}}};return"static"===this._config.display&&(t.modifiers.applyStyle={enabled:!1}),t},c._jQueryInterface=function(e){return this.each(function(){var t=g(this).data(Dt);if(t||(t=new c(this,"object"==typeof e?e:null),g(this).data(Dt,t)),"string"==typeof e){if("undefined"==typeof t[e])throw new TypeError('No method named "'+e+'"');t[e]()}})},c._clearMenus=function(t){if(!t||3!==t.which&&("keyup"!==t.type||9===t.which))for(var e=[].slice.call(document.querySelectorAll(Ut)),n=0,i=e.length;n<i;n++){var o=c._getParentFromElement(e[n]),r=g(e[n]).data(Dt),s={relatedTarget:e[n]};if(t&&"click"===t.type&&(s.clickEvent=t),r){var a=r._menu;if(g(o).hasClass(Lt)&&!(t&&("click"===t.type&&/input|textarea/i.test(t.target.tagName)||"keyup"===t.type&&9===t.which)&&g.contains(o,t.target))){var l=g.Event(kt.HIDE,s);g(o).trigger(l),l.isDefaultPrevented()||("ontouchstart"in document.documentElement&&g(document.body).children().off("mouseover",null,g.noop),e[n].setAttribute("aria-expanded","false"),g(a).removeClass(Lt),g(o).removeClass(Lt).trigger(g.Event(kt.HIDDEN,s)))}}}},c._getParentFromElement=function(t){var e,n=_.getSelectorFromElement(t);return n&&(e=document.querySelector(n)),e||t.parentNode},c._dataApiKeydownHandler=function(t){if((/input|textarea/i.test(t.target.tagName)?!(32===t.which||27!==t.which&&(40!==t.which&&38!==t.which||g(t.target).closest(qt).length)):Ot.test(t.which))&&(t.preventDefault(),t.stopPropagation(),!this.disabled&&!g(this).hasClass(Pt))){var e=c._getParentFromElement(this),n=g(e).hasClass(Lt);if(n&&(!n||27!==t.which&&32!==t.which)){var i=[].slice.call(e.querySelectorAll(Kt));if(0!==i.length){var o=i.indexOf(t.target);38===t.which&&0<o&&o--,40===t.which&&o<i.length-1&&o++,o<0&&(o=0),i[o].focus()}}else{if(27===t.which){var r=e.querySelector(Ut);g(r).trigger("focus")}g(this).trigger("click")}}},s(c,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return $t}},{key:"DefaultType",get:function(){return Gt}}]),c}();g(document).on(kt.KEYDOWN_DATA_API,Ut,Jt._dataApiKeydownHandler).on(kt.KEYDOWN_DATA_API,qt,Jt._dataApiKeydownHandler).on(kt.CLICK_DATA_API+" "+kt.KEYUP_DATA_API,Jt._clearMenus).on(kt.CLICK_DATA_API,Ut,function(t){t.preventDefault(),t.stopPropagation(),Jt._jQueryInterface.call(g(this),"toggle")}).on(kt.CLICK_DATA_API,Wt,function(t){t.stopPropagation()}),g.fn[It]=Jt._jQueryInterface,g.fn[It].Constructor=Jt,g.fn[It].noConflict=function(){return g.fn[It]=Nt,Jt._jQueryInterface};var Zt="modal",te="bs.modal",ee="."+te,ne=g.fn[Zt],ie={backdrop:!0,keyboard:!0,focus:!0,show:!0},oe={backdrop:"(boolean|string)",keyboard:"boolean",focus:"boolean",show:"boolean"},re={HIDE:"hide"+ee,HIDDEN:"hidden"+ee,SHOW:"show"+ee,SHOWN:"shown"+ee,FOCUSIN:"focusin"+ee,RESIZE:"resize"+ee,CLICK_DISMISS:"click.dismiss"+ee,KEYDOWN_DISMISS:"keydown.dismiss"+ee,MOUSEUP_DISMISS:"mouseup.dismiss"+ee,MOUSEDOWN_DISMISS:"mousedown.dismiss"+ee,CLICK_DATA_API:"click"+ee+".data-api"},se="modal-dialog-scrollable",ae="modal-scrollbar-measure",le="modal-backdrop",ce="modal-open",he="fade",ue="show",fe=".modal-dialog",de=".modal-body",ge='[data-toggle="modal"]',_e='[data-dismiss="modal"]',me=".fixed-top, .fixed-bottom, .is-fixed, .sticky-top",pe=".sticky-top",ve=function(){function o(t,e){this._config=this._getConfig(e),this._element=t,this._dialog=t.querySelector(fe),this._backdrop=null,this._isShown=!1,this._isBodyOverflowing=!1,this._ignoreBackdropClick=!1,this._isTransitioning=!1,this._scrollbarWidth=0}var t=o.prototype;return t.toggle=function(t){return this._isShown?this.hide():this.show(t)},t.show=function(t){var e=this;if(!this._isShown&&!this._isTransitioning){g(this._element).hasClass(he)&&(this._isTransitioning=!0);var n=g.Event(re.SHOW,{relatedTarget:t});g(this._element).trigger(n),this._isShown||n.isDefaultPrevented()||(this._isShown=!0,this._checkScrollbar(),this._setScrollbar(),this._adjustDialog(),this._setEscapeEvent(),this._setResizeEvent(),g(this._element).on(re.CLICK_DISMISS,_e,function(t){return e.hide(t)}),g(this._dialog).on(re.MOUSEDOWN_DISMISS,function(){g(e._element).one(re.MOUSEUP_DISMISS,function(t){g(t.target).is(e._element)&&(e._ignoreBackdropClick=!0)})}),this._showBackdrop(function(){return e._showElement(t)}))}},t.hide=function(t){var e=this;if(t&&t.preventDefault(),this._isShown&&!this._isTransitioning){var n=g.Event(re.HIDE);if(g(this._element).trigger(n),this._isShown&&!n.isDefaultPrevented()){this._isShown=!1;var i=g(this._element).hasClass(he);if(i&&(this._isTransitioning=!0),this._setEscapeEvent(),this._setResizeEvent(),g(document).off(re.FOCUSIN),g(this._element).removeClass(ue),g(this._element).off(re.CLICK_DISMISS),g(this._dialog).off(re.MOUSEDOWN_DISMISS),i){var o=_.getTransitionDurationFromElement(this._element);g(this._element).one(_.TRANSITION_END,function(t){return e._hideModal(t)}).emulateTransitionEnd(o)}else this._hideModal()}}},t.dispose=function(){[window,this._element,this._dialog].forEach(function(t){return g(t).off(ee)}),g(document).off(re.FOCUSIN),g.removeData(this._element,te),this._config=null,this._element=null,this._dialog=null,this._backdrop=null,this._isShown=null,this._isBodyOverflowing=null,this._ignoreBackdropClick=null,this._isTransitioning=null,this._scrollbarWidth=null},t.handleUpdate=function(){this._adjustDialog()},t._getConfig=function(t){return t=l({},ie,t),_.typeCheckConfig(Zt,t,oe),t},t._showElement=function(t){var e=this,n=g(this._element).hasClass(he);this._element.parentNode&&this._element.parentNode.nodeType===Node.ELEMENT_NODE||document.body.appendChild(this._element),this._element.style.display="block",this._element.removeAttribute("aria-hidden"),this._element.setAttribute("aria-modal",!0),g(this._dialog).hasClass(se)?this._dialog.querySelector(de).scrollTop=0:this._element.scrollTop=0,n&&_.reflow(this._element),g(this._element).addClass(ue),this._config.focus&&this._enforceFocus();var i=g.Event(re.SHOWN,{relatedTarget:t}),o=function(){e._config.focus&&e._element.focus(),e._isTransitioning=!1,g(e._element).trigger(i)};if(n){var r=_.getTransitionDurationFromElement(this._dialog);g(this._dialog).one(_.TRANSITION_END,o).emulateTransitionEnd(r)}else o()},t._enforceFocus=function(){var e=this;g(document).off(re.FOCUSIN).on(re.FOCUSIN,function(t){document!==t.target&&e._element!==t.target&&0===g(e._element).has(t.target).length&&e._element.focus()})},t._setEscapeEvent=function(){var e=this;this._isShown&&this._config.keyboard?g(this._element).on(re.KEYDOWN_DISMISS,function(t){27===t.which&&(t.preventDefault(),e.hide())}):this._isShown||g(this._element).off(re.KEYDOWN_DISMISS)},t._setResizeEvent=function(){var e=this;this._isShown?g(window).on(re.RESIZE,function(t){return e.handleUpdate(t)}):g(window).off(re.RESIZE)},t._hideModal=function(){var t=this;this._element.style.display="none",this._element.setAttribute("aria-hidden",!0),this._element.removeAttribute("aria-modal"),this._isTransitioning=!1,this._showBackdrop(function(){g(document.body).removeClass(ce),t._resetAdjustments(),t._resetScrollbar(),g(t._element).trigger(re.HIDDEN)})},t._removeBackdrop=function(){this._backdrop&&(g(this._backdrop).remove(),this._backdrop=null)},t._showBackdrop=function(t){var e=this,n=g(this._element).hasClass(he)?he:"";if(this._isShown&&this._config.backdrop){if(this._backdrop=document.createElement("div"),this._backdrop.className=le,n&&this._backdrop.classList.add(n),g(this._backdrop).appendTo(document.body),g(this._element).on(re.CLICK_DISMISS,function(t){e._ignoreBackdropClick?e._ignoreBackdropClick=!1:t.target===t.currentTarget&&("static"===e._config.backdrop?e._element.focus():e.hide())}),n&&_.reflow(this._backdrop),g(this._backdrop).addClass(ue),!t)return;if(!n)return void t();var i=_.getTransitionDurationFromElement(this._backdrop);g(this._backdrop).one(_.TRANSITION_END,t).emulateTransitionEnd(i)}else if(!this._isShown&&this._backdrop){g(this._backdrop).removeClass(ue);var o=function(){e._removeBackdrop(),t&&t()};if(g(this._element).hasClass(he)){var r=_.getTransitionDurationFromElement(this._backdrop);g(this._backdrop).one(_.TRANSITION_END,o).emulateTransitionEnd(r)}else o()}else t&&t()},t._adjustDialog=function(){var t=this._element.scrollHeight>document.documentElement.clientHeight;!this._isBodyOverflowing&&t&&(this._element.style.paddingLeft=this._scrollbarWidth+"px"),this._isBodyOverflowing&&!t&&(this._element.style.paddingRight=this._scrollbarWidth+"px")},t._resetAdjustments=function(){this._element.style.paddingLeft="",this._element.style.paddingRight=""},t._checkScrollbar=function(){var t=document.body.getBoundingClientRect();this._isBodyOverflowing=t.left+t.right<window.innerWidth,this._scrollbarWidth=this._getScrollbarWidth()},t._setScrollbar=function(){var o=this;if(this._isBodyOverflowing){var t=[].slice.call(document.querySelectorAll(me)),e=[].slice.call(document.querySelectorAll(pe));g(t).each(function(t,e){var n=e.style.paddingRight,i=g(e).css("padding-right");g(e).data("padding-right",n).css("padding-right",parseFloat(i)+o._scrollbarWidth+"px")}),g(e).each(function(t,e){var n=e.style.marginRight,i=g(e).css("margin-right");g(e).data("margin-right",n).css("margin-right",parseFloat(i)-o._scrollbarWidth+"px")});var n=document.body.style.paddingRight,i=g(document.body).css("padding-right");g(document.body).data("padding-right",n).css("padding-right",parseFloat(i)+this._scrollbarWidth+"px")}g(document.body).addClass(ce)},t._resetScrollbar=function(){var t=[].slice.call(document.querySelectorAll(me));g(t).each(function(t,e){var n=g(e).data("padding-right");g(e).removeData("padding-right"),e.style.paddingRight=n||""});var e=[].slice.call(document.querySelectorAll(""+pe));g(e).each(function(t,e){var n=g(e).data("margin-right");"undefined"!=typeof n&&g(e).css("margin-right",n).removeData("margin-right")});var n=g(document.body).data("padding-right");g(document.body).removeData("padding-right"),document.body.style.paddingRight=n||""},t._getScrollbarWidth=function(){var t=document.createElement("div");t.className=ae,document.body.appendChild(t);var e=t.getBoundingClientRect().width-t.clientWidth;return document.body.removeChild(t),e},o._jQueryInterface=function(n,i){return this.each(function(){var t=g(this).data(te),e=l({},ie,g(this).data(),"object"==typeof n&&n?n:{});if(t||(t=new o(this,e),g(this).data(te,t)),"string"==typeof n){if("undefined"==typeof t[n])throw new TypeError('No method named "'+n+'"');t[n](i)}else e.show&&t.show(i)})},s(o,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return ie}}]),o}();g(document).on(re.CLICK_DATA_API,ge,function(t){var e,n=this,i=_.getSelectorFromElement(this);i&&(e=document.querySelector(i));var o=g(e).data(te)?"toggle":l({},g(e).data(),g(this).data());"A"!==this.tagName&&"AREA"!==this.tagName||t.preventDefault();var r=g(e).one(re.SHOW,function(t){t.isDefaultPrevented()||r.one(re.HIDDEN,function(){g(n).is(":visible")&&n.focus()})});ve._jQueryInterface.call(g(e),o,this)}),g.fn[Zt]=ve._jQueryInterface,g.fn[Zt].Constructor=ve,g.fn[Zt].noConflict=function(){return g.fn[Zt]=ne,ve._jQueryInterface};var ye=["background","cite","href","itemtype","longdesc","poster","src","xlink:href"],Ee={"*":["class","dir","id","lang","role",/^aria-[\w-]*$/i],a:["target","href","title","rel"],area:[],b:[],br:[],col:[],code:[],div:[],em:[],hr:[],h1:[],h2:[],h3:[],h4:[],h5:[],h6:[],i:[],img:["src","alt","title","width","height"],li:[],ol:[],p:[],pre:[],s:[],small:[],span:[],sub:[],sup:[],strong:[],u:[],ul:[]},Ce=/^(?:(?:https?|mailto|ftp|tel|file):|[^&:/?#]*(?:[/?#]|$))/gi,Te=/^data:(?:image\/(?:bmp|gif|jpeg|jpg|png|tiff|webp)|video\/(?:mpeg|mp4|ogg|webm)|audio\/(?:mp3|oga|ogg|opus));base64,[a-z0-9+/]+=*$/i;function Se(t,s,e){if(0===t.length)return t;if(e&&"function"==typeof e)return e(t);for(var n=(new window.DOMParser).parseFromString(t,"text/html"),a=Object.keys(s),l=[].slice.call(n.body.querySelectorAll("*")),i=function(t,e){var n=l[t],i=n.nodeName.toLowerCase();if(-1===a.indexOf(n.nodeName.toLowerCase()))return n.parentNode.removeChild(n),"continue";var o=[].slice.call(n.attributes),r=[].concat(s["*"]||[],s[i]||[]);o.forEach(function(t){(function(t,e){var n=t.nodeName.toLowerCase();if(-1!==e.indexOf(n))return-1===ye.indexOf(n)||Boolean(t.nodeValue.match(Ce)||t.nodeValue.match(Te));for(var i=e.filter(function(t){return t instanceof RegExp}),o=0,r=i.length;o<r;o++)if(n.match(i[o]))return!0;return!1})(t,r)||n.removeAttribute(t.nodeName)})},o=0,r=l.length;o<r;o++)i(o);return n.body.innerHTML}var be="tooltip",Ie="bs.tooltip",De="."+Ie,we=g.fn[be],Ae="bs-tooltip",Ne=new RegExp("(^|\\s)"+Ae+"\\S+","g"),Oe=["sanitize","whiteList","sanitizeFn"],ke={animation:"boolean",template:"string",title:"(string|element|function)",trigger:"string",delay:"(number|object)",html:"boolean",selector:"(string|boolean)",placement:"(string|function)",offset:"(number|string|function)",container:"(string|element|boolean)",fallbackPlacement:"(string|array)",boundary:"(string|element)",sanitize:"boolean",sanitizeFn:"(null|function)",whiteList:"object"},Pe={AUTO:"auto",TOP:"top",RIGHT:"right",BOTTOM:"bottom",LEFT:"left"},Le={animation:!0,template:'<div class="tooltip" role="tooltip"><div class="arrow"></div><div class="tooltip-inner"></div></div>',trigger:"hover focus",title:"",delay:0,html:!1,selector:!1,placement:"top",offset:0,container:!1,fallbackPlacement:"flip",boundary:"scrollParent",sanitize:!0,sanitizeFn:null,whiteList:Ee},je="show",He="out",Re={HIDE:"hide"+De,HIDDEN:"hidden"+De,SHOW:"show"+De,SHOWN:"shown"+De,INSERTED:"inserted"+De,CLICK:"click"+De,FOCUSIN:"focusin"+De,FOCUSOUT:"focusout"+De,MOUSEENTER:"mouseenter"+De,MOUSELEAVE:"mouseleave"+De},xe="fade",Fe="show",Ue=".tooltip-inner",We=".arrow",qe="hover",Me="focus",Ke="click",Qe="manual",Be=function(){function i(t,e){if("undefined"==typeof u)throw new TypeError("Bootstrap's tooltips require Popper.js (https://popper.js.org/)");this._isEnabled=!0,this._timeout=0,this._hoverState="",this._activeTrigger={},this._popper=null,this.element=t,this.config=this._getConfig(e),this.tip=null,this._setListeners()}var t=i.prototype;return t.enable=function(){this._isEnabled=!0},t.disable=function(){this._isEnabled=!1},t.toggleEnabled=function(){this._isEnabled=!this._isEnabled},t.toggle=function(t){if(this._isEnabled)if(t){var e=this.constructor.DATA_KEY,n=g(t.currentTarget).data(e);n||(n=new this.constructor(t.currentTarget,this._getDelegateConfig()),g(t.currentTarget).data(e,n)),n._activeTrigger.click=!n._activeTrigger.click,n._isWithActiveTrigger()?n._enter(null,n):n._leave(null,n)}else{if(g(this.getTipElement()).hasClass(Fe))return void this._leave(null,this);this._enter(null,this)}},t.dispose=function(){clearTimeout(this._timeout),g.removeData(this.element,this.constructor.DATA_KEY),g(this.element).off(this.constructor.EVENT_KEY),g(this.element).closest(".modal").off("hide.bs.modal"),this.tip&&g(this.tip).remove(),this._isEnabled=null,this._timeout=null,this._hoverState=null,(this._activeTrigger=null)!==this._popper&&this._popper.destroy(),this._popper=null,this.element=null,this.config=null,this.tip=null},t.show=function(){var e=this;if("none"===g(this.element).css("display"))throw new Error("Please use show on visible elements");var t=g.Event(this.constructor.Event.SHOW);if(this.isWithContent()&&this._isEnabled){g(this.element).trigger(t);var n=_.findShadowRoot(this.element),i=g.contains(null!==n?n:this.element.ownerDocument.documentElement,this.element);if(t.isDefaultPrevented()||!i)return;var o=this.getTipElement(),r=_.getUID(this.constructor.NAME);o.setAttribute("id",r),this.element.setAttribute("aria-describedby",r),this.setContent(),this.config.animation&&g(o).addClass(xe);var s="function"==typeof this.config.placement?this.config.placement.call(this,o,this.element):this.config.placement,a=this._getAttachment(s);this.addAttachmentClass(a);var l=this._getContainer();g(o).data(this.constructor.DATA_KEY,this),g.contains(this.element.ownerDocument.documentElement,this.tip)||g(o).appendTo(l),g(this.element).trigger(this.constructor.Event.INSERTED),this._popper=new u(this.element,o,{placement:a,modifiers:{offset:this._getOffset(),flip:{behavior:this.config.fallbackPlacement},arrow:{element:We},preventOverflow:{boundariesElement:this.config.boundary}},onCreate:function(t){t.originalPlacement!==t.placement&&e._handlePopperPlacementChange(t)},onUpdate:function(t){return e._handlePopperPlacementChange(t)}}),g(o).addClass(Fe),"ontouchstart"in document.documentElement&&g(document.body).children().on("mouseover",null,g.noop);var c=function(){e.config.animation&&e._fixTransition();var t=e._hoverState;e._hoverState=null,g(e.element).trigger(e.constructor.Event.SHOWN),t===He&&e._leave(null,e)};if(g(this.tip).hasClass(xe)){var h=_.getTransitionDurationFromElement(this.tip);g(this.tip).one(_.TRANSITION_END,c).emulateTransitionEnd(h)}else c()}},t.hide=function(t){var e=this,n=this.getTipElement(),i=g.Event(this.constructor.Event.HIDE),o=function(){e._hoverState!==je&&n.parentNode&&n.parentNode.removeChild(n),e._cleanTipClass(),e.element.removeAttribute("aria-describedby"),g(e.element).trigger(e.constructor.Event.HIDDEN),null!==e._popper&&e._popper.destroy(),t&&t()};if(g(this.element).trigger(i),!i.isDefaultPrevented()){if(g(n).removeClass(Fe),"ontouchstart"in document.documentElement&&g(document.body).children().off("mouseover",null,g.noop),this._activeTrigger[Ke]=!1,this._activeTrigger[Me]=!1,this._activeTrigger[qe]=!1,g(this.tip).hasClass(xe)){var r=_.getTransitionDurationFromElement(n);g(n).one(_.TRANSITION_END,o).emulateTransitionEnd(r)}else o();this._hoverState=""}},t.update=function(){null!==this._popper&&this._popper.scheduleUpdate()},t.isWithContent=function(){return Boolean(this.getTitle())},t.addAttachmentClass=function(t){g(this.getTipElement()).addClass(Ae+"-"+t)},t.getTipElement=function(){return this.tip=this.tip||g(this.config.template)[0],this.tip},t.setContent=function(){var t=this.getTipElement();this.setElementContent(g(t.querySelectorAll(Ue)),this.getTitle()),g(t).removeClass(xe+" "+Fe)},t.setElementContent=function(t,e){"object"!=typeof e||!e.nodeType&&!e.jquery?this.config.html?(this.config.sanitize&&(e=Se(e,this.config.whiteList,this.config.sanitizeFn)),t.html(e)):t.text(e):this.config.html?g(e).parent().is(t)||t.empty().append(e):t.text(g(e).text())},t.getTitle=function(){var t=this.element.getAttribute("data-original-title");return t||(t="function"==typeof this.config.title?this.config.title.call(this.element):this.config.title),t},t._getOffset=function(){var e=this,t={};return"function"==typeof this.config.offset?t.fn=function(t){return t.offsets=l({},t.offsets,e.config.offset(t.offsets,e.element)||{}),t}:t.offset=this.config.offset,t},t._getContainer=function(){return!1===this.config.container?document.body:_.isElement(this.config.container)?g(this.config.container):g(document).find(this.config.container)},t._getAttachment=function(t){return Pe[t.toUpperCase()]},t._setListeners=function(){var i=this;this.config.trigger.split(" ").forEach(function(t){if("click"===t)g(i.element).on(i.constructor.Event.CLICK,i.config.selector,function(t){return i.toggle(t)});else if(t!==Qe){var e=t===qe?i.constructor.Event.MOUSEENTER:i.constructor.Event.FOCUSIN,n=t===qe?i.constructor.Event.MOUSELEAVE:i.constructor.Event.FOCUSOUT;g(i.element).on(e,i.config.selector,function(t){return i._enter(t)}).on(n,i.config.selector,function(t){return i._leave(t)})}}),g(this.element).closest(".modal").on("hide.bs.modal",function(){i.element&&i.hide()}),this.config.selector?this.config=l({},this.config,{trigger:"manual",selector:""}):this._fixTitle()},t._fixTitle=function(){var t=typeof this.element.getAttribute("data-original-title");(this.element.getAttribute("title")||"string"!==t)&&(this.element.setAttribute("data-original-title",this.element.getAttribute("title")||""),this.element.setAttribute("title",""))},t._enter=function(t,e){var n=this.constructor.DATA_KEY;(e=e||g(t.currentTarget).data(n))||(e=new this.constructor(t.currentTarget,this._getDelegateConfig()),g(t.currentTarget).data(n,e)),t&&(e._activeTrigger["focusin"===t.type?Me:qe]=!0),g(e.getTipElement()).hasClass(Fe)||e._hoverState===je?e._hoverState=je:(clearTimeout(e._timeout),e._hoverState=je,e.config.delay&&e.config.delay.show?e._timeout=setTimeout(function(){e._hoverState===je&&e.show()},e.config.delay.show):e.show())},t._leave=function(t,e){var n=this.constructor.DATA_KEY;(e=e||g(t.currentTarget).data(n))||(e=new this.constructor(t.currentTarget,this._getDelegateConfig()),g(t.currentTarget).data(n,e)),t&&(e._activeTrigger["focusout"===t.type?Me:qe]=!1),e._isWithActiveTrigger()||(clearTimeout(e._timeout),e._hoverState=He,e.config.delay&&e.config.delay.hide?e._timeout=setTimeout(function(){e._hoverState===He&&e.hide()},e.config.delay.hide):e.hide())},t._isWithActiveTrigger=function(){for(var t in this._activeTrigger)if(this._activeTrigger[t])return!0;return!1},t._getConfig=function(t){var e=g(this.element).data();return Object.keys(e).forEach(function(t){-1!==Oe.indexOf(t)&&delete e[t]}),"number"==typeof(t=l({},this.constructor.Default,e,"object"==typeof t&&t?t:{})).delay&&(t.delay={show:t.delay,hide:t.delay}),"number"==typeof t.title&&(t.title=t.title.toString()),"number"==typeof t.content&&(t.content=t.content.toString()),_.typeCheckConfig(be,t,this.constructor.DefaultType),t.sanitize&&(t.template=Se(t.template,t.whiteList,t.sanitizeFn)),t},t._getDelegateConfig=function(){var t={};if(this.config)for(var e in this.config)this.constructor.Default[e]!==this.config[e]&&(t[e]=this.config[e]);return t},t._cleanTipClass=function(){var t=g(this.getTipElement()),e=t.attr("class").match(Ne);null!==e&&e.length&&t.removeClass(e.join(""))},t._handlePopperPlacementChange=function(t){var e=t.instance;this.tip=e.popper,this._cleanTipClass(),this.addAttachmentClass(this._getAttachment(t.placement))},t._fixTransition=function(){var t=this.getTipElement(),e=this.config.animation;null===t.getAttribute("x-placement")&&(g(t).removeClass(xe),this.config.animation=!1,this.hide(),this.show(),this.config.animation=e)},i._jQueryInterface=function(n){return this.each(function(){var t=g(this).data(Ie),e="object"==typeof n&&n;if((t||!/dispose|hide/.test(n))&&(t||(t=new i(this,e),g(this).data(Ie,t)),"string"==typeof n)){if("undefined"==typeof t[n])throw new TypeError('No method named "'+n+'"');t[n]()}})},s(i,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return Le}},{key:"NAME",get:function(){return be}},{key:"DATA_KEY",get:function(){return Ie}},{key:"Event",get:function(){return Re}},{key:"EVENT_KEY",get:function(){return De}},{key:"DefaultType",get:function(){return ke}}]),i}();g.fn[be]=Be._jQueryInterface,g.fn[be].Constructor=Be,g.fn[be].noConflict=function(){return g.fn[be]=we,Be._jQueryInterface};var Ve="popover",Ye="bs.popover",ze="."+Ye,Xe=g.fn[Ve],$e="bs-popover",Ge=new RegExp("(^|\\s)"+$e+"\\S+","g"),Je=l({},Be.Default,{placement:"right",trigger:"click",content:"",template:'<div class="popover" role="tooltip"><div class="arrow"></div><h3 class="popover-header"></h3><div class="popover-body"></div></div>'}),Ze=l({},Be.DefaultType,{content:"(string|element|function)"}),tn="fade",en="show",nn=".popover-header",on=".popover-body",rn={HIDE:"hide"+ze,HIDDEN:"hidden"+ze,SHOW:"show"+ze,SHOWN:"shown"+ze,INSERTED:"inserted"+ze,CLICK:"click"+ze,FOCUSIN:"focusin"+ze,FOCUSOUT:"focusout"+ze,MOUSEENTER:"mouseenter"+ze,MOUSELEAVE:"mouseleave"+ze},sn=function(t){var e,n;function i(){return t.apply(this,arguments)||this}n=t,(e=i).prototype=Object.create(n.prototype),(e.prototype.constructor=e).__proto__=n;var o=i.prototype;return o.isWithContent=function(){return this.getTitle()||this._getContent()},o.addAttachmentClass=function(t){g(this.getTipElement()).addClass($e+"-"+t)},o.getTipElement=function(){return this.tip=this.tip||g(this.config.template)[0],this.tip},o.setContent=function(){var t=g(this.getTipElement());this.setElementContent(t.find(nn),this.getTitle());var e=this._getContent();"function"==typeof e&&(e=e.call(this.element)),this.setElementContent(t.find(on),e),t.removeClass(tn+" "+en)},o._getContent=function(){return this.element.getAttribute("data-content")||this.config.content},o._cleanTipClass=function(){var t=g(this.getTipElement()),e=t.attr("class").match(Ge);null!==e&&0<e.length&&t.removeClass(e.join(""))},i._jQueryInterface=function(n){return this.each(function(){var t=g(this).data(Ye),e="object"==typeof n?n:null;if((t||!/dispose|hide/.test(n))&&(t||(t=new i(this,e),g(this).data(Ye,t)),"string"==typeof n)){if("undefined"==typeof t[n])throw new TypeError('No method named "'+n+'"');t[n]()}})},s(i,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return Je}},{key:"NAME",get:function(){return Ve}},{key:"DATA_KEY",get:function(){return Ye}},{key:"Event",get:function(){return rn}},{key:"EVENT_KEY",get:function(){return ze}},{key:"DefaultType",get:function(){return Ze}}]),i}(Be);g.fn[Ve]=sn._jQueryInterface,g.fn[Ve].Constructor=sn,g.fn[Ve].noConflict=function(){return g.fn[Ve]=Xe,sn._jQueryInterface};var an="scrollspy",ln="bs.scrollspy",cn="."+ln,hn=g.fn[an],un={offset:10,method:"auto",target:""},fn={offset:"number",method:"string",target:"(string|element)"},dn={ACTIVATE:"activate"+cn,SCROLL:"scroll"+cn,LOAD_DATA_API:"load"+cn+".data-api"},gn="dropdown-item",_n="active",mn='[data-spy="scroll"]',pn=".nav, .list-group",vn=".nav-link",yn=".nav-item",En=".list-group-item",Cn=".dropdown",Tn=".dropdown-item",Sn=".dropdown-toggle",bn="offset",In="position",Dn=function(){function n(t,e){var n=this;this._element=t,this._scrollElement="BODY"===t.tagName?window:t,this._config=this._getConfig(e),this._selector=this._config.target+" "+vn+","+this._config.target+" "+En+","+this._config.target+" "+Tn,this._offsets=[],this._targets=[],this._activeTarget=null,this._scrollHeight=0,g(this._scrollElement).on(dn.SCROLL,function(t){return n._process(t)}),this.refresh(),this._process()}var t=n.prototype;return t.refresh=function(){var e=this,t=this._scrollElement===this._scrollElement.window?bn:In,o="auto"===this._config.method?t:this._config.method,r=o===In?this._getScrollTop():0;this._offsets=[],this._targets=[],this._scrollHeight=this._getScrollHeight(),[].slice.call(document.querySelectorAll(this._selector)).map(function(t){var e,n=_.getSelectorFromElement(t);if(n&&(e=document.querySelector(n)),e){var i=e.getBoundingClientRect();if(i.width||i.height)return[g(e)[o]().top+r,n]}return null}).filter(function(t){return t}).sort(function(t,e){return t[0]-e[0]}).forEach(function(t){e._offsets.push(t[0]),e._targets.push(t[1])})},t.dispose=function(){g.removeData(this._element,ln),g(this._scrollElement).off(cn),this._element=null,this._scrollElement=null,this._config=null,this._selector=null,this._offsets=null,this._targets=null,this._activeTarget=null,this._scrollHeight=null},t._getConfig=function(t){if("string"!=typeof(t=l({},un,"object"==typeof t&&t?t:{})).target){var e=g(t.target).attr("id");e||(e=_.getUID(an),g(t.target).attr("id",e)),t.target="#"+e}return _.typeCheckConfig(an,t,fn),t},t._getScrollTop=function(){return this._scrollElement===window?this._scrollElement.pageYOffset:this._scrollElement.scrollTop},t._getScrollHeight=function(){return this._scrollElement.scrollHeight||Math.max(document.body.scrollHeight,document.documentElement.scrollHeight)},t._getOffsetHeight=function(){return this._scrollElement===window?window.innerHeight:this._scrollElement.getBoundingClientRect().height},t._process=function(){var t=this._getScrollTop()+this._config.offset,e=this._getScrollHeight(),n=this._config.offset+e-this._getOffsetHeight();if(this._scrollHeight!==e&&this.refresh(),n<=t){var i=this._targets[this._targets.length-1];this._activeTarget!==i&&this._activate(i)}else{if(this._activeTarget&&t<this._offsets[0]&&0<this._offsets[0])return this._activeTarget=null,void this._clear();for(var o=this._offsets.length;o--;){this._activeTarget!==this._targets[o]&&t>=this._offsets[o]&&("undefined"==typeof this._offsets[o+1]||t<this._offsets[o+1])&&this._activate(this._targets[o])}}},t._activate=function(e){this._activeTarget=e,this._clear();var t=this._selector.split(",").map(function(t){return t+'[data-target="'+e+'"],'+t+'[href="'+e+'"]'}),n=g([].slice.call(document.querySelectorAll(t.join(","))));n.hasClass(gn)?(n.closest(Cn).find(Sn).addClass(_n),n.addClass(_n)):(n.addClass(_n),n.parents(pn).prev(vn+", "+En).addClass(_n),n.parents(pn).prev(yn).children(vn).addClass(_n)),g(this._scrollElement).trigger(dn.ACTIVATE,{relatedTarget:e})},t._clear=function(){[].slice.call(document.querySelectorAll(this._selector)).filter(function(t){return t.classList.contains(_n)}).forEach(function(t){return t.classList.remove(_n)})},n._jQueryInterface=function(e){return this.each(function(){var t=g(this).data(ln);if(t||(t=new n(this,"object"==typeof e&&e),g(this).data(ln,t)),"string"==typeof e){if("undefined"==typeof t[e])throw new TypeError('No method named "'+e+'"');t[e]()}})},s(n,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"Default",get:function(){return un}}]),n}();g(window).on(dn.LOAD_DATA_API,function(){for(var t=[].slice.call(document.querySelectorAll(mn)),e=t.length;e--;){var n=g(t[e]);Dn._jQueryInterface.call(n,n.data())}}),g.fn[an]=Dn._jQueryInterface,g.fn[an].Constructor=Dn,g.fn[an].noConflict=function(){return g.fn[an]=hn,Dn._jQueryInterface};var wn="bs.tab",An="."+wn,Nn=g.fn.tab,On={HIDE:"hide"+An,HIDDEN:"hidden"+An,SHOW:"show"+An,SHOWN:"shown"+An,CLICK_DATA_API:"click"+An+".data-api"},kn="dropdown-menu",Pn="active",Ln="disabled",jn="fade",Hn="show",Rn=".dropdown",xn=".nav, .list-group",Fn=".active",Un="> li > .active",Wn='[data-toggle="tab"], [data-toggle="pill"], [data-toggle="list"]',qn=".dropdown-toggle",Mn="> .dropdown-menu .active",Kn=function(){function i(t){this._element=t}var t=i.prototype;return t.show=function(){var n=this;if(!(this._element.parentNode&&this._element.parentNode.nodeType===Node.ELEMENT_NODE&&g(this._element).hasClass(Pn)||g(this._element).hasClass(Ln))){var t,i,e=g(this._element).closest(xn)[0],o=_.getSelectorFromElement(this._element);if(e){var r="UL"===e.nodeName||"OL"===e.nodeName?Un:Fn;i=(i=g.makeArray(g(e).find(r)))[i.length-1]}var s=g.Event(On.HIDE,{relatedTarget:this._element}),a=g.Event(On.SHOW,{relatedTarget:i});if(i&&g(i).trigger(s),g(this._element).trigger(a),!a.isDefaultPrevented()&&!s.isDefaultPrevented()){o&&(t=document.querySelector(o)),this._activate(this._element,e);var l=function(){var t=g.Event(On.HIDDEN,{relatedTarget:n._element}),e=g.Event(On.SHOWN,{relatedTarget:i});g(i).trigger(t),g(n._element).trigger(e)};t?this._activate(t,t.parentNode,l):l()}}},t.dispose=function(){g.removeData(this._element,wn),this._element=null},t._activate=function(t,e,n){var i=this,o=(!e||"UL"!==e.nodeName&&"OL"!==e.nodeName?g(e).children(Fn):g(e).find(Un))[0],r=n&&o&&g(o).hasClass(jn),s=function(){return i._transitionComplete(t,o,n)};if(o&&r){var a=_.getTransitionDurationFromElement(o);g(o).removeClass(Hn).one(_.TRANSITION_END,s).emulateTransitionEnd(a)}else s()},t._transitionComplete=function(t,e,n){if(e){g(e).removeClass(Pn);var i=g(e.parentNode).find(Mn)[0];i&&g(i).removeClass(Pn),"tab"===e.getAttribute("role")&&e.setAttribute("aria-selected",!1)}if(g(t).addClass(Pn),"tab"===t.getAttribute("role")&&t.setAttribute("aria-selected",!0),_.reflow(t),t.classList.contains(jn)&&t.classList.add(Hn),t.parentNode&&g(t.parentNode).hasClass(kn)){var o=g(t).closest(Rn)[0];if(o){var r=[].slice.call(o.querySelectorAll(qn));g(r).addClass(Pn)}t.setAttribute("aria-expanded",!0)}n&&n()},i._jQueryInterface=function(n){return this.each(function(){var t=g(this),e=t.data(wn);if(e||(e=new i(this),t.data(wn,e)),"string"==typeof n){if("undefined"==typeof e[n])throw new TypeError('No method named "'+n+'"');e[n]()}})},s(i,null,[{key:"VERSION",get:function(){return"4.3.1"}}]),i}();g(document).on(On.CLICK_DATA_API,Wn,function(t){t.preventDefault(),Kn._jQueryInterface.call(g(this),"show")}),g.fn.tab=Kn._jQueryInterface,g.fn.tab.Constructor=Kn,g.fn.tab.noConflict=function(){return g.fn.tab=Nn,Kn._jQueryInterface};var Qn="toast",Bn="bs.toast",Vn="."+Bn,Yn=g.fn[Qn],zn={CLICK_DISMISS:"click.dismiss"+Vn,HIDE:"hide"+Vn,HIDDEN:"hidden"+Vn,SHOW:"show"+Vn,SHOWN:"shown"+Vn},Xn="fade",$n="hide",Gn="show",Jn="showing",Zn={animation:"boolean",autohide:"boolean",delay:"number"},ti={animation:!0,autohide:!0,delay:500},ei='[data-dismiss="toast"]',ni=function(){function i(t,e){this._element=t,this._config=this._getConfig(e),this._timeout=null,this._setListeners()}var t=i.prototype;return t.show=function(){var t=this;g(this._element).trigger(zn.SHOW),this._config.animation&&this._element.classList.add(Xn);var e=function(){t._element.classList.remove(Jn),t._element.classList.add(Gn),g(t._element).trigger(zn.SHOWN),t._config.autohide&&t.hide()};if(this._element.classList.remove($n),this._element.classList.add(Jn),this._config.animation){var n=_.getTransitionDurationFromElement(this._element);g(this._element).one(_.TRANSITION_END,e).emulateTransitionEnd(n)}else e()},t.hide=function(t){var e=this;this._element.classList.contains(Gn)&&(g(this._element).trigger(zn.HIDE),t?this._close():this._timeout=setTimeout(function(){e._close()},this._config.delay))},t.dispose=function(){clearTimeout(this._timeout),this._timeout=null,this._element.classList.contains(Gn)&&this._element.classList.remove(Gn),g(this._element).off(zn.CLICK_DISMISS),g.removeData(this._element,Bn),this._element=null,this._config=null},t._getConfig=function(t){return t=l({},ti,g(this._element).data(),"object"==typeof t&&t?t:{}),_.typeCheckConfig(Qn,t,this.constructor.DefaultType),t},t._setListeners=function(){var t=this;g(this._element).on(zn.CLICK_DISMISS,ei,function(){return t.hide(!0)})},t._close=function(){var t=this,e=function(){t._element.classList.add($n),g(t._element).trigger(zn.HIDDEN)};if(this._element.classList.remove(Gn),this._config.animation){var n=_.getTransitionDurationFromElement(this._element);g(this._element).one(_.TRANSITION_END,e).emulateTransitionEnd(n)}else e()},i._jQueryInterface=function(n){return this.each(function(){var t=g(this),e=t.data(Bn);if(e||(e=new i(this,"object"==typeof n&&n),t.data(Bn,e)),"string"==typeof n){if("undefined"==typeof e[n])throw new TypeError('No method named "'+n+'"');e[n](this)}})},s(i,null,[{key:"VERSION",get:function(){return"4.3.1"}},{key:"DefaultType",get:function(){return Zn}},{key:"Default",get:function(){return ti}}]),i}();g.fn[Qn]=ni._jQueryInterface,g.fn[Qn].Constructor=ni,g.fn[Qn].noConflict=function(){return g.fn[Qn]=Yn,ni._jQueryInterface},function(){if("undefined"==typeof g)throw new TypeError("Bootstrap's JavaScript requires jQuery. jQuery must be included before Bootstrap's JavaScript.");var t=g.fn.jquery.split(" ")[0].split(".");if(t[0]<2&&t[1]<9||1===t[0]&&9===t[1]&&t[2]<1||4<=t[0])throw new Error("Bootstrap's JavaScript requires at least jQuery v1.9.1 but less than v4.0.0")}(),t.Util=_,t.Alert=p,t.Button=P,t.Carousel=lt,t.Collapse=bt,t.Dropdown=Jt,t.Modal=ve,t.Popover=sn,t.Scrollspy=Dn,t.Tab=Kn,t.Toast=ni,t.Tooltip=Be,Object.defineProperty(t,"__esModule",{value:!0})});
\ No newline at end of file

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/static/js/vendor/jquery-3.6.3.slim.min.js
Status: removed
Changes: +0 -2
Diff:
@@ -1,2 +0,0 @@
-/*! jQuery v3.6.3 -ajax,-ajax/jsonp,-ajax/load,-ajax/script,-ajax/var/location,-ajax/var/nonce,-ajax/var/rquery,-ajax/xhr,-manipulation/_evalUrl,-deprecated/ajax-event-alias,-effects,-effects/Tween,-effects/animatedSelector | (c) OpenJS Foundation and other contributors | jquery.org/license */
-!function(e,t){"use strict";"object"==typeof module&&"object"==typeof module.exports?module.exports=e.document?t(e,!0):function(e){if(!e.document)throw new Error("jQuery requires a window with a document");return t(e)}:t(e)}("undefined"!=typeof window?window:this,function(g,e){"use strict";var t=[],r=Object.getPrototypeOf,s=t.slice,v=t.flat?function(e){return t.flat.call(e)}:function(e){return t.concat.apply([],e)},u=t.push,i=t.indexOf,n={},o=n.toString,y=n.hasOwnProperty,a=y.toString,l=a.call(Object),m={},b=function(e){return"function"==typeof e&&"number"!=typeof e.nodeType&&"function"!=typeof e.item},x=function(e){return null!=e&&e===e.window},w=g.document,c={type:!0,src:!0,nonce:!0,noModule:!0};function C(e,t,n){var r,i,o=(n=n||w).createElement("script");if(o.text=e,t)for(r in c)(i=t[r]||t.getAttribute&&t.getAttribute(r))&&o.setAttribute(r,i);n.head.appendChild(o).parentNode.removeChild(o)}function T(e){return null==e?e+"":"object"==typeof e||"function"==typeof e?n[o.call(e)]||"object":typeof e}var f="3.6.3 -ajax,-ajax/jsonp,-ajax/load,-ajax/script,-ajax/var/location,-ajax/var/nonce,-ajax/var/rquery,-ajax/xhr,-manipulation/_evalUrl,-deprecated/ajax-event-alias,-effects,-effects/Tween,-effects/animatedSelector",E=function(e,t){return new E.fn.init(e,t)};function d(e){var t=!!e&&"length"in e&&e.length,n=T(e);return!b(e)&&!x(e)&&("array"===n||0===t||"number"==typeof t&&0<t&&t-1 in e)}E.fn=E.prototype={jquery:f,constructor:E,length:0,toArray:function(){return s.call(this)},get:function(e){return null==e?s.call(this):e<0?this[e+this.length]:this[e]},pushStack:function(e){var t=E.merge(this.constructor(),e);return t.prevObject=this,t},each:function(e){return E.each(this,e)},map:function(n){return this.pushStack(E.map(this,function(e,t){return n.call(e,t,e)}))},slice:function(){return this.pushStack(s.apply(this,arguments))},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},even:function(){return this.pushStack(E.grep(this,function(e,t){return(t+1)%2}))},odd:function(){return this.pushStack(E.grep(this,function(e,t){return t%2}))},eq:function(e){var t=this.length,n=+e+(e<0?t:0);return this.pushStack(0<=n&&n<t?[this[n]]:[])},end:function(){return this.prevObject||this.constructor()},push:u,sort:t.sort,splice:t.splice},E.extend=E.fn.extend=function(){var e,t,n,r,i,o,a=arguments[0]||{},s=1,u=arguments.length,l=!1;for("boolean"==typeof a&&(l=a,a=arguments[s]||{},s++),"object"==typeof a||b(a)||(a={}),s===u&&(a=this,s--);s<u;s++)if(null!=(e=arguments[s]))for(t in e)r=e[t],"__proto__"!==t&&a!==r&&(l&&r&&(E.isPlainObject(r)||(i=Array.isArray(r)))?(n=a[t],o=i&&!Array.isArray(n)?[]:i||E.isPlainObject(n)?n:{},i=!1,a[t]=E.extend(l,o,r)):void 0!==r&&(a[t]=r));return a},E.extend({expando:"jQuery"+(f+Math.random()).replace(/\D/g,""),isReady:!0,error:function(e){throw new Error(e)},noop:function(){},isPlainObject:function(e){var t,n;return!(!e||"[object Object]"!==o.call(e))&&(!(t=r(e))||"function"==typeof(n=y.call(t,"constructor")&&t.constructor)&&a.call(n)===l)},isEmptyObject:function(e){var t;for(t in e)return!1;return!0},globalEval:function(e,t,n){C(e,{nonce:t&&t.nonce},n)},each:function(e,t){var n,r=0;if(d(e)){for(n=e.length;r<n;r++)if(!1===t.call(e[r],r,e[r]))break}else for(r in e)if(!1===t.call(e[r],r,e[r]))break;return e},makeArray:function(e,t){var n=t||[];return null!=e&&(d(Object(e))?E.merge(n,"string"==typeof e?[e]:e):u.call(n,e)),n},inArray:function(e,t,n){return null==t?-1:i.call(t,e,n)},merge:function(e,t){for(var n=+t.length,r=0,i=e.length;r<n;r++)e[i++]=t[r];return e.length=i,e},grep:function(e,t,n){for(var r=[],i=0,o=e.length,a=!n;i<o;i++)!t(e[i],i)!==a&&r.push(e[i]);return r},map:function(e,t,n){var r,i,o=0,a=[];if(d(e))for(r=e.length;o<r;o++)null!=(i=t(e[o],o,n))&&a.push(i);else for(o in e)null!=(i=t(e[o],o,n))&&a.push(i);return v(a)},guid:1,support:m}),"function"==typeof Symbol&&(E.fn[Symbol.iterator]=t[Symbol.iterator]),E.each("Boolean Number String Function Array Date RegExp Object Error Symbol".split(" "),function(e,t){n["[object "+t+"]"]=t.toLowerCase()});var p=function(n){var e,p,x,o,i,h,f,g,w,u,l,C,T,a,E,v,s,c,y,S="sizzle"+1*new Date,d=n.document,A=0,r=0,m=ue(),b=ue(),N=ue(),k=ue(),D=function(e,t){return e===t&&(l=!0),0},L={}.hasOwnProperty,t=[],j=t.pop,q=t.push,O=t.push,P=t.slice,H=function(e,t){for(var n=0,r=e.length;n<r;n++)if(e[n]===t)return n;return-1},I="checked|selected|async|autofocus|autoplay|controls|defer|disabled|hidden|ismap|loop|multiple|open|readonly|required|scoped",R="[\\x20\\t\\r\\n\\f]",B="(?:\\\\[\\da-fA-F]{1,6}"+R+"?|\\\\[^\\r\\n\\f]|[\\w-]|[^\0-\\x7f])+",M="\\["+R+"*("+B+")(?:"+R+"*([*^$|!~]?=)"+R+"*(?:'((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\"|("+B+"))|)"+R+"*\\]",W=":("+B+")(?:\\((('((?:\\\\.|[^\\\\'])*)'|\"((?:\\\\.|[^\\\\\"])*)\")|((?:\\\\.|[^\\\\()[\\]]|"+M+")*)|.*)\\)|)",F=new RegExp(R+"+","g"),$=new RegExp("^"+R+"+|((?:^|[^\\\\])(?:\\\\.)*)"+R+"+$","g"),z=new RegExp("^"+R+"*,"+R+"*"),_=new RegExp("^"+R+"*([>+~]|"+R+")"+R+"*"),U=new RegExp(R+"|>"),V=new RegExp(W),X=new RegExp("^"+B+"$"),Q={ID:new RegExp("^#("+B+")"),CLASS:new RegExp("^\\.("+B+")"),TAG:new RegExp("^("+B+"|[*])"),ATTR:new RegExp("^"+M),PSEUDO:new RegExp("^"+W),CHILD:new RegExp("^:(only|first|last|nth|nth-last)-(child|of-type)(?:\\("+R+"*(even|odd|(([+-]|)(\\d*)n|)"+R+"*(?:([+-]|)"+R+"*(\\d+)|))"+R+"*\\)|)","i"),bool:new RegExp("^(?:"+I+")$","i"),needsContext:new RegExp("^"+R+"*[>+~]|:(even|odd|eq|gt|lt|nth|first|last)(?:\\("+R+"*((?:-\\d)?\\d*)"+R+"*\\)|)(?=[^-]|$)","i")},Y=/HTML$/i,G=/^(?:input|select|textarea|button)$/i,K=/^h\d$/i,J=/^[^{]+\{\s*\[native \w/,Z=/^(?:#([\w-]+)|(\w+)|\.([\w-]+))$/,ee=/[+~]/,te=new RegExp("\\\\[\\da-fA-F]{1,6}"+R+"?|\\\\([^\\r\\n\\f])","g"),ne=function(e,t){var n="0x"+e.slice(1)-65536;return t||(n<0?String.fromCharCode(n+65536):String.fromCharCode(n>>10|55296,1023&n|56320))},re=/([\0-\x1f\x7f]|^-?\d)|^-$|[^\0-\x1f\x7f-\uFFFF\w-]/g,ie=function(e,t){return t?"\0"===e?"\ufffd":e.slice(0,-1)+"\\"+e.charCodeAt(e.length-1).toString(16)+" ":"\\"+e},oe=function(){C()},ae=xe(function(e){return!0===e.disabled&&"fieldset"===e.nodeName.toLowerCase()},{dir:"parentNode",next:"legend"});try{O.apply(t=P.call(d.childNodes),d.childNodes),t[d.childNodes.length].nodeType}catch(e){O={apply:t.length?function(e,t){q.apply(e,P.call(t))}:function(e,t){var n=e.length,r=0;while(e[n++]=t[r++]);e.length=n-1}}}function se(t,e,n,r){var i,o,a,s,u,l,c,f=e&&e.ownerDocument,d=e?e.nodeType:9;if(n=n||[],"string"!=typeof t||!t||1!==d&&9!==d&&11!==d)return n;if(!r&&(C(e),e=e||T,E)){if(11!==d&&(u=Z.exec(t)))if(i=u[1]){if(9===d){if(!(a=e.getElementById(i)))return n;if(a.id===i)return n.push(a),n}else if(f&&(a=f.getElementById(i))&&y(e,a)&&a.id===i)return n.push(a),n}else{if(u[2])return O.apply(n,e.getElementsByTagName(t)),n;if((i=u[3])&&p.getElementsByClassName&&e.getElementsByClassName)return O.apply(n,e.getElementsByClassName(i)),n}if(p.qsa&&!k[t+" "]&&(!v||!v.test(t))&&(1!==d||"object"!==e.nodeName.toLowerCase())){if(c=t,f=e,1===d&&(U.test(t)||_.test(t))){(f=ee.test(t)&&ye(e.parentNode)||e)===e&&p.scope||((s=e.getAttribute("id"))?s=s.replace(re,ie):e.setAttribute("id",s=S)),o=(l=h(t)).length;while(o--)l[o]=(s?"#"+s:":scope")+" "+be(l[o]);c=l.join(",")}try{if(p.cssSupportsSelector&&!CSS.supports("selector(:is("+c+"))"))throw new Error;return O.apply(n,f.querySelectorAll(c)),n}catch(e){k(t,!0)}finally{s===S&&e.removeAttribute("id")}}}return g(t.replace($,"$1"),e,n,r)}function ue(){var r=[];return function e(t,n){return r.push(t+" ")>x.cacheLength&&delete e[r.shift()],e[t+" "]=n}}function le(e){return e[S]=!0,e}function ce(e){var t=T.createElement("fieldset");try{return!!e(t)}catch(e){return!1}finally{t.parentNode&&t.parentNode.removeChild(t),t=null}}function fe(e,t){var n=e.split("|"),r=n.length;while(r--)x.attrHandle[n[r]]=t}function de(e,t){var n=t&&e,r=n&&1===e.nodeType&&1===t.nodeType&&e.sourceIndex-t.sourceIndex;if(r)return r;if(n)while(n=n.nextSibling)if(n===t)return-1;return e?1:-1}function pe(t){return function(e){return"input"===e.nodeName.toLowerCase()&&e.type===t}}function he(n){return function(e){var t=e.nodeName.toLowerCase();return("input"===t||"button"===t)&&e.type===n}}function ge(t){return function(e){return"form"in e?e.parentNode&&!1===e.disabled?"label"in e?"label"in e.parentNode?e.parentNode.disabled===t:e.disabled===t:e.isDisabled===t||e.isDisabled!==!t&&ae(e)===t:e.disabled===t:"label"in e&&e.disabled===t}}function ve(a){return le(function(o){return o=+o,le(function(e,t){var n,r=a([],e.length,o),i=r.length;while(i--)e[n=r[i]]&&(e[n]=!(t[n]=e[n]))})})}function ye(e){return e&&"undefined"!=typeof e.getElementsByTagName&&e}for(e in p=se.support={},i=se.isXML=function(e){var t=e&&e.namespaceURI,n=e&&(e.ownerDocument||e).documentElement;return!Y.test(t||n&&n.nodeName||"HTML")},C=se.setDocument=function(e){var t,n,r=e?e.ownerDocument||e:d;return r!=T&&9===r.nodeType&&r.documentElement&&(a=(T=r).documentElement,E=!i(T),d!=T&&(n=T.defaultView)&&n.top!==n&&(n.addEventListener?n.addEventListener("unload",oe,!1):n.attachEvent&&n.attachEvent("onunload",oe)),p.scope=ce(function(e){return a.appendChild(e).appendChild(T.createElement("div")),"undefined"!=typeof e.querySelectorAll&&!e.querySelectorAll(":scope fieldset div").length}),p.cssSupportsSelector=ce(function(){return CSS.supports("selector(*)")&&T.querySelectorAll(":is(:jqfake)")&&!CSS.supports("selector(:is(*,:jqfake))")}),p.attributes=ce(function(e){return e.className="i",!e.getAttribute("className")}),p.getElementsByTagName=ce(function(e){return e.appendChild(T.createComment("")),!e.getElementsByTagName("*").length}),p.getElementsByClassName=J.test(T.getElementsByClassName),p.getById=ce(function(e){return a.appendChild(e).id=S,!T.getElementsByName||!T.getElementsByName(S).length}),p.getById?(x.filter.ID=function(e){var t=e.replace(te,ne);return function(e){return e.getAttribute("id")===t}},x.find.ID=function(e,t){if("undefined"!=typeof t.getElementById&&E){var n=t.getElementById(e);return n?[n]:[]}}):(x.filter.ID=function(e){var n=e.replace(te,ne);return function(e){var t="undefined"!=typeof e.getAttributeNode&&e.getAttributeNode("id");return t&&t.value===n}},x.find.ID=function(e,t){if("undefined"!=typeof t.getElementById&&E){var n,r,i,o=t.getElementById(e);if(o){if((n=o.getAttributeNode("id"))&&n.value===e)return[o];i=t.getElementsByName(e),r=0;while(o=i[r++])if((n=o.getAttributeNode("id"))&&n.value===e)return[o]}return[]}}),x.find.TAG=p.getElementsByTagName?function(e,t){return"undefined"!=typeof t.getElementsByTagName?t.getElementsByTagName(e):p.qsa?t.querySelectorAll(e):void 0}:function(e,t){var n,r=[],i=0,o=t.getElementsByTagName(e);if("*"===e){while(n=o[i++])1===n.nodeType&&r.push(n);return r}return o},x.find.CLASS=p.getElementsByClassName&&function(e,t){if("undefined"!=typeof t.getElementsByClassName&&E)return t.getElementsByClassName(e)},s=[],v=[],(p.qsa=J.test(T.querySelectorAll))&&(ce(function(e){var t;a.appendChild(e).innerHTML="<a id='"+S+"'></a><select id='"+S+"-\r\\' msallowcapture=''><option selected=''></option></select>",e.querySelectorAll("[msallowcapture^='']").length&&v.push("[*^$]="+R+"*(?:''|\"\")"),e.querySelectorAll("[selected]").length||v.push("\\["+R+"*(?:value|"+I+")"),e.querySelectorAll("[id~="+S+"-]").length||v.push("~="),(t=T.createElement("input")).setAttribute("name",""),e.appendChild(t),e.querySelectorAll("[name='']").length||v.push("\\["+R+"*name"+R+"*="+R+"*(?:''|\"\")"),e.querySelectorAll(":checked").length||v.push(":checked"),e.querySelectorAll("a#"+S+"+*").length||v.push(".#.+[+~]"),e.querySelectorAll("\\\f"),v.push("[\\r\\n\\f]")}),ce(function(e){e.innerHTML="<a href='' disabled='disabled'></a><select disabled='disabled'><option/></select>";var t=T.createElement("input");t.setAttribute("type","hidden"),e.appendChild(t).setAttribute("name","D"),e.querySelectorAll("[name=d]").length&&v.push("name"+R+"*[*^$|!~]?="),2!==e.querySelectorAll(":enabled").length&&v.push(":enabled",":disabled"),a.appendChild(e).disabled=!0,2!==e.querySelectorAll(":disabled").length&&v.push(":enabled",":disabled"),e.querySelectorAll("*,:x"),v.push(",.*:")})),(p.matchesSelector=J.test(c=a.matches||a.webkitMatchesSelector||a.mozMatchesSelector||a.oMatchesSelector||a.msMatchesSelector))&&ce(function(e){p.disconnectedMatch=c.call(e,"*"),c.call(e,"[s!='']:x"),s.push("!=",W)}),p.cssSupportsSelector||v.push(":has"),v=v.length&&new RegExp(v.join("|")),s=s.length&&new RegExp(s.join("|")),t=J.test(a.compareDocumentPosition),y=t||J.test(a.contains)?function(e,t){var n=9===e.nodeType&&e.documentElement||e,r=t&&t.parentNode;return e===r||!(!r||1!==r.nodeType||!(n.contains?n.contains(r):e.compareDocumentPosition&&16&e.compareDocumentPosition(r)))}:function(e,t){if(t)while(t=t.parentNode)if(t===e)return!0;return!1},D=t?function(e,t){if(e===t)return l=!0,0;var n=!e.compareDocumentPosition-!t.compareDocumentPosition;return n||(1&(n=(e.ownerDocument||e)==(t.ownerDocument||t)?e.compareDocumentPosition(t):1)||!p.sortDetached&&t.compareDocumentPosition(e)===n?e==T||e.ownerDocument==d&&y(d,e)?-1:t==T||t.ownerDocument==d&&y(d,t)?1:u?H(u,e)-H(u,t):0:4&n?-1:1)}:function(e,t){if(e===t)return l=!0,0;var n,r=0,i=e.parentNode,o=t.parentNode,a=[e],s=[t];if(!i||!o)return e==T?-1:t==T?1:i?-1:o?1:u?H(u,e)-H(u,t):0;if(i===o)return de(e,t);n=e;while(n=n.parentNode)a.unshift(n);n=t;while(n=n.parentNode)s.unshift(n);while(a[r]===s[r])r++;return r?de(a[r],s[r]):a[r]==d?-1:s[r]==d?1:0}),T},se.matches=function(e,t){return se(e,null,null,t)},se.matchesSelector=function(e,t){if(C(e),p.matchesSelector&&E&&!k[t+" "]&&(!s||!s.test(t))&&(!v||!v.test(t)))try{var n=c.call(e,t);if(n||p.disconnectedMatch||e.document&&11!==e.document.nodeType)return n}catch(e){k(t,!0)}return 0<se(t,T,null,[e]).length},se.contains=function(e,t){return(e.ownerDocument||e)!=T&&C(e),y(e,t)},se.attr=function(e,t){(e.ownerDocument||e)!=T&&C(e);var n=x.attrHandle[t.toLowerCase()],r=n&&L.call(x.attrHandle,t.toLowerCase())?n(e,t,!E):void 0;return void 0!==r?r:p.attributes||!E?e.getAttribute(t):(r=e.getAttributeNode(t))&&r.specified?r.value:null},se.escape=function(e){return(e+"").replace(re,ie)},se.error=function(e){throw new Error("Syntax error, unrecognized expression: "+e)},se.uniqueSort=function(e){var t,n=[],r=0,i=0;if(l=!p.detectDuplicates,u=!p.sortStable&&e.slice(0),e.sort(D),l){while(t=e[i++])t===e[i]&&(r=n.push(i));while(r--)e.splice(n[r],1)}return u=null,e},o=se.getText=function(e){var t,n="",r=0,i=e.nodeType;if(i){if(1===i||9===i||11===i){if("string"==typeof e.textContent)return e.textContent;for(e=e.firstChild;e;e=e.nextSibling)n+=o(e)}else if(3===i||4===i)return e.nodeValue}else while(t=e[r++])n+=o(t);return n},(x=se.selectors={cacheLength:50,createPseudo:le,match:Q,attrHandle:{},find:{},relative:{">":{dir:"parentNode",first:!0}," ":{dir:"parentNode"},"+":{dir:"previousSibling",first:!0},"~":{dir:"previousSibling"}},preFilter:{ATTR:function(e){return e[1]=e[1].replace(te,ne),e[3]=(e[3]||e[4]||e[5]||"").replace(te,ne),"~="===e[2]&&(e[3]=" "+e[3]+" "),e.slice(0,4)},CHILD:function(e){return e[1]=e[1].toLowerCase(),"nth"===e[1].slice(0,3)?(e[3]||se.error(e[0]),e[4]=+(e[4]?e[5]+(e[6]||1):2*("even"===e[3]||"odd"===e[3])),e[5]=+(e[7]+e[8]||"odd"===e[3])):e[3]&&se.error(e[0]),e},PSEUDO:function(e){var t,n=!e[6]&&e[2];return Q.CHILD.test(e[0])?null:(e[3]?e[2]=e[4]||e[5]||"":n&&V.test(n)&&(t=h(n,!0))&&(t=n.indexOf(")",n.length-t)-n.length)&&(e[0]=e[0].slice(0,t),e[2]=n.slice(0,t)),e.slice(0,3))}},filter:{TAG:function(e){var t=e.replace(te,ne).toLowerCase();return"*"===e?function(){return!0}:function(e){return e.nodeName&&e.nodeName.toLowerCase()===t}},CLASS:function(e){var t=m[e+" "];return t||(t=new RegExp("(^|"+R+")"+e+"("+R+"|$)"))&&m(e,function(e){return t.test("string"==typeof e.className&&e.className||"undefined"!=typeof e.getAttribute&&e.getAttribute("class")||"")})},ATTR:function(n,r,i){return function(e){var t=se.attr(e,n);return null==t?"!="===r:!r||(t+="","="===r?t===i:"!="===r?t!==i:"^="===r?i&&0===t.indexOf(i):"*="===r?i&&-1<t.indexOf(i):"$="===r?i&&t.slice(-i.length)===i:"~="===r?-1<(" "+t.replace(F," ")+" ").indexOf(i):"|="===r&&(t===i||t.slice(0,i.length+1)===i+"-"))}},CHILD:function(h,e,t,g,v){var y="nth"!==h.slice(0,3),m="last"!==h.slice(-4),b="of-type"===e;return 1===g&&0===v?function(e){return!!e.parentNode}:function(e,t,n){var r,i,o,a,s,u,l=y!==m?"nextSibling":"previousSibling",c=e.parentNode,f=b&&e.nodeName.toLowerCase(),d=!n&&!b,p=!1;if(c){if(y){while(l){a=e;while(a=a[l])if(b?a.nodeName.toLowerCase()===f:1===a.nodeType)return!1;u=l="only"===h&&!u&&"nextSibling"}return!0}if(u=[m?c.firstChild:c.lastChild],m&&d){p=(s=(r=(i=(o=(a=c)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===A&&r[1])&&r[2],a=s&&c.childNodes[s];while(a=++s&&a&&a[l]||(p=s=0)||u.pop())if(1===a.nodeType&&++p&&a===e){i[h]=[A,s,p];break}}else if(d&&(p=s=(r=(i=(o=(a=e)[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]||[])[0]===A&&r[1]),!1===p)while(a=++s&&a&&a[l]||(p=s=0)||u.pop())if((b?a.nodeName.toLowerCase()===f:1===a.nodeType)&&++p&&(d&&((i=(o=a[S]||(a[S]={}))[a.uniqueID]||(o[a.uniqueID]={}))[h]=[A,p]),a===e))break;return(p-=v)===g||p%g==0&&0<=p/g}}},PSEUDO:function(e,o){var t,a=x.pseudos[e]||x.setFilters[e.toLowerCase()]||se.error("unsupported pseudo: "+e);return a[S]?a(o):1<a.length?(t=[e,e,"",o],x.setFilters.hasOwnProperty(e.toLowerCase())?le(function(e,t){var n,r=a(e,o),i=r.length;while(i--)e[n=H(e,r[i])]=!(t[n]=r[i])}):function(e){return a(e,0,t)}):a}},pseudos:{not:le(function(e){var r=[],i=[],s=f(e.replace($,"$1"));return s[S]?le(function(e,t,n,r){var i,o=s(e,null,r,[]),a=e.length;while(a--)(i=o[a])&&(e[a]=!(t[a]=i))}):function(e,t,n){return r[0]=e,s(r,null,n,i),r[0]=null,!i.pop()}}),has:le(function(t){return function(e){return 0<se(t,e).length}}),contains:le(function(t){return t=t.replace(te,ne),function(e){return-1<(e.textContent||o(e)).indexOf(t)}}),lang:le(function(n){return X.test(n||"")||se.error("unsupported lang: "+n),n=n.replace(te,ne).toLowerCase(),function(e){var t;do{if(t=E?e.lang:e.getAttribute("xml:lang")||e.getAttribute("lang"))return(t=t.toLowerCase())===n||0===t.indexOf(n+"-")}while((e=e.parentNode)&&1===e.nodeType);return!1}}),target:function(e){var t=n.location&&n.location.hash;return t&&t.slice(1)===e.id},root:function(e){return e===a},focus:function(e){return e===T.activeElement&&(!T.hasFocus||T.hasFocus())&&!!(e.type||e.href||~e.tabIndex)},enabled:ge(!1),disabled:ge(!0),checked:function(e){var t=e.nodeName.toLowerCase();return"input"===t&&!!e.checked||"option"===t&&!!e.selected},selected:function(e){return e.parentNode&&e.parentNode.selectedIndex,!0===e.selected},empty:function(e){for(e=e.firstChild;e;e=e.nextSibling)if(e.nodeType<6)return!1;return!0},parent:function(e){return!x.pseudos.empty(e)},header:function(e){return K.test(e.nodeName)},input:function(e){return G.test(e.nodeName)},button:function(e){var t=e.nodeName.toLowerCase();return"input"===t&&"button"===e.type||"button"===t},text:function(e){var t;return"input"===e.nodeName.toLowerCase()&&"text"===e.type&&(null==(t=e.getAttribute("type"))||"text"===t.toLowerCase())},first:ve(function(){return[0]}),last:ve(function(e,t){return[t-1]}),eq:ve(function(e,t,n){return[n<0?n+t:n]}),even:ve(function(e,t){for(var n=0;n<t;n+=2)e.push(n);return e}),odd:ve(function(e,t){for(var n=1;n<t;n+=2)e.push(n);return e}),lt:ve(function(e,t,n){for(var r=n<0?n+t:t<n?t:n;0<=--r;)e.push(r);return e}),gt:ve(function(e,t,n){for(var r=n<0?n+t:n;++r<t;)e.push(r);return e})}}).pseudos.nth=x.pseudos.eq,{radio:!0,checkbox:!0,file:!0,password:!0,image:!0})x.pseudos[e]=pe(e);for(e in{submit:!0,reset:!0})x.pseudos[e]=he(e);function me(){}function be(e){for(var t=0,n=e.length,r="";t<n;t++)r+=e[t].value;return r}function xe(s,e,t){var u=e.dir,l=e.next,c=l||u,f=t&&"parentNode"===c,d=r++;return e.first?function(e,t,n){while(e=e[u])if(1===e.nodeType||f)return s(e,t,n);return!1}:function(e,t,n){var r,i,o,a=[A,d];if(n){while(e=e[u])if((1===e.nodeType||f)&&s(e,t,n))return!0}else while(e=e[u])if(1===e.nodeType||f)if(i=(o=e[S]||(e[S]={}))[e.uniqueID]||(o[e.uniqueID]={}),l&&l===e.nodeName.toLowerCase())e=e[u]||e;else{if((r=i[c])&&r[0]===A&&r[1]===d)return a[2]=r[2];if((i[c]=a)[2]=s(e,t,n))return!0}return!1}}function we(i){return 1<i.length?function(e,t,n){var r=i.length;while(r--)if(!i[r](e,t,n))return!1;return!0}:i[0]}function Ce(e,t,n,r,i){for(var o,a=[],s=0,u=e.length,l=null!=t;s<u;s++)(o=e[s])&&(n&&!n(o,r,i)||(a.push(o),l&&t.push(s)));return a}function Te(p,h,g,v,y,e){return v&&!v[S]&&(v=Te(v)),y&&!y[S]&&(y=Te(y,e)),le(function(e,t,n,r){var i,o,a,s=[],u=[],l=t.length,c=e||function(e,t,n){for(var r=0,i=t.length;r<i;r++)se(e,t[r],n);return n}(h||"*",n.nodeType?[n]:n,[]),f=!p||!e&&h?c:Ce(c,s,p,n,r),d=g?y||(e?p:l||v)?[]:t:f;if(g&&g(f,d,n,r),v){i=Ce(d,u),v(i,[],n,r),o=i.length;while(o--)(a=i[o])&&(d[u[o]]=!(f[u[o]]=a))}if(e){if(y||p){if(y){i=[],o=d.length;while(o--)(a=d[o])&&i.push(f[o]=a);y(null,d=[],i,r)}o=d.length;while(o--)(a=d[o])&&-1<(i=y?H(e,a):s[o])&&(e[i]=!(t[i]=a))}}else d=Ce(d===t?d.splice(l,d.length):d),y?y(null,t,d,r):O.apply(t,d)})}function Ee(e){for(var i,t,n,r=e.length,o=x.relative[e[0].type],a=o||x.relative[" "],s=o?1:0,u=xe(function(e){return e===i},a,!0),l=xe(function(e){return-1<H(i,e)},a,!0),c=[function(e,t,n){var r=!o&&(n||t!==w)||((i=t).nodeType?u(e,t,n):l(e,t,n));return i=null,r}];s<r;s++)if(t=x.relative[e[s].type])c=[xe(we(c),t)];else{if((t=x.filter[e[s].type].apply(null,e[s].matches))[S]){for(n=++s;n<r;n++)if(x.relative[e[n].type])break;return Te(1<s&&we(c),1<s&&be(e.slice(0,s-1).concat({value:" "===e[s-2].type?"*":""})).replace($,"$1"),t,s<n&&Ee(e.slice(s,n)),n<r&&Ee(e=e.slice(n)),n<r&&be(e))}c.push(t)}return we(c)}return me.prototype=x.filters=x.pseudos,x.setFilters=new me,h=se.tokenize=function(e,t){var n,r,i,o,a,s,u,l=b[e+" "];if(l)return t?0:l.slice(0);a=e,s=[],u=x.preFilter;while(a){for(o in n&&!(r=z.exec(a))||(r&&(a=a.slice(r[0].length)||a),s.push(i=[])),n=!1,(r=_.exec(a))&&(n=r.shift(),i.push({value:n,type:r[0].replace($," ")}),a=a.slice(n.length)),x.filter)!(r=Q[o].exec(a))||u[o]&&!(r=u[o](r))||(n=r.shift(),i.push({value:n,type:o,matches:r}),a=a.slice(n.length));if(!n)break}return t?a.length:a?se.error(e):b(e,s).slice(0)},f=se.compile=function(e,t){var n,v,y,m,b,r,i=[],o=[],a=N[e+" "];if(!a){t||(t=h(e)),n=t.length;while(n--)(a=Ee(t[n]))[S]?i.push(a):o.push(a);(a=N(e,(v=o,m=0<(y=i).length,b=0<v.length,r=function(e,t,n,r,i){var o,a,s,u=0,l="0",c=e&&[],f=[],d=w,p=e||b&&x.find.TAG("*",i),h=A+=null==d?1:Math.random()||.1,g=p.length;for(i&&(w=t==T||t||i);l!==g&&null!=(o=p[l]);l++){if(b&&o){a=0,t||o.ownerDocument==T||(C(o),n=!E);while(s=v[a++])if(s(o,t||T,n)){r.push(o);break}i&&(A=h)}m&&((o=!s&&o)&&u--,e&&c.push(o))}if(u+=l,m&&l!==u){a=0;while(s=y[a++])s(c,f,t,n);if(e){if(0<u)while(l--)c[l]||f[l]||(f[l]=j.call(r));f=Ce(f)}O.apply(r,f),i&&!e&&0<f.length&&1<u+y.length&&se.uniqueSort(r)}return i&&(A=h,w=d),c},m?le(r):r))).selector=e}return a},g=se.select=function(e,t,n,r){var i,o,a,s,u,l="function"==typeof e&&e,c=!r&&h(e=l.selector||e);if(n=n||[],1===c.length){if(2<(o=c[0]=c[0].slice(0)).length&&"ID"===(a=o[0]).type&&9===t.nodeType&&E&&x.relative[o[1].type]){if(!(t=(x.find.ID(a.matches[0].replace(te,ne),t)||[])[0]))return n;l&&(t=t.parentNode),e=e.slice(o.shift().value.length)}i=Q.needsContext.test(e)?0:o.length;while(i--){if(a=o[i],x.relative[s=a.type])break;if((u=x.find[s])&&(r=u(a.matches[0].replace(te,ne),ee.test(o[0].type)&&ye(t.parentNode)||t))){if(o.splice(i,1),!(e=r.length&&be(o)))return O.apply(n,r),n;break}}}return(l||f(e,c))(r,t,!E,n,!t||ee.test(e)&&ye(t.parentNode)||t),n},p.sortStable=S.split("").sort(D).join("")===S,p.detectDuplicates=!!l,C(),p.sortDetached=ce(function(e){return 1&e.compareDocumentPosition(T.createElement("fieldset"))}),ce(function(e){return e.innerHTML="<a href='#'></a>","#"===e.firstChild.getAttribute("href")})||fe("type|href|height|width",function(e,t,n){if(!n)return e.getAttribute(t,"type"===t.toLowerCase()?1:2)}),p.attributes&&ce(function(e){return e.innerHTML="<input/>",e.firstChild.setAttribute("value",""),""===e.firstChild.getAttribute("value")})||fe("value",function(e,t,n){if(!n&&"input"===e.nodeName.toLowerCase())return e.defaultValue}),ce(function(e){return null==e.getAttribute("disabled")})||fe(I,function(e,t,n){var r;if(!n)return!0===e[t]?t.toLowerCase():(r=e.getAttributeNode(t))&&r.specified?r.value:null}),se}(g);E.find=p,E.expr=p.selectors,E.expr[":"]=E.expr.pseudos,E.uniqueSort=E.unique=p.uniqueSort,E.text=p.getText,E.isXMLDoc=p.isXML,E.contains=p.contains,E.escapeSelector=p.escape;var h=function(e,t,n){var r=[],i=void 0!==n;while((e=e[t])&&9!==e.nodeType)if(1===e.nodeType){if(i&&E(e).is(n))break;r.push(e)}return r},S=function(e,t){for(var n=[];e;e=e.nextSibling)1===e.nodeType&&e!==t&&n.push(e);return n},A=E.expr.match.needsContext;function N(e,t){return e.nodeName&&e.nodeName.toLowerCase()===t.toLowerCase()}var k=/^<([a-z][^\/\0>:\x20\t\r\n\f]*)[\x20\t\r\n\f]*\/?>(?:<\/\1>|)$/i;function D(e,n,r){return b(n)?E.grep(e,function(e,t){return!!n.call(e,t,e)!==r}):n.nodeType?E.grep(e,function(e){return e===n!==r}):"string"!=typeof n?E.grep(e,function(e){return-1<i.call(n,e)!==r}):E.filter(n,e,r)}E.filter=function(e,t,n){var r=t[0];return n&&(e=":not("+e+")"),1===t.length&&1===r.nodeType?E.find.matchesSelector(r,e)?[r]:[]:E.find.matches(e,E.grep(t,function(e){return 1===e.nodeType}))},E.fn.extend({find:function(e){var t,n,r=this.length,i=this;if("string"!=typeof e)return this.pushStack(E(e).filter(function(){for(t=0;t<r;t++)if(E.contains(i[t],this))return!0}));for(n=this.pushStack([]),t=0;t<r;t++)E.find(e,i[t],n);return 1<r?E.uniqueSort(n):n},filter:function(e){return this.pushStack(D(this,e||[],!1))},not:function(e){return this.pushStack(D(this,e||[],!0))},is:function(e){return!!D(this,"string"==typeof e&&A.test(e)?E(e):e||[],!1).length}});var L,j=/^(?:\s*(<[\w\W]+>)[^>]*|#([\w-]+))$/;(E.fn.init=function(e,t,n){var r,i;if(!e)return this;if(n=n||L,"string"==typeof e){if(!(r="<"===e[0]&&">"===e[e.length-1]&&3<=e.length?[null,e,null]:j.exec(e))||!r[1]&&t)return!t||t.jquery?(t||n).find(e):this.constructor(t).find(e);if(r[1]){if(t=t instanceof E?t[0]:t,E.merge(this,E.parseHTML(r[1],t&&t.nodeType?t.ownerDocument||t:w,!0)),k.test(r[1])&&E.isPlainObject(t))for(r in t)b(this[r])?this[r](t[r]):this.attr(r,t[r]);return this}return(i=w.getElementById(r[2]))&&(this[0]=i,this.length=1),this}return e.nodeType?(this[0]=e,this.length=1,this):b(e)?void 0!==n.ready?n.ready(e):e(E):E.makeArray(e,this)}).prototype=E.fn,L=E(w);var q=/^(?:parents|prev(?:Until|All))/,O={children:!0,contents:!0,next:!0,prev:!0};function P(e,t){while((e=e[t])&&1!==e.nodeType);return e}E.fn.extend({has:function(e){var t=E(e,this),n=t.length;return this.filter(function(){for(var e=0;e<n;e++)if(E.contains(this,t[e]))return!0})},closest:function(e,t){var n,r=0,i=this.length,o=[],a="string"!=typeof e&&E(e);if(!A.test(e))for(;r<i;r++)for(n=this[r];n&&n!==t;n=n.parentNode)if(n.nodeType<11&&(a?-1<a.index(n):1===n.nodeType&&E.find.matchesSelector(n,e))){o.push(n);break}return this.pushStack(1<o.length?E.uniqueSort(o):o)},index:function(e){return e?"string"==typeof e?i.call(E(e),this[0]):i.call(this,e.jquery?e[0]:e):this[0]&&this[0].parentNode?this.first().prevAll().length:-1},add:function(e,t){return this.pushStack(E.uniqueSort(E.merge(this.get(),E(e,t))))},addBack:function(e){return this.add(null==e?this.prevObject:this.prevObject.filter(e))}}),E.each({parent:function(e){var t=e.parentNode;return t&&11!==t.nodeType?t:null},parents:function(e){return h(e,"parentNode")},parentsUntil:function(e,t,n){return h(e,"parentNode",n)},next:function(e){return P(e,"nextSibling")},prev:function(e){return P(e,"previousSibling")},nextAll:function(e){return h(e,"nextSibling")},prevAll:function(e){return h(e,"previousSibling")},nextUntil:function(e,t,n){return h(e,"nextSibling",n)},prevUntil:function(e,t,n){return h(e,"previousSibling",n)},siblings:function(e){return S((e.parentNode||{}).firstChild,e)},children:function(e){return S(e.firstChild)},contents:function(e){return null!=e.contentDocument&&r(e.contentDocument)?e.contentDocument:(N(e,"template")&&(e=e.content||e),E.merge([],e.childNodes))}},function(r,i){E.fn[r]=function(e,t){var n=E.map(this,i,e);return"Until"!==r.slice(-5)&&(t=e),t&&"string"==typeof t&&(n=E.filter(t,n)),1<this.length&&(O[r]||E.uniqueSort(n),q.test(r)&&n.reverse()),this.pushStack(n)}});var H=/[^\x20\t\r\n\f]+/g;function I(e){return e}function R(e){throw e}function B(e,t,n,r){var i;try{e&&b(i=e.promise)?i.call(e).done(t).fail(n):e&&b(i=e.then)?i.call(e,t,n):t.apply(void 0,[e].slice(r))}catch(e){n.apply(void 0,[e])}}E.Callbacks=function(r){var e,n;r="string"==typeof r?(e=r,n={},E.each(e.match(H)||[],function(e,t){n[t]=!0}),n):E.extend({},r);var i,t,o,a,s=[],u=[],l=-1,c=function(){for(a=a||r.once,o=i=!0;u.length;l=-1){t=u.shift();while(++l<s.length)!1===s[l].apply(t[0],t[1])&&r.stopOnFalse&&(l=s.length,t=!1)}r.memory||(t=!1),i=!1,a&&(s=t?[]:"")},f={add:function(){return s&&(t&&!i&&(l=s.length-1,u.push(t)),function n(e){E.each(e,function(e,t){b(t)?r.unique&&f.has(t)||s.push(t):t&&t.length&&"string"!==T(t)&&n(t)})}(arguments),t&&!i&&c()),this},remove:function(){return E.each(arguments,function(e,t){var n;while(-1<(n=E.inArray(t,s,n)))s.splice(n,1),n<=l&&l--}),this},has:function(e){return e?-1<E.inArray(e,s):0<s.length},empty:function(){return s&&(s=[]),this},disable:function(){return a=u=[],s=t="",this},disabled:function(){return!s},lock:function(){return a=u=[],t||i||(s=t=""),this},locked:function(){return!!a},fireWith:function(e,t){return a||(t=[e,(t=t||[]).slice?t.slice():t],u.push(t),i||c()),this},fire:function(){return f.fireWith(this,arguments),this},fired:function(){return!!o}};return f},E.extend({Deferred:function(e){var o=[["notify","progress",E.Callbacks("memory"),E.Callbacks("memory"),2],["resolve","done",E.Callbacks("once memory"),E.Callbacks("once memory"),0,"resolved"],["reject","fail",E.Callbacks("once memory"),E.Callbacks("once memory"),1,"rejected"]],i="pending",a={state:function(){return i},always:function(){return s.done(arguments).fail(arguments),this},"catch":function(e){return a.then(null,e)},pipe:function(){var i=arguments;return E.Deferred(function(r){E.each(o,function(e,t){var n=b(i[t[4]])&&i[t[4]];s[t[1]](function(){var e=n&&n.apply(this,arguments);e&&b(e.promise)?e.promise().progress(r.notify).done(r.resolve).fail(r.reject):r[t[0]+"With"](this,n?[e]:arguments)})}),i=null}).promise()},then:function(t,n,r){var u=0;function l(i,o,a,s){return function(){var n=this,r=arguments,e=function(){var e,t;if(!(i<u)){if((e=a.apply(n,r))===o.promise())throw new TypeError("Thenable self-resolution");t=e&&("object"==typeof e||"function"==typeof e)&&e.then,b(t)?s?t.call(e,l(u,o,I,s),l(u,o,R,s)):(u++,t.call(e,l(u,o,I,s),l(u,o,R,s),l(u,o,I,o.notifyWith))):(a!==I&&(n=void 0,r=[e]),(s||o.resolveWith)(n,r))}},t=s?e:function(){try{e()}catch(e){E.Deferred.exceptionHook&&E.Deferred.exceptionHook(e,t.stackTrace),u<=i+1&&(a!==R&&(n=void 0,r=[e]),o.rejectWith(n,r))}};i?t():(E.Deferred.getStackHook&&(t.stackTrace=E.Deferred.getStackHook()),g.setTimeout(t))}}return E.Deferred(function(e){o[0][3].add(l(0,e,b(r)?r:I,e.notifyWith)),o[1][3].add(l(0,e,b(t)?t:I)),o[2][3].add(l(0,e,b(n)?n:R))}).promise()},promise:function(e){return null!=e?E.extend(e,a):a}},s={};return E.each(o,function(e,t){var n=t[2],r=t[5];a[t[1]]=n.add,r&&n.add(function(){i=r},o[3-e][2].disable,o[3-e][3].disable,o[0][2].lock,o[0][3].lock),n.add(t[3].fire),s[t[0]]=function(){return s[t[0]+"With"](this===s?void 0:this,arguments),this},s[t[0]+"With"]=n.fireWith}),a.promise(s),e&&e.call(s,s),s},when:function(e){var n=arguments.length,t=n,r=Array(t),i=s.call(arguments),o=E.Deferred(),a=function(t){return function(e){r[t]=this,i[t]=1<arguments.length?s.call(arguments):e,--n||o.resolveWith(r,i)}};if(n<=1&&(B(e,o.done(a(t)).resolve,o.reject,!n),"pending"===o.state()||b(i[t]&&i[t].then)))return o.then();while(t--)B(i[t],a(t),o.reject);return o.promise()}});var M=/^(Eval|Internal|Range|Reference|Syntax|Type|URI)Error$/;E.Deferred.exceptionHook=function(e,t){g.console&&g.console.warn&&e&&M.test(e.name)&&g.console.warn("jQuery.Deferred exception: "+e.message,e.stack,t)},E.readyException=function(e){g.setTimeout(function(){throw e})};var W=E.Deferred();function F(){w.removeEventListener("DOMContentLoaded",F),g.removeEventListener("load",F),E.ready()}E.fn.ready=function(e){return W.then(e)["catch"](function(e){E.readyException(e)}),this},E.extend({isReady:!1,readyWait:1,ready:function(e){(!0===e?--E.readyWait:E.isReady)||(E.isReady=!0)!==e&&0<--E.readyWait||W.resolveWith(w,[E])}}),E.ready.then=W.then,"complete"===w.readyState||"loading"!==w.readyState&&!w.documentElement.doScroll?g.setTimeout(E.ready):(w.addEventListener("DOMContentLoaded",F),g.addEventListener("load",F));var $=function(e,t,n,r,i,o,a){var s=0,u=e.length,l=null==n;if("object"===T(n))for(s in i=!0,n)$(e,t,s,n[s],!0,o,a);else if(void 0!==r&&(i=!0,b(r)||(a=!0),l&&(a?(t.call(e,r),t=null):(l=t,t=function(e,t,n){return l.call(E(e),n)})),t))for(;s<u;s++)t(e[s],n,a?r:r.call(e[s],s,t(e[s],n)));return i?e:l?t.call(e):u?t(e[0],n):o},z=/^-ms-/,_=/-([a-z])/g;function U(e,t){return t.toUpperCase()}function V(e){return e.replace(z,"ms-").replace(_,U)}var X=function(e){return 1===e.nodeType||9===e.nodeType||!+e.nodeType};function Q(){this.expando=E.expando+Q.uid++}Q.uid=1,Q.prototype={cache:function(e){var t=e[this.expando];return t||(t={},X(e)&&(e.nodeType?e[this.expando]=t:Object.defineProperty(e,this.expando,{value:t,configurable:!0}))),t},set:function(e,t,n){var r,i=this.cache(e);if("string"==typeof t)i[V(t)]=n;else for(r in t)i[V(r)]=t[r];return i},get:function(e,t){return void 0===t?this.cache(e):e[this.expando]&&e[this.expando][V(t)]},access:function(e,t,n){return void 0===t||t&&"string"==typeof t&&void 0===n?this.get(e,t):(this.set(e,t,n),void 0!==n?n:t)},remove:function(e,t){var n,r=e[this.expando];if(void 0!==r){if(void 0!==t){n=(t=Array.isArray(t)?t.map(V):(t=V(t))in r?[t]:t.match(H)||[]).length;while(n--)delete r[t[n]]}(void 0===t||E.isEmptyObject(r))&&(e.nodeType?e[this.expando]=void 0:delete e[this.expando])}},hasData:function(e){var t=e[this.expando];return void 0!==t&&!E.isEmptyObject(t)}};var Y=new Q,G=new Q,K=/^(?:\{[\w\W]*\}|\[[\w\W]*\])$/,J=/[A-Z]/g;function Z(e,t,n){var r,i;if(void 0===n&&1===e.nodeType)if(r="data-"+t.replace(J,"-$&").toLowerCase(),"string"==typeof(n=e.getAttribute(r))){try{n="true"===(i=n)||"false"!==i&&("null"===i?null:i===+i+""?+i:K.test(i)?JSON.parse(i):i)}catch(e){}G.set(e,t,n)}else n=void 0;return n}E.extend({hasData:function(e){return G.hasData(e)||Y.hasData(e)},data:function(e,t,n){return G.access(e,t,n)},removeData:function(e,t){G.remove(e,t)},_data:function(e,t,n){return Y.access(e,t,n)},_removeData:function(e,t){Y.remove(e,t)}}),E.fn.extend({data:function(n,e){var t,r,i,o=this[0],a=o&&o.attributes;if(void 0===n){if(this.length&&(i=G.get(o),1===o.nodeType&&!Y.get(o,"hasDataAttrs"))){t=a.length;while(t--)a[t]&&0===(r=a[t].name).indexOf("data-")&&(r=V(r.slice(5)),Z(o,r,i[r]));Y.set(o,"hasDataAttrs",!0)}return i}return"object"==typeof n?this.each(function(){G.set(this,n)}):$(this,function(e){var t;if(o&&void 0===e)return void 0!==(t=G.get(o,n))?t:void 0!==(t=Z(o,n))?t:void 0;this.each(function(){G.set(this,n,e)})},null,e,1<arguments.length,null,!0)},removeData:function(e){return this.each(function(){G.remove(this,e)})}}),E.extend({queue:function(e,t,n){var r;if(e)return t=(t||"fx")+"queue",r=Y.get(e,t),n&&(!r||Array.isArray(n)?r=Y.access(e,t,E.makeArray(n)):r.push(n)),r||[]},dequeue:function(e,t){t=t||"fx";var n=E.queue(e,t),r=n.length,i=n.shift(),o=E._queueHooks(e,t);"inprogress"===i&&(i=n.shift(),r--),i&&("fx"===t&&n.unshift("inprogress"),delete o.stop,i.call(e,function(){E.dequeue(e,t)},o)),!r&&o&&o.empty.fire()},_queueHooks:function(e,t){var n=t+"queueHooks";return Y.get(e,n)||Y.access(e,n,{empty:E.Callbacks("once memory").add(function(){Y.remove(e,[t+"queue",n])})})}}),E.fn.extend({queue:function(t,n){var e=2;return"string"!=typeof t&&(n=t,t="fx",e--),arguments.length<e?E.queue(this[0],t):void 0===n?this:this.each(function(){var e=E.queue(this,t,n);E._queueHooks(this,t),"fx"===t&&"inprogress"!==e[0]&&E.dequeue(this,t)})},dequeue:function(e){return this.each(function(){E.dequeue(this,e)})},clearQueue:function(e){return this.queue(e||"fx",[])},promise:function(e,t){var n,r=1,i=E.Deferred(),o=this,a=this.length,s=function(){--r||i.resolveWith(o,[o])};"string"!=typeof e&&(t=e,e=void 0),e=e||"fx";while(a--)(n=Y.get(o[a],e+"queueHooks"))&&n.empty&&(r++,n.empty.add(s));return s(),i.promise(t)}});var ee=/[+-]?(?:\d*\.|)\d+(?:[eE][+-]?\d+|)/.source,te=new RegExp("^(?:([+-])=|)("+ee+")([a-z%]*)$","i"),ne=["Top","Right","Bottom","Left"],re=w.documentElement,ie=function(e){return E.contains(e.ownerDocument,e)},oe={composed:!0};re.getRootNode&&(ie=function(e){return E.contains(e.ownerDocument,e)||e.getRootNode(oe)===e.ownerDocument});var ae=function(e,t){return"none"===(e=t||e).style.display||""===e.style.display&&ie(e)&&"none"===E.css(e,"display")};var se={};function ue(e,t){for(var n,r,i,o,a,s,u,l=[],c=0,f=e.length;c<f;c++)(r=e[c]).style&&(n=r.style.display,t?("none"===n&&(l[c]=Y.get(r,"display")||null,l[c]||(r.style.display="")),""===r.style.display&&ae(r)&&(l[c]=(u=a=o=void 0,a=(i=r).ownerDocument,s=i.nodeName,(u=se[s])||(o=a.body.appendChild(a.createElement(s)),u=E.css(o,"display"),o.parentNode.removeChild(o),"none"===u&&(u="block"),se[s]=u)))):"none"!==n&&(l[c]="none",Y.set(r,"display",n)));for(c=0;c<f;c++)null!=l[c]&&(e[c].style.display=l[c]);return e}E.fn.extend({show:function(){return ue(this,!0)},hide:function(){return ue(this)},toggle:function(e){return"boolean"==typeof e?e?this.show():this.hide():this.each(function(){ae(this)?E(this).show():E(this).hide()})}});var le,ce,fe=/^(?:checkbox|radio)$/i,de=/<([a-z][^\/\0>\x20\t\r\n\f]*)/i,pe=/^$|^module$|\/(?:java|ecma)script/i;le=w.createDocumentFragment().appendChild(w.createElement("div")),(ce=w.createElement("input")).setAttribute("type","radio"),ce.setAttribute("checked","checked"),ce.setAttribute("name","t"),le.appendChild(ce),m.checkClone=le.cloneNode(!0).cloneNode(!0).lastChild.checked,le.innerHTML="<textarea>x</textarea>",m.noCloneChecked=!!le.cloneNode(!0).lastChild.defaultValue,le.innerHTML="<option></option>",m.option=!!le.lastChild;var he={thead:[1,"<table>","</table>"],col:[2,"<table><colgroup>","</colgroup></table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],_default:[0,"",""]};function ge(e,t){var n;return n="undefined"!=typeof e.getElementsByTagName?e.getElementsByTagName(t||"*"):"undefined"!=typeof e.querySelectorAll?e.querySelectorAll(t||"*"):[],void 0===t||t&&N(e,t)?E.merge([e],n):n}function ve(e,t){for(var n=0,r=e.length;n<r;n++)Y.set(e[n],"globalEval",!t||Y.get(t[n],"globalEval"))}he.tbody=he.tfoot=he.colgroup=he.caption=he.thead,he.th=he.td,m.option||(he.optgroup=he.option=[1,"<select multiple='multiple'>","</select>"]);var ye=/<|&#?\w+;/;function me(e,t,n,r,i){for(var o,a,s,u,l,c,f=t.createDocumentFragment(),d=[],p=0,h=e.length;p<h;p++)if((o=e[p])||0===o)if("object"===T(o))E.merge(d,o.nodeType?[o]:o);else if(ye.test(o)){a=a||f.appendChild(t.createElement("div")),s=(de.exec(o)||["",""])[1].toLowerCase(),u=he[s]||he._default,a.innerHTML=u[1]+E.htmlPrefilter(o)+u[2],c=u[0];while(c--)a=a.lastChild;E.merge(d,a.childNodes),(a=f.firstChild).textContent=""}else d.push(t.createTextNode(o));f.textContent="",p=0;while(o=d[p++])if(r&&-1<E.inArray(o,r))i&&i.push(o);else if(l=ie(o),a=ge(f.appendChild(o),"script"),l&&ve(a),n){c=0;while(o=a[c++])pe.test(o.type||"")&&n.push(o)}return f}var be=/^([^.]*)(?:\.(.+)|)/;function xe(){return!0}function we(){return!1}function Ce(e,t){return e===function(){try{return w.activeElement}catch(e){}}()==("focus"===t)}function Te(e,t,n,r,i,o){var a,s;if("object"==typeof t){for(s in"string"!=typeof n&&(r=r||n,n=void 0),t)Te(e,s,n,r,t[s],o);return e}if(null==r&&null==i?(i=n,r=n=void 0):null==i&&("string"==typeof n?(i=r,r=void 0):(i=r,r=n,n=void 0)),!1===i)i=we;else if(!i)return e;return 1===o&&(a=i,(i=function(e){return E().off(e),a.apply(this,arguments)}).guid=a.guid||(a.guid=E.guid++)),e.each(function(){E.event.add(this,t,i,r,n)})}function Ee(e,i,o){o?(Y.set(e,i,!1),E.event.add(e,i,{namespace:!1,handler:function(e){var t,n,r=Y.get(this,i);if(1&e.isTrigger&&this[i]){if(r.length)(E.event.special[i]||{}).delegateType&&e.stopPropagation();else if(r=s.call(arguments),Y.set(this,i,r),t=o(this,i),this[i](),r!==(n=Y.get(this,i))||t?Y.set(this,i,!1):n={},r!==n)return e.stopImmediatePropagation(),e.preventDefault(),n&&n.value}else r.length&&(Y.set(this,i,{value:E.event.trigger(E.extend(r[0],E.Event.prototype),r.slice(1),this)}),e.stopImmediatePropagation())}})):void 0===Y.get(e,i)&&E.event.add(e,i,xe)}E.event={global:{},add:function(t,e,n,r,i){var o,a,s,u,l,c,f,d,p,h,g,v=Y.get(t);if(X(t)){n.handler&&(n=(o=n).handler,i=o.selector),i&&E.find.matchesSelector(re,i),n.guid||(n.guid=E.guid++),(u=v.events)||(u=v.events=Object.create(null)),(a=v.handle)||(a=v.handle=function(e){return"undefined"!=typeof E&&E.event.triggered!==e.type?E.event.dispatch.apply(t,arguments):void 0}),l=(e=(e||"").match(H)||[""]).length;while(l--)p=g=(s=be.exec(e[l])||[])[1],h=(s[2]||"").split(".").sort(),p&&(f=E.event.special[p]||{},p=(i?f.delegateType:f.bindType)||p,f=E.event.special[p]||{},c=E.extend({type:p,origType:g,data:r,handler:n,guid:n.guid,selector:i,needsContext:i&&E.expr.match.needsContext.test(i),namespace:h.join(".")},o),(d=u[p])||((d=u[p]=[]).delegateCount=0,f.setup&&!1!==f.setup.call(t,r,h,a)||t.addEventListener&&t.addEventListener(p,a)),f.add&&(f.add.call(t,c),c.handler.guid||(c.handler.guid=n.guid)),i?d.splice(d.delegateCount++,0,c):d.push(c),E.event.global[p]=!0)}},remove:function(e,t,n,r,i){var o,a,s,u,l,c,f,d,p,h,g,v=Y.hasData(e)&&Y.get(e);if(v&&(u=v.events)){l=(t=(t||"").match(H)||[""]).length;while(l--)if(p=g=(s=be.exec(t[l])||[])[1],h=(s[2]||"").split(".").sort(),p){f=E.event.special[p]||{},d=u[p=(r?f.delegateType:f.bindType)||p]||[],s=s[2]&&new RegExp("(^|\\.)"+h.join("\\.(?:.*\\.|)")+"(\\.|$)"),a=o=d.length;while(o--)c=d[o],!i&&g!==c.origType||n&&n.guid!==c.guid||s&&!s.test(c.namespace)||r&&r!==c.selector&&("**"!==r||!c.selector)||(d.splice(o,1),c.selector&&d.delegateCount--,f.remove&&f.remove.call(e,c));a&&!d.length&&(f.teardown&&!1!==f.teardown.call(e,h,v.handle)||E.removeEvent(e,p,v.handle),delete u[p])}else for(p in u)E.event.remove(e,p+t[l],n,r,!0);E.isEmptyObject(u)&&Y.remove(e,"handle events")}},dispatch:function(e){var t,n,r,i,o,a,s=new Array(arguments.length),u=E.event.fix(e),l=(Y.get(this,"events")||Object.create(null))[u.type]||[],c=E.event.special[u.type]||{};for(s[0]=u,t=1;t<arguments.length;t++)s[t]=arguments[t];if(u.delegateTarget=this,!c.preDispatch||!1!==c.preDispatch.call(this,u)){a=E.event.handlers.call(this,u,l),t=0;while((i=a[t++])&&!u.isPropagationStopped()){u.currentTarget=i.elem,n=0;while((o=i.handlers[n++])&&!u.isImmediatePropagationStopped())u.rnamespace&&!1!==o.namespace&&!u.rnamespace.test(o.namespace)||(u.handleObj=o,u.data=o.data,void 0!==(r=((E.event.special[o.origType]||{}).handle||o.handler).apply(i.elem,s))&&!1===(u.result=r)&&(u.preventDefault(),u.stopPropagation()))}return c.postDispatch&&c.postDispatch.call(this,u),u.result}},handlers:function(e,t){var n,r,i,o,a,s=[],u=t.delegateCount,l=e.target;if(u&&l.nodeType&&!("click"===e.type&&1<=e.button))for(;l!==this;l=l.parentNode||this)if(1===l.nodeType&&("click"!==e.type||!0!==l.disabled)){for(o=[],a={},n=0;n<u;n++)void 0===a[i=(r=t[n]).selector+" "]&&(a[i]=r.needsContext?-1<E(i,this).index(l):E.find(i,this,null,[l]).length),a[i]&&o.push(r);o.length&&s.push({elem:l,handlers:o})}return l=this,u<t.length&&s.push({elem:l,handlers:t.slice(u)}),s},addProp:function(t,e){Object.defineProperty(E.Event.prototype,t,{enumerable:!0,configurable:!0,get:b(e)?function(){if(this.originalEvent)return e(this.originalEvent)}:function(){if(this.originalEvent)return this.originalEvent[t]},set:function(e){Object.defineProperty(this,t,{enumerable:!0,configurable:!0,writable:!0,value:e})}})},fix:function(e){return e[E.expando]?e:new E.Event(e)},special:{load:{noBubble:!0},click:{setup:function(e){var t=this||e;return fe.test(t.type)&&t.click&&N(t,"input")&&Ee(t,"click",xe),!1},trigger:function(e){var t=this||e;return fe.test(t.type)&&t.click&&N(t,"input")&&Ee(t,"click"),!0},_default:function(e){var t=e.target;return fe.test(t.type)&&t.click&&N(t,"input")&&Y.get(t,"click")||N(t,"a")}},beforeunload:{postDispatch:function(e){void 0!==e.result&&e.originalEvent&&(e.originalEvent.returnValue=e.result)}}}},E.removeEvent=function(e,t,n){e.removeEventListener&&e.removeEventListener(t,n)},E.Event=function(e,t){if(!(this instanceof E.Event))return new E.Event(e,t);e&&e.type?(this.originalEvent=e,this.type=e.type,this.isDefaultPrevented=e.defaultPrevented||void 0===e.defaultPrevented&&!1===e.returnValue?xe:we,this.target=e.target&&3===e.target.nodeType?e.target.parentNode:e.target,this.currentTarget=e.currentTarget,this.relatedTarget=e.relatedTarget):this.type=e,t&&E.extend(this,t),this.timeStamp=e&&e.timeStamp||Date.now(),this[E.expando]=!0},E.Event.prototype={constructor:E.Event,isDefaultPrevented:we,isPropagationStopped:we,isImmediatePropagationStopped:we,isSimulated:!1,preventDefault:function(){var e=this.originalEvent;this.isDefaultPrevented=xe,e&&!this.isSimulated&&e.preventDefault()},stopPropagation:function(){var e=this.originalEvent;this.isPropagationStopped=xe,e&&!this.isSimulated&&e.stopPropagation()},stopImmediatePropagation:function(){var e=this.originalEvent;this.isImmediatePropagationStopped=xe,e&&!this.isSimulated&&e.stopImmediatePropagation(),this.stopPropagation()}},E.each({altKey:!0,bubbles:!0,cancelable:!0,changedTouches:!0,ctrlKey:!0,detail:!0,eventPhase:!0,metaKey:!0,pageX:!0,pageY:!0,shiftKey:!0,view:!0,"char":!0,code:!0,charCode:!0,key:!0,keyCode:!0,button:!0,buttons:!0,clientX:!0,clientY:!0,offsetX:!0,offsetY:!0,pointerId:!0,pointerType:!0,screenX:!0,screenY:!0,targetTouches:!0,toElement:!0,touches:!0,which:!0},E.event.addProp),E.each({focus:"focusin",blur:"focusout"},function(t,e){E.event.special[t]={setup:function(){return Ee(this,t,Ce),!1},trigger:function(){return Ee(this,t),!0},_default:function(e){return Y.get(e.target,t)},delegateType:e}}),E.each({mouseenter:"mouseover",mouseleave:"mouseout",pointerenter:"pointerover",pointerleave:"pointerout"},function(e,i){E.event.special[e]={delegateType:i,bindType:i,handle:function(e){var t,n=e.relatedTarget,r=e.handleObj;return n&&(n===this||E.contains(this,n))||(e.type=r.origType,t=r.handler.apply(this,arguments),e.type=i),t}}}),E.fn.extend({on:function(e,t,n,r){return Te(this,e,t,n,r)},one:function(e,t,n,r){return Te(this,e,t,n,r,1)},off:function(e,t,n){var r,i;if(e&&e.preventDefault&&e.handleObj)return r=e.handleObj,E(e.delegateTarget).off(r.namespace?r.origType+"."+r.namespace:r.origType,r.selector,r.handler),this;if("object"==typeof e){for(i in e)this.off(i,t,e[i]);return this}return!1!==t&&"function"!=typeof t||(n=t,t=void 0),!1===n&&(n=we),this.each(function(){E.event.remove(this,e,n,t)})}});var Se=/<script|<style|<link/i,Ae=/checked\s*(?:[^=]|=\s*.checked.)/i,Ne=/^\s*<!\[CDATA\[|\]\]>\s*$/g;function ke(e,t){return N(e,"table")&&N(11!==t.nodeType?t:t.firstChild,"tr")&&E(e).children("tbody")[0]||e}function De(e){return e.type=(null!==e.getAttribute("type"))+"/"+e.type,e}function Le(e){return"true/"===(e.type||"").slice(0,5)?e.type=e.type.slice(5):e.removeAttribute("type"),e}function je(e,t){var n,r,i,o,a,s;if(1===t.nodeType){if(Y.hasData(e)&&(s=Y.get(e).events))for(i in Y.remove(t,"handle events"),s)for(n=0,r=s[i].length;n<r;n++)E.event.add(t,i,s[i][n]);G.hasData(e)&&(o=G.access(e),a=E.extend({},o),G.set(t,a))}}function qe(n,r,i,o){r=v(r);var e,t,a,s,u,l,c=0,f=n.length,d=f-1,p=r[0],h=b(p);if(h||1<f&&"string"==typeof p&&!m.checkClone&&Ae.test(p))return n.each(function(e){var t=n.eq(e);h&&(r[0]=p.call(this,e,t.html())),qe(t,r,i,o)});if(f&&(t=(e=me(r,n[0].ownerDocument,!1,n,o)).firstChild,1===e.childNodes.length&&(e=t),t||o)){for(s=(a=E.map(ge(e,"script"),De)).length;c<f;c++)u=e,c!==d&&(u=E.clone(u,!0,!0),s&&E.merge(a,ge(u,"script"))),i.call(n[c],u,c);if(s)for(l=a[a.length-1].ownerDocument,E.map(a,Le),c=0;c<s;c++)u=a[c],pe.test(u.type||"")&&!Y.access(u,"globalEval")&&E.contains(l,u)&&(u.src&&"module"!==(u.type||"").toLowerCase()?E._evalUrl&&!u.noModule&&E._evalUrl(u.src,{nonce:u.nonce||u.getAttribute("nonce")},l):C(u.textContent.replace(Ne,""),u,l))}return n}function Oe(e,t,n){for(var r,i=t?E.filter(t,e):e,o=0;null!=(r=i[o]);o++)n||1!==r.nodeType||E.cleanData(ge(r)),r.parentNode&&(n&&ie(r)&&ve(ge(r,"script")),r.parentNode.removeChild(r));return e}E.extend({htmlPrefilter:function(e){return e},clone:function(e,t,n){var r,i,o,a,s,u,l,c=e.cloneNode(!0),f=ie(e);if(!(m.noCloneChecked||1!==e.nodeType&&11!==e.nodeType||E.isXMLDoc(e)))for(a=ge(c),r=0,i=(o=ge(e)).length;r<i;r++)s=o[r],u=a[r],void 0,"input"===(l=u.nodeName.toLowerCase())&&fe.test(s.type)?u.checked=s.checked:"input"!==l&&"textarea"!==l||(u.defaultValue=s.defaultValue);if(t)if(n)for(o=o||ge(e),a=a||ge(c),r=0,i=o.length;r<i;r++)je(o[r],a[r]);else je(e,c);return 0<(a=ge(c,"script")).length&&ve(a,!f&&ge(e,"script")),c},cleanData:function(e){for(var t,n,r,i=E.event.special,o=0;void 0!==(n=e[o]);o++)if(X(n)){if(t=n[Y.expando]){if(t.events)for(r in t.events)i[r]?E.event.remove(n,r):E.removeEvent(n,r,t.handle);n[Y.expando]=void 0}n[G.expando]&&(n[G.expando]=void 0)}}}),E.fn.extend({detach:function(e){return Oe(this,e,!0)},remove:function(e){return Oe(this,e)},text:function(e){return $(this,function(e){return void 0===e?E.text(this):this.empty().each(function(){1!==this.nodeType&&11!==this.nodeType&&9!==this.nodeType||(this.textContent=e)})},null,e,arguments.length)},append:function(){return qe(this,arguments,function(e){1!==this.nodeType&&11!==this.nodeType&&9!==this.nodeType||ke(this,e).appendChild(e)})},prepend:function(){return qe(this,arguments,function(e){if(1===this.nodeType||11===this.nodeType||9===this.nodeType){var t=ke(this,e);t.insertBefore(e,t.firstChild)}})},before:function(){return qe(this,arguments,function(e){this.parentNode&&this.parentNode.insertBefore(e,this)})},after:function(){return qe(this,arguments,function(e){this.parentNode&&this.parentNode.insertBefore(e,this.nextSibling)})},empty:function(){for(var e,t=0;null!=(e=this[t]);t++)1===e.nodeType&&(E.cleanData(ge(e,!1)),e.textContent="");return this},clone:function(e,t){return e=null!=e&&e,t=null==t?e:t,this.map(function(){return E.clone(this,e,t)})},html:function(e){return $(this,function(e){var t=this[0]||{},n=0,r=this.length;if(void 0===e&&1===t.nodeType)return t.innerHTML;if("string"==typeof e&&!Se.test(e)&&!he[(de.exec(e)||["",""])[1].toLowerCase()]){e=E.htmlPrefilter(e);try{for(;n<r;n++)1===(t=this[n]||{}).nodeType&&(E.cleanData(ge(t,!1)),t.innerHTML=e);t=0}catch(e){}}t&&this.empty().append(e)},null,e,arguments.length)},replaceWith:function(){var n=[];return qe(this,arguments,function(e){var t=this.parentNode;E.inArray(this,n)<0&&(E.cleanData(ge(this)),t&&t.replaceChild(e,this))},n)}}),E.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(e,a){E.fn[e]=function(e){for(var t,n=[],r=E(e),i=r.length-1,o=0;o<=i;o++)t=o===i?this:this.clone(!0),E(r[o])[a](t),u.apply(n,t.get());return this.pushStack(n)}});var Pe=new RegExp("^("+ee+")(?!px)[a-z%]+$","i"),He=/^--/,Ie=function(e){var t=e.ownerDocument.defaultView;return t&&t.opener||(t=g),t.getComputedStyle(e)},Re=function(e,t,n){var r,i,o={};for(i in t)o[i]=e.style[i],e.style[i]=t[i];for(i in r=n.call(e),t)e.style[i]=o[i];return r},Be=new RegExp(ne.join("|"),"i"),Me="[\\x20\\t\\r\\n\\f]",We=new RegExp("^"+Me+"+|((?:^|[^\\\\])(?:\\\\.)*)"+Me+"+$","g");function Fe(e,t,n){var r,i,o,a,s=He.test(t),u=e.style;return(n=n||Ie(e))&&(a=n.getPropertyValue(t)||n[t],s&&a&&(a=a.replace(We,"$1")||void 0),""!==a||ie(e)||(a=E.style(e,t)),!m.pixelBoxStyles()&&Pe.test(a)&&Be.test(t)&&(r=u.width,i=u.minWidth,o=u.maxWidth,u.minWidth=u.maxWidth=u.width=a,a=n.width,u.width=r,u.minWidth=i,u.maxWidth=o)),void 0!==a?a+"":a}function $e(e,t){return{get:function(){if(!e())return(this.get=t).apply(this,arguments);delete this.get}}}!function(){function e(){if(l){u.style.cssText="position:absolute;left:-11111px;width:60px;margin-top:1px;padding:0;border:0",l.style.cssText="position:relative;display:block;box-sizing:border-box;overflow:scroll;margin:auto;border:1px;padding:1px;width:60%;top:1%",re.appendChild(u).appendChild(l);var e=g.getComputedStyle(l);n="1%"!==e.top,s=12===t(e.marginLeft),l.style.right="60%",o=36===t(e.right),r=36===t(e.width),l.style.position="absolute",i=12===t(l.offsetWidth/3),re.removeChild(u),l=null}}function t(e){return Math.round(parseFloat(e))}var n,r,i,o,a,s,u=w.createElement("div"),l=w.createElement("div");l.style&&(l.style.backgroundClip="content-box",l.cloneNode(!0).style.backgroundClip="",m.clearCloneStyle="content-box"===l.style.backgroundClip,E.extend(m,{boxSizingReliable:function(){return e(),r},pixelBoxStyles:function(){return e(),o},pixelPosition:function(){return e(),n},reliableMarginLeft:function(){return e(),s},scrollboxSize:function(){return e(),i},reliableTrDimensions:function(){var e,t,n,r;return null==a&&(e=w.createElement("table"),t=w.createElement("tr"),n=w.createElement("div"),e.style.cssText="position:absolute;left:-11111px;border-collapse:separate",t.style.cssText="border:1px solid",t.style.height="1px",n.style.height="9px",n.style.display="block",re.appendChild(e).appendChild(t).appendChild(n),r=g.getComputedStyle(t),a=parseInt(r.height,10)+parseInt(r.borderTopWidth,10)+parseInt(r.borderBottomWidth,10)===t.offsetHeight,re.removeChild(e)),a}}))}();var ze=["Webkit","Moz","ms"],_e=w.createElement("div").style,Ue={};function Ve(e){var t=E.cssProps[e]||Ue[e];return t||(e in _e?e:Ue[e]=function(e){var t=e[0].toUpperCase()+e.slice(1),n=ze.length;while(n--)if((e=ze[n]+t)in _e)return e}(e)||e)}var Xe,Qe,Ye=/^(none|table(?!-c[ea]).+)/,Ge={position:"absolute",visibility:"hidden",display:"block"},Ke={letterSpacing:"0",fontWeight:"400"};function Je(e,t,n){var r=te.exec(t);return r?Math.max(0,r[2]-(n||0))+(r[3]||"px"):t}function Ze(e,t,n,r,i,o){var a="width"===t?1:0,s=0,u=0;if(n===(r?"border":"content"))return 0;for(;a<4;a+=2)"margin"===n&&(u+=E.css(e,n+ne[a],!0,i)),r?("content"===n&&(u-=E.css(e,"padding"+ne[a],!0,i)),"margin"!==n&&(u-=E.css(e,"border"+ne[a]+"Width",!0,i))):(u+=E.css(e,"padding"+ne[a],!0,i),"padding"!==n?u+=E.css(e,"border"+ne[a]+"Width",!0,i):s+=E.css(e,"border"+ne[a]+"Width",!0,i));return!r&&0<=o&&(u+=Math.max(0,Math.ceil(e["offset"+t[0].toUpperCase()+t.slice(1)]-o-u-s-.5))||0),u}function et(e,t,n){var r=Ie(e),i=(!m.boxSizingReliable()||n)&&"border-box"===E.css(e,"boxSizing",!1,r),o=i,a=Fe(e,t,r),s="offset"+t[0].toUpperCase()+t.slice(1);if(Pe.test(a)){if(!n)return a;a="auto"}return(!m.boxSizingReliable()&&i||!m.reliableTrDimensions()&&N(e,"tr")||"auto"===a||!parseFloat(a)&&"inline"===E.css(e,"display",!1,r))&&e.getClientRects().length&&(i="border-box"===E.css(e,"boxSizing",!1,r),(o=s in e)&&(a=e[s])),(a=parseFloat(a)||0)+Ze(e,t,n||(i?"border":"content"),o,r,a)+"px"}E.extend({cssHooks:{opacity:{get:function(e,t){if(t){var n=Fe(e,"opacity");return""===n?"1":n}}}},cssNumber:{animationIterationCount:!0,columnCount:!0,fillOpacity:!0,flexGrow:!0,flexShrink:!0,fontWeight:!0,gridArea:!0,gridColumn:!0,gridColumnEnd:!0,gridColumnStart:!0,gridRow:!0,gridRowEnd:!0,gridRowStart:!0,lineHeight:!0,opacity:!0,order:!0,orphans:!0,widows:!0,zIndex:!0,zoom:!0},cssProps:{},style:function(e,t,n,r){if(e&&3!==e.nodeType&&8!==e.nodeType&&e.style){var i,o,a,s=V(t),u=He.test(t),l=e.style;if(u||(t=Ve(s)),a=E.cssHooks[t]||E.cssHooks[s],void 0===n)return a&&"get"in a&&void 0!==(i=a.get(e,!1,r))?i:l[t];"string"===(o=typeof n)&&(i=te.exec(n))&&i[1]&&(n=function(e,t,n,r){var i,o,a=20,s=r?function(){return r.cur()}:function(){return E.css(e,t,"")},u=s(),l=n&&n[3]||(E.cssNumber[t]?"":"px"),c=e.nodeType&&(E.cssNumber[t]||"px"!==l&&+u)&&te.exec(E.css(e,t));if(c&&c[3]!==l){u/=2,l=l||c[3],c=+u||1;while(a--)E.style(e,t,c+l),(1-o)*(1-(o=s()/u||.5))<=0&&(a=0),c/=o;c*=2,E.style(e,t,c+l),n=n||[]}return n&&(c=+c||+u||0,i=n[1]?c+(n[1]+1)*n[2]:+n[2],r&&(r.unit=l,r.start=c,r.end=i)),i}(e,t,i),o="number"),null!=n&&n==n&&("number"!==o||u||(n+=i&&i[3]||(E.cssNumber[s]?"":"px")),m.clearCloneStyle||""!==n||0!==t.indexOf("background")||(l[t]="inherit"),a&&"set"in a&&void 0===(n=a.set(e,n,r))||(u?l.setProperty(t,n):l[t]=n))}},css:function(e,t,n,r){var i,o,a,s=V(t);return He.test(t)||(t=Ve(s)),(a=E.cssHooks[t]||E.cssHooks[s])&&"get"in a&&(i=a.get(e,!0,n)),void 0===i&&(i=Fe(e,t,r)),"normal"===i&&t in Ke&&(i=Ke[t]),""===n||n?(o=parseFloat(i),!0===n||isFinite(o)?o||0:i):i}}),E.each(["height","width"],function(e,u){E.cssHooks[u]={get:function(e,t,n){if(t)return!Ye.test(E.css(e,"display"))||e.getClientRects().length&&e.getBoundingClientRect().width?et(e,u,n):Re(e,Ge,function(){return et(e,u,n)})},set:function(e,t,n){var r,i=Ie(e),o=!m.scrollboxSize()&&"absolute"===i.position,a=(o||n)&&"border-box"===E.css(e,"boxSizing",!1,i),s=n?Ze(e,u,n,a,i):0;return a&&o&&(s-=Math.ceil(e["offset"+u[0].toUpperCase()+u.slice(1)]-parseFloat(i[u])-Ze(e,u,"border",!1,i)-.5)),s&&(r=te.exec(t))&&"px"!==(r[3]||"px")&&(e.style[u]=t,t=E.css(e,u)),Je(0,t,s)}}}),E.cssHooks.marginLeft=$e(m.reliableMarginLeft,function(e,t){if(t)return(parseFloat(Fe(e,"marginLeft"))||e.getBoundingClientRect().left-Re(e,{marginLeft:0},function(){return e.getBoundingClientRect().left}))+"px"}),E.each({margin:"",padding:"",border:"Width"},function(i,o){E.cssHooks[i+o]={expand:function(e){for(var t=0,n={},r="string"==typeof e?e.split(" "):[e];t<4;t++)n[i+ne[t]+o]=r[t]||r[t-2]||r[0];return n}},"margin"!==i&&(E.cssHooks[i+o].set=Je)}),E.fn.extend({css:function(e,t){return $(this,function(e,t,n){var r,i,o={},a=0;if(Array.isArray(t)){for(r=Ie(e),i=t.length;a<i;a++)o[t[a]]=E.css(e,t[a],!1,r);return o}return void 0!==n?E.style(e,t,n):E.css(e,t)},e,t,1<arguments.length)}}),E.fn.delay=function(r,e){return r=E.fx&&E.fx.speeds[r]||r,e=e||"fx",this.queue(e,function(e,t){var n=g.setTimeout(e,r);t.stop=function(){g.clearTimeout(n)}})},Xe=w.createElement("input"),Qe=w.createElement("select").appendChild(w.createElement("option")),Xe.type="checkbox",m.checkOn=""!==Xe.value,m.optSelected=Qe.selected,(Xe=w.createElement("input")).value="t",Xe.type="radio",m.radioValue="t"===Xe.value;var tt,nt=E.expr.attrHandle;E.fn.extend({attr:function(e,t){return $(this,E.attr,e,t,1<arguments.length)},removeAttr:function(e){return this.each(function(){E.removeAttr(this,e)})}}),E.extend({attr:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&&8!==o&&2!==o)return"undefined"==typeof e.getAttribute?E.prop(e,t,n):(1===o&&E.isXMLDoc(e)||(i=E.attrHooks[t.toLowerCase()]||(E.expr.match.bool.test(t)?tt:void 0)),void 0!==n?null===n?void E.removeAttr(e,t):i&&"set"in i&&void 0!==(r=i.set(e,n,t))?r:(e.setAttribute(t,n+""),n):i&&"get"in i&&null!==(r=i.get(e,t))?r:null==(r=E.find.attr(e,t))?void 0:r)},attrHooks:{type:{set:function(e,t){if(!m.radioValue&&"radio"===t&&N(e,"input")){var n=e.value;return e.setAttribute("type",t),n&&(e.value=n),t}}}},removeAttr:function(e,t){var n,r=0,i=t&&t.match(H);if(i&&1===e.nodeType)while(n=i[r++])e.removeAttribute(n)}}),tt={set:function(e,t,n){return!1===t?E.removeAttr(e,n):e.setAttribute(n,n),n}},E.each(E.expr.match.bool.source.match(/\w+/g),function(e,t){var a=nt[t]||E.find.attr;nt[t]=function(e,t,n){var r,i,o=t.toLowerCase();return n||(i=nt[o],nt[o]=r,r=null!=a(e,t,n)?o:null,nt[o]=i),r}});var rt=/^(?:input|select|textarea|button)$/i,it=/^(?:a|area)$/i;function ot(e){return(e.match(H)||[]).join(" ")}function at(e){return e.getAttribute&&e.getAttribute("class")||""}function st(e){return Array.isArray(e)?e:"string"==typeof e&&e.match(H)||[]}E.fn.extend({prop:function(e,t){return $(this,E.prop,e,t,1<arguments.length)},removeProp:function(e){return this.each(function(){delete this[E.propFix[e]||e]})}}),E.extend({prop:function(e,t,n){var r,i,o=e.nodeType;if(3!==o&&8!==o&&2!==o)return 1===o&&E.isXMLDoc(e)||(t=E.propFix[t]||t,i=E.propHooks[t]),void 0!==n?i&&"set"in i&&void 0!==(r=i.set(e,n,t))?r:e[t]=n:i&&"get"in i&&null!==(r=i.get(e,t))?r:e[t]},propHooks:{tabIndex:{get:function(e){var t=E.find.attr(e,"tabindex");return t?parseInt(t,10):rt.test(e.nodeName)||it.test(e.nodeName)&&e.href?0:-1}}},propFix:{"for":"htmlFor","class":"className"}}),m.optSelected||(E.propHooks.selected={get:function(e){var t=e.parentNode;return t&&t.parentNode&&t.parentNode.selectedIndex,null},set:function(e){var t=e.parentNode;t&&(t.selectedIndex,t.parentNode&&t.parentNode.selectedIndex)}}),E.each(["tabIndex","readOnly","maxLength","cellSpacing","cellPadding","rowSpan","colSpan","useMap","frameBorder","contentEditable"],function(){E.propFix[this.toLowerCase()]=this}),E.fn.extend({addClass:function(t){var e,n,r,i,o,a;return b(t)?this.each(function(e){E(this).addClass(t.call(this,e,at(this)))}):(e=st(t)).length?this.each(function(){if(r=at(this),n=1===this.nodeType&&" "+ot(r)+" "){for(o=0;o<e.length;o++)i=e[o],n.indexOf(" "+i+" ")<0&&(n+=i+" ");a=ot(n),r!==a&&this.setAttribute("class",a)}}):this},removeClass:function(t){var e,n,r,i,o,a;return b(t)?this.each(function(e){E(this).removeClass(t.call(this,e,at(this)))}):arguments.length?(e=st(t)).length?this.each(function(){if(r=at(this),n=1===this.nodeType&&" "+ot(r)+" "){for(o=0;o<e.length;o++){i=e[o];while(-1<n.indexOf(" "+i+" "))n=n.replace(" "+i+" "," ")}a=ot(n),r!==a&&this.setAttribute("class",a)}}):this:this.attr("class","")},toggleClass:function(t,n){var e,r,i,o,a=typeof t,s="string"===a||Array.isArray(t);return b(t)?this.each(function(e){E(this).toggleClass(t.call(this,e,at(this),n),n)}):"boolean"==typeof n&&s?n?this.addClass(t):this.removeClass(t):(e=st(t),this.each(function(){if(s)for(o=E(this),i=0;i<e.length;i++)r=e[i],o.hasClass(r)?o.removeClass(r):o.addClass(r);else void 0!==t&&"boolean"!==a||((r=at(this))&&Y.set(this,"__className__",r),this.setAttribute&&this.setAttribute("class",r||!1===t?"":Y.get(this,"__className__")||""))}))},hasClass:function(e){var t,n,r=0;t=" "+e+" ";while(n=this[r++])if(1===n.nodeType&&-1<(" "+ot(at(n))+" ").indexOf(t))return!0;return!1}});var ut=/\r/g;E.fn.extend({val:function(n){var r,e,i,t=this[0];return arguments.length?(i=b(n),this.each(function(e){var t;1===this.nodeType&&(null==(t=i?n.call(this,e,E(this).val()):n)?t="":"number"==typeof t?t+="":Array.isArray(t)&&(t=E.map(t,function(e){return null==e?"":e+""})),(r=E.valHooks[this.type]||E.valHooks[this.nodeName.toLowerCase()])&&"set"in r&&void 0!==r.set(this,t,"value")||(this.value=t))})):t?(r=E.valHooks[t.type]||E.valHooks[t.nodeName.toLowerCase()])&&"get"in r&&void 0!==(e=r.get(t,"value"))?e:"string"==typeof(e=t.value)?e.replace(ut,""):null==e?"":e:void 0}}),E.extend({valHooks:{option:{get:function(e){var t=E.find.attr(e,"value");return null!=t?t:ot(E.text(e))}},select:{get:function(e){var t,n,r,i=e.options,o=e.selectedIndex,a="select-one"===e.type,s=a?null:[],u=a?o+1:i.length;for(r=o<0?u:a?o:0;r<u;r++)if(((n=i[r]).selected||r===o)&&!n.disabled&&(!n.parentNode.disabled||!N(n.parentNode,"optgroup"))){if(t=E(n).val(),a)return t;s.push(t)}return s},set:function(e,t){var n,r,i=e.options,o=E.makeArray(t),a=i.length;while(a--)((r=i[a]).selected=-1<E.inArray(E.valHooks.option.get(r),o))&&(n=!0);return n||(e.selectedIndex=-1),o}}}}),E.each(["radio","checkbox"],function(){E.valHooks[this]={set:function(e,t){if(Array.isArray(t))return e.checked=-1<E.inArray(E(e).val(),t)}},m.checkOn||(E.valHooks[this].get=function(e){return null===e.getAttribute("value")?"on":e.value})}),m.focusin="onfocusin"in g;var lt=/^(?:focusinfocus|focusoutblur)$/,ct=function(e){e.stopPropagation()};E.extend(E.event,{trigger:function(e,t,n,r){var i,o,a,s,u,l,c,f,d=[n||w],p=y.call(e,"type")?e.type:e,h=y.call(e,"namespace")?e.namespace.split("."):[];if(o=f=a=n=n||w,3!==n.nodeType&&8!==n.nodeType&&!lt.test(p+E.event.triggered)&&(-1<p.indexOf(".")&&(p=(h=p.split(".")).shift(),h.sort()),u=p.indexOf(":")<0&&"on"+p,(e=e[E.expando]?e:new E.Event(p,"object"==typeof e&&e)).isTrigger=r?2:3,e.namespace=h.join("."),e.rnamespace=e.namespace?new RegExp("(^|\\.)"+h.join("\\.(?:.*\\.|)")+"(\\.|$)"):null,e.result=void 0,e.target||(e.target=n),t=null==t?[e]:E.makeArray(t,[e]),c=E.event.special[p]||{},r||!c.trigger||!1!==c.trigger.apply(n,t))){if(!r&&!c.noBubble&&!x(n)){for(s=c.delegateType||p,lt.test(s+p)||(o=o.parentNode);o;o=o.parentNode)d.push(o),a=o;a===(n.ownerDocument||w)&&d.push(a.defaultView||a.parentWindow||g)}i=0;while((o=d[i++])&&!e.isPropagationStopped())f=o,e.type=1<i?s:c.bindType||p,(l=(Y.get(o,"events")||Object.create(null))[e.type]&&Y.get(o,"handle"))&&l.apply(o,t),(l=u&&o[u])&&l.apply&&X(o)&&(e.result=l.apply(o,t),!1===e.result&&e.preventDefault());return e.type=p,r||e.isDefaultPrevented()||c._default&&!1!==c._default.apply(d.pop(),t)||!X(n)||u&&b(n[p])&&!x(n)&&((a=n[u])&&(n[u]=null),E.event.triggered=p,e.isPropagationStopped()&&f.addEventListener(p,ct),n[p](),e.isPropagationStopped()&&f.removeEventListener(p,ct),E.event.triggered=void 0,a&&(n[u]=a)),e.result}},simulate:function(e,t,n){var r=E.extend(new E.Event,n,{type:e,isSimulated:!0});E.event.trigger(r,null,t)}}),E.fn.extend({trigger:function(e,t){return this.each(function(){E.event.trigger(e,t,this)})},triggerHandler:function(e,t){var n=this[0];if(n)return E.event.trigger(e,t,n,!0)}}),m.focusin||E.each({focus:"focusin",blur:"focusout"},function(n,r){var i=function(e){E.event.simulate(r,e.target,E.event.fix(e))};E.event.special[r]={setup:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r);t||e.addEventListener(n,i,!0),Y.access(e,r,(t||0)+1)},teardown:function(){var e=this.ownerDocument||this.document||this,t=Y.access(e,r)-1;t?Y.access(e,r,t):(e.removeEventListener(n,i,!0),Y.remove(e,r))}}}),E.parseXML=function(e){var t,n;if(!e||"string"!=typeof e)return null;try{t=(new g.DOMParser).parseFromString(e,"text/xml")}catch(e){}return n=t&&t.getElementsByTagName("parsererror")[0],t&&!n||E.error("Invalid XML: "+(n?E.map(n.childNodes,function(e){return e.textContent}).join("\n"):e)),t};var ft,dt=/\[\]$/,pt=/\r?\n/g,ht=/^(?:submit|button|image|reset|file)$/i,gt=/^(?:input|select|textarea|keygen)/i;function vt(n,e,r,i){var t;if(Array.isArray(e))E.each(e,function(e,t){r||dt.test(n)?i(n,t):vt(n+"["+("object"==typeof t&&null!=t?e:"")+"]",t,r,i)});else if(r||"object"!==T(e))i(n,e);else for(t in e)vt(n+"["+t+"]",e[t],r,i)}E.param=function(e,t){var n,r=[],i=function(e,t){var n=b(t)?t():t;r[r.length]=encodeURIComponent(e)+"="+encodeURIComponent(null==n?"":n)};if(null==e)return"";if(Array.isArray(e)||e.jquery&&!E.isPlainObject(e))E.each(e,function(){i(this.name,this.value)});else for(n in e)vt(n,e[n],t,i);return r.join("&")},E.fn.extend({serialize:function(){return E.param(this.serializeArray())},serializeArray:function(){return this.map(function(){var e=E.prop(this,"elements");return e?E.makeArray(e):this}).filter(function(){var e=this.type;return this.name&&!E(this).is(":disabled")&&gt.test(this.nodeName)&&!ht.test(e)&&(this.checked||!fe.test(e))}).map(function(e,t){var n=E(this).val();return null==n?null:Array.isArray(n)?E.map(n,function(e){return{name:t.name,value:e.replace(pt,"\r\n")}}):{name:t.name,value:n.replace(pt,"\r\n")}}).get()}}),E.fn.extend({wrapAll:function(e){var t;return this[0]&&(b(e)&&(e=e.call(this[0])),t=E(e,this[0].ownerDocument).eq(0).clone(!0),this[0].parentNode&&t.insertBefore(this[0]),t.map(function(){var e=this;while(e.firstElementChild)e=e.firstElementChild;return e}).append(this)),this},wrapInner:function(n){return b(n)?this.each(function(e){E(this).wrapInner(n.call(this,e))}):this.each(function(){var e=E(this),t=e.contents();t.length?t.wrapAll(n):e.append(n)})},wrap:function(t){var n=b(t);return this.each(function(e){E(this).wrapAll(n?t.call(this,e):t)})},unwrap:function(e){return this.parent(e).not("body").each(function(){E(this).replaceWith(this.childNodes)}),this}}),E.expr.pseudos.hidden=function(e){return!E.expr.pseudos.visible(e)},E.expr.pseudos.visible=function(e){return!!(e.offsetWidth||e.offsetHeight||e.getClientRects().length)},m.createHTMLDocument=((ft=w.implementation.createHTMLDocument("").body).innerHTML="<form></form><form></form>",2===ft.childNodes.length),E.parseHTML=function(e,t,n){return"string"!=typeof e?[]:("boolean"==typeof t&&(n=t,t=!1),t||(m.createHTMLDocument?((r=(t=w.implementation.createHTMLDocument("")).createElement("base")).href=w.location.href,t.head.appendChild(r)):t=w),o=!n&&[],(i=k.exec(e))?[t.createElement(i[1])]:(i=me([e],t,o),o&&o.length&&E(o).remove(),E.merge([],i.childNodes)));var r,i,o},E.offset={setOffset:function(e,t,n){var r,i,o,a,s,u,l=E.css(e,"position"),c=E(e),f={};"static"===l&&(e.style.position="relative"),s=c.offset(),o=E.css(e,"top"),u=E.css(e,"left"),("absolute"===l||"fixed"===l)&&-1<(o+u).indexOf("auto")?(a=(r=c.position()).top,i=r.left):(a=parseFloat(o)||0,i=parseFloat(u)||0),b(t)&&(t=t.call(e,n,E.extend({},s))),null!=t.top&&(f.top=t.top-s.top+a),null!=t.left&&(f.left=t.left-s.left+i),"using"in t?t.using.call(e,f):c.css(f)}},E.fn.extend({offset:function(t){if(arguments.length)return void 0===t?this:this.each(function(e){E.offset.setOffset(this,t,e)});var e,n,r=this[0];return r?r.getClientRects().length?(e=r.getBoundingClientRect(),n=r.ownerDocument.defaultView,{top:e.top+n.pageYOffset,left:e.left+n.pageXOffset}):{top:0,left:0}:void 0},position:function(){if(this[0]){var e,t,n,r=this[0],i={top:0,left:0};if("fixed"===E.css(r,"position"))t=r.getBoundingClientRect();else{t=this.offset(),n=r.ownerDocument,e=r.offsetParent||n.documentElement;while(e&&(e===n.body||e===n.documentElement)&&"static"===E.css(e,"position"))e=e.parentNode;e&&e!==r&&1===e.nodeType&&((i=E(e).offset()).top+=E.css(e,"borderTopWidth",!0),i.left+=E.css(e,"borderLeftWidth",!0))}return{top:t.top-i.top-E.css(r,"marginTop",!0),left:t.left-i.left-E.css(r,"marginLeft",!0)}}},offsetParent:function(){return this.map(function(){var e=this.offsetParent;while(e&&"static"===E.css(e,"position"))e=e.offsetParent;return e||re})}}),E.each({scrollLeft:"pageXOffset",scrollTop:"pageYOffset"},function(t,i){var o="pageYOffset"===i;E.fn[t]=function(e){return $(this,function(e,t,n){var r;if(x(e)?r=e:9===e.nodeType&&(r=e.defaultView),void 0===n)return r?r[i]:e[t];r?r.scrollTo(o?r.pageXOffset:n,o?n:r.pageYOffset):e[t]=n},t,e,arguments.length)}}),E.each(["top","left"],function(e,n){E.cssHooks[n]=$e(m.pixelPosition,function(e,t){if(t)return t=Fe(e,n),Pe.test(t)?E(e).position()[n]+"px":t})}),E.each({Height:"height",Width:"width"},function(a,s){E.each({padding:"inner"+a,content:s,"":"outer"+a},function(r,o){E.fn[o]=function(e,t){var n=arguments.length&&(r||"boolean"!=typeof e),i=r||(!0===e||!0===t?"margin":"border");return $(this,function(e,t,n){var r;return x(e)?0===o.indexOf("outer")?e["inner"+a]:e.document.documentElement["client"+a]:9===e.nodeType?(r=e.documentElement,Math.max(e.body["scroll"+a],r["scroll"+a],e.body["offset"+a],r["offset"+a],r["client"+a])):void 0===n?E.css(e,t,i):E.style(e,t,n,i)},s,n?e:void 0,n)}})}),E.fn.extend({bind:function(e,t,n){return this.on(e,null,t,n)},unbind:function(e,t){return this.off(e,null,t)},delegate:function(e,t,n,r){return this.on(t,e,n,r)},undelegate:function(e,t,n){return 1===arguments.length?this.off(e,"**"):this.off(t,e||"**",n)},hover:function(e,t){return this.mouseenter(e).mouseleave(t||e)}}),E.each("blur focus focusin focusout resize scroll click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup contextmenu".split(" "),function(e,n){E.fn[n]=function(e,t){return 0<arguments.length?this.on(n,null,e,t):this.trigger(n)}});var yt=/^[\s\uFEFF\xA0]+|([^\s\uFEFF\xA0])[\s\uFEFF\xA0]+$/g;E.proxy=function(e,t){var n,r,i;if("string"==typeof t&&(n=e[t],t=e,e=n),b(e))return r=s.call(arguments,2),(i=function(){return e.apply(t||this,r.concat(s.call(arguments)))}).guid=e.guid=e.guid||E.guid++,i},E.holdReady=function(e){e?E.readyWait++:E.ready(!0)},E.isArray=Array.isArray,E.parseJSON=JSON.parse,E.nodeName=N,E.isFunction=b,E.isWindow=x,E.camelCase=V,E.type=T,E.now=Date.now,E.isNumeric=function(e){var t=E.type(e);return("number"===t||"string"===t)&&!isNaN(e-parseFloat(e))},E.trim=function(e){return null==e?"":(e+"").replace(yt,"$1")},"function"==typeof define&&define.amd&&define("jquery",[],function(){return E});var mt=g.jQuery,bt=g.$;return E.noConflict=function(e){return g.$===E&&(g.$=bt),e&&g.jQuery===E&&(g.jQuery=mt),E},"undefined"==typeof e&&(g.jQuery=g.$=E),E});

----------------------------------------

File: docs/api_reference/themes/scikit-learn-modern/theme.conf
Status: removed
Changes: +0 -8
Diff:
@@ -1,8 +0,0 @@
-[theme]
-inherit = basic
-pygments_style = default
-stylesheet = css/theme.css
-
-[options]
-link_to_live_contributing_page = false
-mathjax_path =

----------------------------------------

File: docs/docs/additional_resources/arxiv_references.mdx
Status: modified
Changes: +104 -153
Diff:
@@ -4,8 +4,11 @@ LangChain implements the latest research in the field of Natural Language Proces
 This page contains `arXiv` papers referenced in the LangChain Documentation, API Reference,
  Templates, and Cookbooks.
 
-From the opposite direction, scientists use LangChain in research and reference LangChain in the research papers. 
-Here you find [such papers](https://arxiv.org/search/?query=langchain&searchtype=all&source=header).
+From the opposite direction, scientists use `LangChain` in research and reference it in the research papers. 
+Here you find papers that reference:
+- [LangChain](https://arxiv.org/search/?query=langchain&searchtype=all&source=header)
+- [LangGraph](https://arxiv.org/search/?query=langgraph&searchtype=all&source=header)
+- [LangSmith](https://arxiv.org/search/?query=langsmith&searchtype=all&source=header)
 
 ## Summary
 
@@ -23,32 +26,30 @@ Here you find [such papers](https://arxiv.org/search/?query=langchain&searchtype
 | `2305.14283v3` [Query Rewriting for Retrieval-Augmented Large Language Models](http://arxiv.org/abs/2305.14283v3) | Xinbei Ma, Yeyun Gong, Pengcheng He,  et al. | 2023-05-23 | `Template:` [rewrite-retrieve-read](https://python.langchain.com/docs/templates/rewrite-retrieve-read), `Cookbook:` [rewrite](https://github.com/langchain-ai/langchain/blob/master/cookbook/rewrite.ipynb)
 | `2305.08291v1` [Large Language Model Guided Tree-of-Thought](http://arxiv.org/abs/2305.08291v1) | Jieyi Long | 2023-05-15 | `API:` [langchain_experimental.tot](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.tot), `Cookbook:` [tree_of_thought](https://github.com/langchain-ai/langchain/blob/master/cookbook/tree_of_thought.ipynb)
 | `2305.04091v3` [Plan-and-Solve Prompting: Improving Zero-Shot Chain-of-Thought Reasoning by Large Language Models](http://arxiv.org/abs/2305.04091v3) | Lei Wang, Wanyu Xu, Yihuai Lan,  et al. | 2023-05-06 | `Cookbook:` [plan_and_execute_agent](https://github.com/langchain-ai/langchain/blob/master/cookbook/plan_and_execute_agent.ipynb)
+| `2305.02156v1` [Zero-Shot Listwise Document Reranking with a Large Language Model](http://arxiv.org/abs/2305.02156v1) | Xueguang Ma, Xinyu Zhang, Ronak Pradeep,  et al. | 2023-05-03 | `API:` [langchain...LLMListwiseRerank](https://api.python.langchain.com/en/latest/retrievers/langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank.html#langchain.retrievers.document_compressors.listwise_rerank.LLMListwiseRerank)
 | `2304.08485v2` [Visual Instruction Tuning](http://arxiv.org/abs/2304.08485v2) | Haotian Liu, Chunyuan Li, Qingyang Wu,  et al. | 2023-04-17 | `Cookbook:` [Semi_structured_and_multi_modal_RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_and_multi_modal_RAG.ipynb), [Semi_structured_multi_modal_RAG_LLaMA2](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_structured_multi_modal_RAG_LLaMA2.ipynb)
 | `2304.03442v2` [Generative Agents: Interactive Simulacra of Human Behavior](http://arxiv.org/abs/2304.03442v2) | Joon Sung Park, Joseph C. O'Brien, Carrie J. Cai,  et al. | 2023-04-07 | `Cookbook:` [multiagent_bidding](https://github.com/langchain-ai/langchain/blob/master/cookbook/multiagent_bidding.ipynb), [generative_agents_interactive_simulacra_of_human_behavior](https://github.com/langchain-ai/langchain/blob/master/cookbook/generative_agents_interactive_simulacra_of_human_behavior.ipynb)
 | `2303.17760v2` [CAMEL: Communicative Agents for "Mind" Exploration of Large Language Model Society](http://arxiv.org/abs/2303.17760v2) | Guohao Li, Hasan Abed Al Kader Hammoud, Hani Itani,  et al. | 2023-03-31 | `Cookbook:` [camel_role_playing](https://github.com/langchain-ai/langchain/blob/master/cookbook/camel_role_playing.ipynb)
 | `2303.17580v4` [HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face](http://arxiv.org/abs/2303.17580v4) | Yongliang Shen, Kaitao Song, Xu Tan,  et al. | 2023-03-30 | `API:` [langchain_experimental.autonomous_agents](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.autonomous_agents), `Cookbook:` [hugginggpt](https://github.com/langchain-ai/langchain/blob/master/cookbook/hugginggpt.ipynb)
-| `2303.08774v6` [GPT-4 Technical Report](http://arxiv.org/abs/2303.08774v6) | OpenAI, Josh Achiam, Steven Adler,  et al. | 2023-03-15 | `Docs:` [docs/integrations/vectorstores/mongodb_atlas](https://python.langchain.com/docs/integrations/vectorstores/mongodb_atlas)
-| `2301.10226v4` [A Watermark for Large Language Models](http://arxiv.org/abs/2301.10226v4) | John Kirchenbauer, Jonas Geiping, Yuxin Wen,  et al. | 2023-01-24 | `API:` [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...OCIModelDeploymentTGI](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI.html#langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
+| `2301.10226v4` [A Watermark for Large Language Models](http://arxiv.org/abs/2301.10226v4) | John Kirchenbauer, Jonas Geiping, Yuxin Wen,  et al. | 2023-01-24 | `API:` [langchain_community...OCIModelDeploymentTGI](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI.html#langchain_community.llms.oci_data_science_model_deployment_endpoint.OCIModelDeploymentTGI), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
 | `2212.10496v1` [Precise Zero-Shot Dense Retrieval without Relevance Labels](http://arxiv.org/abs/2212.10496v1) | Luyu Gao, Xueguang Ma, Jimmy Lin,  et al. | 2022-12-20 | `API:` [langchain...HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html#langchain.chains.hyde.base.HypotheticalDocumentEmbedder), `Template:` [hyde](https://python.langchain.com/docs/templates/hyde), `Cookbook:` [hypothetical_document_embeddings](https://github.com/langchain-ai/langchain/blob/master/cookbook/hypothetical_document_embeddings.ipynb)
 | `2212.07425v3` [Robust and Explainable Identification of Logical Fallacies in Natural Language Arguments](http://arxiv.org/abs/2212.07425v3) | Zhivar Sourati, Vishnu Priya Prasanna Venkatesh, Darshan Deshpande,  et al. | 2022-12-12 | `API:` [langchain_experimental.fallacy_removal](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.fallacy_removal)
 | `2211.13892v2` [Complementary Explanations for Effective In-Context Learning](http://arxiv.org/abs/2211.13892v2) | Xi Ye, Srinivasan Iyer, Asli Celikyilmaz,  et al. | 2022-11-25 | `API:` [langchain_core...MaxMarginalRelevanceExampleSelector](https://api.python.langchain.com/en/latest/example_selectors/langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector.html#langchain_core.example_selectors.semantic_similarity.MaxMarginalRelevanceExampleSelector)
-| `2211.10435v2` [PAL: Program-aided Language Models](http://arxiv.org/abs/2211.10435v2) | Luyu Gao, Aman Madaan, Shuyan Zhou,  et al. | 2022-11-18 | `API:` [langchain_experimental...PALChain](https://api.python.langchain.com/en/latest/pal_chain/langchain_experimental.pal_chain.base.PALChain.html#langchain_experimental.pal_chain.base.PALChain), [langchain_experimental.pal_chain](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.pal_chain), `Cookbook:` [program_aided_language_model](https://github.com/langchain-ai/langchain/blob/master/cookbook/program_aided_language_model.ipynb)
-| `2210.03629v3` [ReAct: Synergizing Reasoning and Acting in Language Models](http://arxiv.org/abs/2210.03629v3) | Shunyu Yao, Jeffrey Zhao, Dian Yu,  et al. | 2022-10-06 | `Docs:` [docs/integrations/providers/cohere](https://python.langchain.com/docs/integrations/providers/cohere), [docs/integrations/chat/huggingface](https://python.langchain.com/docs/integrations/chat/huggingface), [docs/integrations/tools/ionic_shopping](https://python.langchain.com/docs/integrations/tools/ionic_shopping), `API:` [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent), [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain)
+| `2211.10435v2` [PAL: Program-aided Language Models](http://arxiv.org/abs/2211.10435v2) | Luyu Gao, Aman Madaan, Shuyan Zhou,  et al. | 2022-11-18 | `API:` [langchain_experimental.pal_chain](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.pal_chain), [langchain_experimental...PALChain](https://api.python.langchain.com/en/latest/pal_chain/langchain_experimental.pal_chain.base.PALChain.html#langchain_experimental.pal_chain.base.PALChain), `Cookbook:` [program_aided_language_model](https://github.com/langchain-ai/langchain/blob/master/cookbook/program_aided_language_model.ipynb)
+| `2210.03629v3` [ReAct: Synergizing Reasoning and Acting in Language Models](http://arxiv.org/abs/2210.03629v3) | Shunyu Yao, Jeffrey Zhao, Dian Yu,  et al. | 2022-10-06 | `Docs:` [docs/integrations/providers/cohere](https://python.langchain.com/docs/integrations/providers/cohere), [docs/integrations/tools/ionic_shopping](https://python.langchain.com/docs/integrations/tools/ionic_shopping), `API:` [langchain...TrajectoryEvalChain](https://api.python.langchain.com/en/latest/evaluation/langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain.html#langchain.evaluation.agents.trajectory_eval_chain.TrajectoryEvalChain), [langchain...create_react_agent](https://api.python.langchain.com/en/latest/agents/langchain.agents.react.agent.create_react_agent.html#langchain.agents.react.agent.create_react_agent)
 | `2209.10785v2` [Deep Lake: a Lakehouse for Deep Learning](http://arxiv.org/abs/2209.10785v2) | Sasun Hambardzumyan, Abhinav Tuli, Levon Ghukasyan,  et al. | 2022-09-22 | `Docs:` [docs/integrations/providers/activeloop_deeplake](https://python.langchain.com/docs/integrations/providers/activeloop_deeplake)
+| `2205.13147v4` [Matryoshka Representation Learning](http://arxiv.org/abs/2205.13147v4) | Aditya Kusupati, Gantavya Bhatt, Aniket Rege,  et al. | 2022-05-26 | `Docs:` [docs/integrations/providers/snowflake](https://python.langchain.com/docs/integrations/providers/snowflake)
 | `2205.12654v1` [Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages](http://arxiv.org/abs/2205.12654v1) | Kevin Heffernan, Onur Çelebi, Holger Schwenk | 2022-05-25 | `API:` [langchain_community...LaserEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.laser.LaserEmbeddings.html#langchain_community.embeddings.laser.LaserEmbeddings)
-| `2204.00498v1` [Evaluating the Text-to-SQL Capabilities of Large Language Models](http://arxiv.org/abs/2204.00498v1) | Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau | 2022-03-15 | `API:` [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL), [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase)
-| `2202.00666v5` [Locally Typical Sampling](http://arxiv.org/abs/2202.00666v5) | Clara Meister, Tiago Pimentel, Gian Wiher,  et al. | 2022-02-01 | `API:` [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
+| `2204.00498v1` [Evaluating the Text-to-SQL Capabilities of Large Language Models](http://arxiv.org/abs/2204.00498v1) | Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau | 2022-03-15 | `API:` [langchain_community...SQLDatabase](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.sql_database.SQLDatabase.html#langchain_community.utilities.sql_database.SQLDatabase), [langchain_community...SparkSQL](https://api.python.langchain.com/en/latest/utilities/langchain_community.utilities.spark_sql.SparkSQL.html#langchain_community.utilities.spark_sql.SparkSQL)
+| `2202.00666v5` [Locally Typical Sampling](http://arxiv.org/abs/2202.00666v5) | Clara Meister, Tiago Pimentel, Gian Wiher,  et al. | 2022-02-01 | `API:` [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
 | `2103.00020v1` [Learning Transferable Visual Models From Natural Language Supervision](http://arxiv.org/abs/2103.00020v1) | Alec Radford, Jong Wook Kim, Chris Hallacy,  et al. | 2021-02-26 | `API:` [langchain_experimental.open_clip](https://api.python.langchain.com/en/latest/experimental_api_reference.html#module-langchain_experimental.open_clip)
-| `1909.05858v2` [CTRL: A Conditional Transformer Language Model for Controllable Generation](http://arxiv.org/abs/1909.05858v2) | Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney,  et al. | 2019-09-11 | `API:` [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
-| `1908.10084v1` [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks](http://arxiv.org/abs/1908.10084v1) | Nils Reimers, Iryna Gurevych | 2019-08-27 | `Docs:` [docs/integrations/text_embedding/sentence_transformers](https://python.langchain.com/docs/integrations/text_embedding/sentence_transformers)
+| `1909.05858v2` [CTRL: A Conditional Transformer Language Model for Controllable Generation](http://arxiv.org/abs/1909.05858v2) | Nitish Shirish Keskar, Bryan McCann, Lav R. Varshney,  et al. | 2019-09-11 | `API:` [langchain_huggingface...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_huggingface.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceEndpoint](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint.html#langchain_community.llms.huggingface_endpoint.HuggingFaceEndpoint), [langchain_community...HuggingFaceTextGenInference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference.html#langchain_community.llms.huggingface_text_gen_inference.HuggingFaceTextGenInference)
 
 ## Self-Discover: Large Language Models Self-Compose Reasoning Structures
 
-- **arXiv id:** 2402.03620v1
+- **arXiv id:** [2402.03620v1](http://arxiv.org/abs/2402.03620v1)  **Published Date:** 2024-02-06
 - **Title:** Self-Discover: Large Language Models Self-Compose Reasoning Structures
 - **Authors:** Pei Zhou, Jay Pujara, Xiang Ren,  et al.
-- **Published Date:** 2024-02-06
-- **URL:** http://arxiv.org/abs/2402.03620v1
 - **LangChain:**
 
    - **Cookbook:** [self-discover](https://github.com/langchain-ai/langchain/blob/master/cookbook/self-discover.ipynb)
@@ -70,11 +71,9 @@ commonalities with human reasoning patterns.
                 
 ## RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
 
-- **arXiv id:** 2401.18059v1
+- **arXiv id:** [2401.18059v1](http://arxiv.org/abs/2401.18059v1)  **Published Date:** 2024-01-31
 - **Title:** RAPTOR: Recursive Abstractive Processing for Tree-Organized Retrieval
 - **Authors:** Parth Sarthi, Salman Abdullah, Aditi Tuli,  et al.
-- **Published Date:** 2024-01-31
-- **URL:** http://arxiv.org/abs/2401.18059v1
 - **LangChain:**
 
    - **Cookbook:** [RAPTOR](https://github.com/langchain-ai/langchain/blob/master/cookbook/RAPTOR.ipynb)
@@ -96,11 +95,9 @@ benchmark by 20% in absolute accuracy.
                 
 ## Corrective Retrieval Augmented Generation
 
-- **arXiv id:** 2401.15884v2
+- **arXiv id:** [2401.15884v2](http://arxiv.org/abs/2401.15884v2)  **Published Date:** 2024-01-29
 - **Title:** Corrective Retrieval Augmented Generation
 - **Authors:** Shi-Qi Yan, Jia-Chen Gu, Yun Zhu,  et al.
-- **Published Date:** 2024-01-29
-- **URL:** http://arxiv.org/abs/2401.15884v2
 - **LangChain:**
 
    - **Cookbook:** [langgraph_crag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_crag.ipynb)
@@ -126,11 +123,9 @@ performance of RAG-based approaches.
                 
 ## Mixtral of Experts
 
-- **arXiv id:** 2401.04088v1
+- **arXiv id:** [2401.04088v1](http://arxiv.org/abs/2401.04088v1)  **Published Date:** 2024-01-08
 - **Title:** Mixtral of Experts
 - **Authors:** Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux,  et al.
-- **Published Date:** 2024-01-08
-- **URL:** http://arxiv.org/abs/2401.04088v1
 - **LangChain:**
 
    - **Cookbook:** [together_ai](https://github.com/langchain-ai/langchain/blob/master/cookbook/together_ai.ipynb)
@@ -152,11 +147,9 @@ the base and instruct models are released under the Apache 2.0 license.
                 
 ## Dense X Retrieval: What Retrieval Granularity Should We Use?
 
-- **arXiv id:** 2312.06648v2
+- **arXiv id:** [2312.06648v2](http://arxiv.org/abs/2312.06648v2)  **Published Date:** 2023-12-11
 - **Title:** Dense X Retrieval: What Retrieval Granularity Should We Use?
 - **Authors:** Tong Chen, Hongwei Wang, Sihao Chen,  et al.
-- **Published Date:** 2023-12-11
-- **URL:** http://arxiv.org/abs/2312.06648v2
 - **LangChain:**
 
    - **Template:** [propositional-retrieval](https://python.langchain.com/docs/templates/propositional-retrieval)
@@ -181,11 +174,9 @@ information.
                 
 ## Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models
 
-- **arXiv id:** 2311.09210v1
+- **arXiv id:** [2311.09210v1](http://arxiv.org/abs/2311.09210v1)  **Published Date:** 2023-11-15
 - **Title:** Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models
 - **Authors:** Wenhao Yu, Hongming Zhang, Xiaoman Pan,  et al.
-- **Published Date:** 2023-11-15
-- **URL:** http://arxiv.org/abs/2311.09210v1
 - **LangChain:**
 
    - **Template:** [chain-of-note-wiki](https://python.langchain.com/docs/templates/chain-of-note-wiki)
@@ -215,11 +206,9 @@ outside the pre-training knowledge scope.
                 
 ## Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection
 
-- **arXiv id:** 2310.11511v1
+- **arXiv id:** [2310.11511v1](http://arxiv.org/abs/2310.11511v1)  **Published Date:** 2023-10-17
 - **Title:** Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection
 - **Authors:** Akari Asai, Zeqiu Wu, Yizhong Wang,  et al.
-- **Published Date:** 2023-10-17
-- **URL:** http://arxiv.org/abs/2310.11511v1
 - **LangChain:**
 
    - **Cookbook:** [langgraph_self_rag](https://github.com/langchain-ai/langchain/blob/master/cookbook/langgraph_self_rag.ipynb)
@@ -248,11 +237,9 @@ to these models.
                 
 ## Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models
 
-- **arXiv id:** 2310.06117v2
+- **arXiv id:** [2310.06117v2](http://arxiv.org/abs/2310.06117v2)  **Published Date:** 2023-10-09
 - **Title:** Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models
 - **Authors:** Huaixiu Steven Zheng, Swaroop Mishra, Xinyun Chen,  et al.
-- **Published Date:** 2023-10-09
-- **URL:** http://arxiv.org/abs/2310.06117v2
 - **LangChain:**
 
    - **Template:** [stepback-qa-prompting](https://python.langchain.com/docs/templates/stepback-qa-prompting)
@@ -271,11 +258,9 @@ and 11% respectively, TimeQA by 27%, and MuSiQue by 7%.
                 
 ## Llama 2: Open Foundation and Fine-Tuned Chat Models
 
-- **arXiv id:** 2307.09288v2
+- **arXiv id:** [2307.09288v2](http://arxiv.org/abs/2307.09288v2)  **Published Date:** 2023-07-18
 - **Title:** Llama 2: Open Foundation and Fine-Tuned Chat Models
 - **Authors:** Hugo Touvron, Louis Martin, Kevin Stone,  et al.
-- **Published Date:** 2023-07-18
-- **URL:** http://arxiv.org/abs/2307.09288v2
 - **LangChain:**
 
    - **Cookbook:** [Semi_Structured_RAG](https://github.com/langchain-ai/langchain/blob/master/cookbook/Semi_Structured_RAG.ipynb)
@@ -292,11 +277,9 @@ contribute to the responsible development of LLMs.
                 
 ## Query Rewriting for Retrieval-Augmented Large Language Models
 
-- **arXiv id:** 2305.14283v3
+- **arXiv id:** [2305.14283v3](http://arxiv.org/abs/2305.14283v3)  **Published Date:** 2023-05-23
 - **Title:** Query Rewriting for Retrieval-Augmented Large Language Models
 - **Authors:** Xinbei Ma, Yeyun Gong, Pengcheng He,  et al.
-- **Published Date:** 2023-05-23
-- **URL:** http://arxiv.org/abs/2305.14283v3
 - **LangChain:**
 
    - **Template:** [rewrite-retrieve-read](https://python.langchain.com/docs/templates/rewrite-retrieve-read)
@@ -322,11 +305,9 @@ for retrieval-augmented LLM.
                 
 ## Large Language Model Guided Tree-of-Thought
 
-- **arXiv id:** 2305.08291v1
+- **arXiv id:** [2305.08291v1](http://arxiv.org/abs/2305.08291v1)  **Published Date:** 2023-05-15
 - **Title:** Large Language Model Guided Tree-of-Thought
 - **Authors:** Jieyi Long
-- **Published Date:** 2023-05-15
-- **URL:** http://arxiv.org/abs/2305.08291v1
 - **LangChain:**

----------------------------------------

File: docs/docs/how_to/chat_model_caching.ipynb
Status: modified
Changes: +2 -2
Diff:
@@ -63,7 +63,7 @@
    "outputs": [],
    "source": [
     "# <!-- ruff: noqa: F821 -->\n",
-    "from langchain.globals import set_llm_cache"
+    "from langchain_core.globals import set_llm_cache"
    ]
   },
   {
@@ -103,7 +103,7 @@

----------------------------------------

File: docs/docs/how_to/document_loader_custom.ipynb
Status: modified
Changes: +4 -4
Diff:
@@ -63,7 +63,7 @@
     "* The `load` methods is a convenience method meant solely for prototyping work -- it just invokes `list(self.lazy_load())`.\n",
     "* The `alazy_load` has a default implementation that will delegate to `lazy_load`. If you're using async, we recommend overriding the default implementation and providing a native async implementation.\n",
     "\n",
-    "::: {.callout-important}\n",
+    ":::{.callout-important}\n",
     "When implementing a document loader do **NOT** provide parameters via the `lazy_load` or `alazy_load` methods.\n",
     "\n",
     "All configuration is expected to be passed through the initializer (__init__). This was a design choice made by LangChain to make sure that once a document loader has been instantiated it has all the information needed to load documents.\n",
@@ -235,7 +235,7 @@
    "id": "56cb443e-f987-4386-b4ec-975ee129adb2",
    "metadata": {},

----------------------------------------

File: docs/docs/how_to/document_loader_json.mdx
Status: modified
Changes: +1 -1
Diff:
@@ -182,7 +182,7 @@ pprint(data)
 </CodeOutputBlock>
 
 
-Another option is set `jq_schema='.'` and provide `content_key`:
+Another option is to set `jq_schema='.'` and provide `content_key`:
 
 ```python
 loader = JSONLoader(

----------------------------------------

File: docs/docs/how_to/document_loader_pdf.ipynb
Status: modified
Changes: +3 -567

----------------------------------------

File: docs/docs/how_to/functions.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -28,7 +28,7 @@
     "\n",
     "You can use arbitrary functions as [Runnables](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.Runnable.html#langchain_core.runnables.base.Runnable). This is useful for formatting or when you need functionality not provided by other LangChain components, and custom functions used as Runnables are called [`RunnableLambdas`](https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.base.RunnableLambda.html).\n",
     "\n",
-    "Note that all inputs to these functions need to be a SINGLE argument. If you have a function that accepts multiple arguments, you should write a wrapper that accepts a single dict input and unpacks it into multiple argument.\n",
+    "Note that all inputs to these functions need to be a SINGLE argument. If you have a function that accepts multiple arguments, you should write a wrapper that accepts a single dict input and unpacks it into multiple arguments.\n",
     "\n",
     "This guide will cover:\n",
     "\n",

----------------------------------------

File: docs/docs/how_to/graph_mapping.ipynb
Status: modified
Changes: +4 -1
Diff:
@@ -364,7 +364,10 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.chains.graph_qa.cypher_utils import CypherQueryCorrector, Schema\n",
+    "from langchain_community.chains.graph_qa.cypher_utils import (\n",
+    "    CypherQueryCorrector,\n",
+    "    Schema,\n",
+    ")\n",
     "\n",

----------------------------------------

File: docs/docs/how_to/llm_caching.ipynb
Status: modified
Changes: +2 -2
Diff:
@@ -36,7 +36,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.globals import set_llm_cache\n",
+    "from langchain_core.globals import set_llm_cache\n",
     "from langchain_openai import OpenAI\n",
     "\n",
     "# To make the caching really obvious, lets use a slower and older model.\n",
@@ -71,7 +71,7 @@

----------------------------------------

File: docs/docs/how_to/qa_chat_history_how_to.ipynb
Status: modified
Changes: +4 -4
Diff:
@@ -721,9 +721,9 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
+    "from langgraph.checkpoint.memory import MemorySaver\n",
     "\n",
-    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
+    "memory = MemorySaver()\n",
     "\n",

----------------------------------------

File: docs/docs/how_to/query_constructing_filters.ipynb
Status: modified
Changes: +2 -2
Diff:
@@ -38,8 +38,8 @@
     "    Operator,\n",
     "    StructuredQuery,\n",
     ")\n",
-    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
-    "from langchain.retrievers.self_query.elasticsearch import ElasticsearchTranslator\n",
+    "from langchain_community.query_constructors.chroma import ChromaTranslator\n",
+    "from langchain_community.query_constructors.elasticsearch import ElasticsearchTranslator\n",
     "from langchain_core.pydantic_v1 import BaseModel"
    ]

----------------------------------------

File: docs/docs/how_to/self_query.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -512,7 +512,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.retrievers.self_query.chroma import ChromaTranslator\n",
+    "from langchain_community.query_constructors.chroma import ChromaTranslator\n",
     "\n",
     "retriever = SelfQueryRetriever(\n",
     "    query_constructor=query_constructor,\n",

----------------------------------------

File: docs/docs/how_to/semantic-chunker.ipynb
Status: modified
Changes: +11 -11
Diff:
@@ -299,16 +299,16 @@
   },
   {
    "cell_type": "markdown",
+   "id": "423c6e099e94ca69",
+   "metadata": {
+    "collapsed": false
+   },
    "source": [
     "### Gradient\n",
     "\n",
     "In this method, the gradient of distance is used to split chunks along with the percentile method.\n",
     "This method is useful when chunks are highly correlated with each other or specific to a domain e.g. legal or medical. The idea is to apply anomaly detection on gradient array so that the distribution become wider and easy to identify boundaries in highly semantic data."
-   ],
-   "metadata": {
-    "collapsed": false
-   },
-   "id": "423c6e099e94ca69"
+   ]

----------------------------------------

File: docs/docs/integrations/chat/index.mdx
Status: added
Changes: +32 -0
Diff:
@@ -0,0 +1,32 @@
+---
+sidebar_position: 0
+sidebar_class_name: hidden
+keywords: [compatibility]
+---
+
+# Chat models
+
+[Chat models](/docs/concepts/#chat-models) are language models that use a sequence of [messages](/docs/concepts/#messages) as inputs and return messages as outputs (as opposed to using plain text). These are generally newer models.
+

----------------------------------------

File: docs/docs/integrations/chat/llamacpp.ipynb
Status: modified
Changes: +19 -5
Diff:
@@ -4,9 +4,23 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "# ChatLlamaCpp\n",
-    "\n",
-    "This notebook provides a quick overview for getting started with chat model intergrated with [llama cpp python](https://github.com/abetlen/llama-cpp-python)."
+    "# Llama.cpp\n",
+    "\n",
+    ">[llama.cpp python](https://github.com/abetlen/llama-cpp-python) library is a simple Python bindings for `@ggerganov`\n",
+    ">[llama.cpp](https://github.com/ggerganov/llama.cpp).\n",
+    ">\n",
+    ">This package provides:\n",
+    ">\n",
+    "> - Low-level access to C API via ctypes interface.\n",

----------------------------------------

File: docs/docs/integrations/chat/octoai.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -99,7 +99,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.11.7"
+   "version": "3.10.12"
   },
   "vscode": {
    "interpreter": {

----------------------------------------

File: docs/docs/integrations/chat/openai.ipynb
Status: modified
Changes: +26 -25
Diff:
@@ -151,7 +151,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 3,
    "id": "ce16ad78-8e6f-48cd-954e-98be75eb5836",
    "metadata": {
     "tags": []
@@ -160,10 +160,10 @@
     {
      "data": {
       "text/plain": [
-       "AIMessage(content=\"J'adore la programmation.\", response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 31, 'total_tokens': 36}, 'model_name': 'gpt-4o', 'system_fingerprint': 'fp_43dfabdef1', 'finish_reason': 'stop', 'logprobs': None}, id='run-012cffe2-5d3d-424d-83b5-51c6d4a593d1-0', usage_metadata={'input_tokens': 31, 'output_tokens': 5, 'total_tokens': 36})"
+       "AIMessage(content=\"J'adore la programmation.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 31, 'total_tokens': 36}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'stop', 'logprobs': None}, id='run-63219b22-03e3-4561-8cc4-78b7c7c3a3ca-0', usage_metadata={'input_tokens': 31, 'output_tokens': 5, 'total_tokens': 36})"
       ]
      },
-     "execution_count": 6,
+     "execution_count": 3,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -182,7 +182,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
+   "execution_count": 4,
    "id": "2cd224b8-4499-41fb-a604-d53a7ff17b2e",
    "metadata": {},
    "outputs": [
@@ -210,7 +210,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 8,
+   "execution_count": 5,
    "id": "fbb043e6",
    "metadata": {
     "tags": []
@@ -219,10 +219,10 @@
     {
      "data": {
       "text/plain": [
-       "AIMessage(content='Ich liebe Programmieren.', response_metadata={'token_usage': {'completion_tokens': 5, 'prompt_tokens': 26, 'total_tokens': 31}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': 'fp_b28b39ffa8', 'finish_reason': 'stop', 'logprobs': None}, id='run-94fa6741-c99b-4513-afce-c3f562631c79-0')"
+       "AIMessage(content='Ich liebe das Programmieren.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 6, 'prompt_tokens': 26, 'total_tokens': 32}, 'model_name': 'gpt-4o-2024-05-13', 'system_fingerprint': 'fp_3aa7262c27', 'finish_reason': 'stop', 'logprobs': None}, id='run-350585e1-16ca-4dad-9460-3d9e7e49aaf1-0', usage_metadata={'input_tokens': 26, 'output_tokens': 6, 'total_tokens': 32})"
       ]
      },
-     "execution_count": 8,
+     "execution_count": 5,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -274,7 +274,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
+   "execution_count": 6,
    "id": "b7ea7690-ec7a-4337-b392-e87d1f39a6ec",

----------------------------------------

File: docs/docs/integrations/chat/perplexity.ipynb
Status: modified
Changes: +22 -8
Diff:
@@ -17,7 +17,7 @@
    "source": [
     "# ChatPerplexity\n",
     "\n",
-    "This notebook covers how to get started with Perplexity chat models."
+    "This notebook covers how to get started with `Perplexity` chat models."
    ]
   },
   {
@@ -37,17 +37,31 @@
     "from langchain_core.prompts import ChatPromptTemplate"
    ]
   },
+  {
+   "cell_type": "markdown",
+   "id": "b26e2035-2f81-4451-ba44-fa2e2d5aeb62",
+   "metadata": {},
+   "source": [

----------------------------------------

File: docs/docs/integrations/chat/together.ipynb
Status: modified
Changes: +14 -26
Diff:
@@ -53,7 +53,8 @@
     "import getpass\n",
     "import os\n",
     "\n",
-    "os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter your Together API key: \")"
+    "if \"TOGETHER_API_KEY\" not in os.environ:\n",
+    "    os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter your Together API key: \")"
    ]
   },
   {
@@ -87,21 +88,10 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": null,
    "id": "652d6238-1f87-422a-b135-f5abbb8652fc",
    "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "\n",
-      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.1.2\u001b[0m\n",
-      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
-      "Note: you may need to restart the kernel to use updated packages.\n"
-     ]
-    }
-   ],
+   "outputs": [],
    "source": [
     "%pip install -qU langchain-together"
    ]
@@ -113,14 +103,12 @@
    "source": [
     "## Instantiation\n",

----------------------------------------

File: docs/docs/integrations/document_loaders/bshtml.ipynb
Status: added
Changes: +243 -0
Diff:
@@ -0,0 +1,243 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# BSHTMLLoader\n",
+    "\n",
+    "\n",
+    "This notebook provides a quick overview for getting started with BeautifulSoup4 [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html).\n",
+    "\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "\n",
+    "| Class | Package | Local | Serializable | JS support|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [BSHTMLLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.html_bs.BSHTMLLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ❌ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| BSHTMLLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access BSHTMLLoader document loader you'll need to install the `langchain-community` integration package and the `bs4` python package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed to use the `BSHTMLLoader` class."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community** and **bs4**."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install -qU langchain_community bs4"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Initialization\n",
+    "\n",
+    "Now we can instantiate our model object and load documents:\n",
+    "\n",
+    "- TODO: Update model instantiation with relevant params."
+   ]
+  },
+  {

----------------------------------------

File: docs/docs/integrations/document_loaders/example_data/example.md
Status: added
Changes: +55 -0
Diff:
@@ -0,0 +1,55 @@
+# Sample Markdown Document
+
+## Introduction
+
+Welcome to this sample Markdown document. Markdown is a lightweight markup language used for formatting text. It's widely used for documentation, readme files, and more.
+
+## Features
+
+### Headers
+
+Markdown supports multiple levels of headers:
+
+- **Header 1**: `# Header 1`
+- **Header 2**: `## Header 2`
+- **Header 3**: `### Header 3`
+
+### Lists

----------------------------------------

File: docs/docs/integrations/document_loaders/example_data/facebook_chat.json
Status: modified
Changes: +1 -0
Diff:
@@ -30,6 +30,7 @@
         {
             "sender_name": "User 2",
             "timestamp_ms": 1675595060730,
+            "content": "",
             "photos": [
                 {"uri": "url_of_some_picture.jpg", "creation_timestamp": 1675595059}
             ]

----------------------------------------

File: docs/docs/integrations/document_loaders/firecrawl.ipynb
Status: modified
Changes: +34 -14
Diff:
@@ -35,7 +35,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -78,7 +78,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -102,7 +102,7 @@
     {
      "data": {
       "text/plain": [
-       "Document(metadata={'ogUrl': 'https://www.firecrawl.dev/', 'title': 'Home - Firecrawl', 'robots': 'follow, index', 'ogImage': 'https://www.firecrawl.dev/og.png?123', 'ogTitle': 'Firecrawl', 'sitemap': {'lastmod': '2024-08-02T12:09:44.527Z', 'priority': 0.5, 'changefreq': 'weekly'}, 'keywords': 'Firecrawl,Markdown,Data,Mendable,Langchain', 'sourceURL': 'https://www.firecrawl.dev/', 'ogSiteName': 'Firecrawl', 'description': 'Firecrawl crawls and converts any website into clean markdown.', 'ogDescription': 'Turn any website into LLM-ready data.', 'pageStatusCode': 500, 'ogLocaleAlternate': []}, page_content='Introducing [Smart Crawl!](https://www.firecrawl.dev/smart-crawl)\\n Join the waitlist to turn any website into an API with AI\\n\\n\\n\\n[🔥 Firecrawl](/)\\n\\n*   [Playground](/playground)\\n    \\n*   [Docs](https://docs.firecrawl.dev)\\n    \\n*   [Pricing](/pricing)\\n    \\n*   [Blog](/blog)\\n    \\n*   Beta Features\\n\\n[Log In](/signin)\\n[Log In](/signin)\\n[Sign Up](/signin/signup)\\n 8.6k\\n\\n[💥 Get 2 months free with yearly plan](/pricing)\\n\\nTurn websites into  \\n_LLM-ready_ data\\n=====================================\\n\\nPower your AI apps with clean data crawled from any website. It\\'s also open-source.\\n\\nStart for free (500 credits)Start for free[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\n\\nA product by\\n\\n[![Mendable Logo](https://www.firecrawl.dev/images/mendable_logo_transparent.png)Mendable](https://mendable.ai)\\n\\n![Example Webpage](https://www.firecrawl.dev/multiple-websites.png)\\n\\nCrawl, Scrape, Clean\\n--------------------\\n\\nWe crawl all accessible subpages and give you clean markdown for each. No sitemap required.\\n\\n    \\n      [\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/\",\\\\\\n          \"markdown\": \"## Welcome to Firecrawl\\\\\\n            Firecrawl is a web scraper that allows you to extract the content of a webpage.\"\\\\\\n        },\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/features\",\\\\\\n          \"markdown\": \"## Features\\\\\\n            Discover how Firecrawl\\'s cutting-edge features can \\\\\\n            transform your data operations.\"\\\\\\n        },\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/pricing\",\\\\\\n          \"markdown\": \"## Pricing Plans\\\\\\n            Choose the perfect plan that fits your needs.\"\\\\\\n        },\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/about\",\\\\\\n          \"markdown\": \"## About Us\\\\\\n            Learn more about Firecrawl\\'s mission and the \\\\\\n            team behind our innovative platform.\"\\\\\\n        }\\\\\\n      ]\\n      \\n\\nNote: The markdown has been edited for display purposes.\\n\\nTrusted by Top Companies\\n------------------------\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/zapier.png)](https://www.zapier.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/gamma.svg)](https://gamma.app)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/nvidia-com.png)](https://www.nvidia.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/teller-io.svg)](https://www.teller.io)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/stackai.svg)](https://www.stack-ai.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/palladiumdigital-co-uk.svg)](https://www.palladiumdigital.co.uk)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/worldwide-casting-com.svg)](https://www.worldwide-casting.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/open-gov-sg.png)](https://www.open.gov.sg)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/bain-com.svg)](https://www.bain.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/demand-io.svg)](https://www.demand.io)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/nocodegarden-io.png)](https://www.nocodegarden.io)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/cyberagent-co-jp.svg)](https://www.cyberagent.co.jp)\\n\\nIntegrate today\\n---------------\\n\\nEnhance your applications with top-tier web scraping and crawling capabilities.\\n\\n#### Scrape\\n\\nExtract markdown or structured data from websites quickly and efficiently.\\n\\n#### Crawling\\n\\nNavigate and retrieve data from all accessible subpages, even without a sitemap.\\n\\nNode.js\\n\\nPython\\n\\ncURL\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n// npm install @mendable/firecrawl-js  \\n  \\nimport FirecrawlApp from \\'@mendable/firecrawl-js\\';  \\n  \\nconst app \\\\= new FirecrawlApp({ apiKey: \"fc-YOUR\\\\_API\\\\_KEY\" });  \\n  \\n// Scrape a website:  \\nconst scrapeResult \\\\= await app.scrapeUrl(\\'firecrawl.dev\\');  \\n  \\nconsole.log(scrapeResult.data.markdown)\\n\\n#### Use well-known tools\\n\\nAlready fully integrated with the greatest existing tools and workflows.\\n\\n[![LlamaIndex](https://www.firecrawl.dev/logos/llamaindex.svg)](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/#using-firecrawl-reader/)\\n[![Langchain](https://www.firecrawl.dev/integrations/langchain.png)](https://python.langchain.com/v0.2/docs/integrations/document_loaders/firecrawl/)\\n[![Dify](https://www.firecrawl.dev/logos/dify.png)](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl/)\\n[![Dify](https://www.firecrawl.dev/integrations/langflow_2.png)](https://www.langflow.org/)\\n[![Flowise](https://www.firecrawl.dev/integrations/flowise.png)](https://flowiseai.com/)\\n[![CrewAI](https://www.firecrawl.dev/integrations/crewai.png)](https://crewai.com/)\\n\\n#### Start for free, scale easily\\n\\nKick off your journey for free and scale seamlessly as your project expands.\\n\\n[Try it out](/signin/signup)\\n\\n#### Open-source\\n\\nDeveloped transparently and collaboratively. Join our community of contributors.\\n\\n[Check out our repo](https://github.com/mendableai/firecrawl)\\n\\nWe handle the hard stuff\\n------------------------\\n\\nRotating proxies, caching, rate limits, js-blocked content and more\\n\\n#### Crawling\\n\\nFirecrawl crawls all accessible subpages, even without a sitemap.\\n\\n#### Dynamic content\\n\\nFirecrawl gathers data even if a website uses javascript to render content.\\n\\n#### To Markdown\\n\\nFirecrawl returns clean, well formatted markdown - ready for use in LLM applications\\n\\n#### Crawling Orchestration\\n\\nFirecrawl orchestrates the crawling process in parallel for the fastest results.\\n\\n#### Caching\\n\\nFirecrawl caches content, so you don\\'t have to wait for a full scrape unless new content exists.\\n\\n#### Built for AI\\n\\nBuilt by LLM engineers, for LLM engineers. Giving you clean data the way you want it.\\n\\nOur wall of love\\n\\nDon\\'t take our word for it\\n--------------------------\\n\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\n\\nGreg Kamradt\\n\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\n\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\n\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\n\\nAmit Naik\\n\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\n\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. 👏\\n\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\n\\nJerry Liu\\n\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\n\\nFirecrawl is awesome 🔥 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\n\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\n\\nBardia Pourvakil\\n\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\n\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\'t recommend them enough.\\n\\n![latentsauce 🧘🏽](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\n\\nlatentsauce 🧘🏽\\n\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\n\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl ❤️❤️❤️\\n\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\n\\nGreg Kamradt\\n\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\n\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\n\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\n\\nAmit Naik\\n\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\n\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. 👏\\n\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\n\\nJerry Liu\\n\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\n\\nFirecrawl is awesome 🔥 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\n\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\n\\nBardia Pourvakil\\n\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\n\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\'t recommend them enough.\\n\\n![latentsauce 🧘🏽](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\n\\nlatentsauce 🧘🏽\\n\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\n\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl ❤️❤️❤️\\n\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\n\\nMichael Ning\\n\\n[](#)\\n\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\n\\n![Alex Reibman 🖇️](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\n\\nAlex Reibman 🖇️\\n\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\n\\nMoved our internal agent\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\n\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\n\\nMichael\\n\\n[@michael\\\\_chomsky](#)\\n\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\n\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\n\\nPaul Scott\\n\\n[@palebluepaul](https://twitter.com/palebluepaul)\\n\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\n\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\n\\nMichael Ning\\n\\n[](#)\\n\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\n\\n![Alex Reibman 🖇️](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\n\\nAlex Reibman 🖇️\\n\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\n\\nMoved our internal agent\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\n\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\n\\nMichael\\n\\n[@michael\\\\_chomsky](#)\\n\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\n\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\n\\nPaul Scott\\n\\n[@palebluepaul](https://twitter.com/palebluepaul)\\n\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\n\\nFlexible Pricing\\n----------------\\n\\nStart for free, then scale as you grow\\n\\nYearly (17% off)Yearly (2 months free)Monthly\\n\\nFree Plan\\n---------\\n\\n500 credits\\n\\n$0/month\\n\\n*   Scrape 500 pages\\n*   5 /scrape per min\\n*   1 /crawl per min\\n\\nGet Started\\n\\nHobby\\n-----\\n\\n3,000 credits\\n\\n$16/month\\n\\n*   Scrape 3,000 pages\\n*   10 /scrape per min\\n*   3 /crawl per min\\n\\nSubscribe\\n\\nStandardMost Popular\\n--------------------\\n\\n100,000 credits\\n\\n$83/month\\n\\n*   Scrape 100,000 pages\\n*   50 /scrape per min\\n*   10 /crawl per min\\n\\nSubscribe\\n\\nGrowth\\n------\\n\\n500,000 credits\\n\\n$333/month\\n\\n*   Scrape 500,000 pages\\n*   500 /scrape per min\\n*   50 /crawl per min\\n*   Priority Support\\n\\nSubscribe\\n\\nEnterprise Plan\\n---------------\\n\\nUnlimited credits. Custom RPMs.\\n\\nTalk to us\\n\\n*   Top priority support\\n*   Feature Acceleration\\n*   SLAs\\n*   Account Manager\\n*   Custom rate limits volume\\n*   Custom concurrency limits\\n*   Beta features access\\n*   CEO\\'s number\\n\\n\\\\* a /scrape refers to the [scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\n API endpoint.\\n\\n\\\\* a /crawl refers to the [crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl)\\n API endpoint.\\n\\nScrape Credits\\n--------------\\n\\nScrape credits are consumed for each API request, varying by endpoint and feature.\\n\\n| Features | Credits per page |\\n| --- | --- |\\n| Scrape(/scrape) | 1   |\\n| Crawl(/crawl) | 1   |\\n| Search(/search) | 1   |\\n| Scrape + LLM extraction (/scrape) | 50  |\\n\\n[](/)\\n\\nReady to _Build?_\\n-----------------\\n\\nStart scraping web data for your AI apps today.  \\nNo credit card needed.\\n\\n[Get Started](/signin)\\n\\n[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\n\\nFAQ\\n---\\n\\nFrequently asked questions about Firecrawl\\n\\n#### General\\n\\nWhat is Firecrawl?\\n\\nFirecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API. Ideal for AI companies looking to empower their LLM applications with web data.\\n\\nWhat sites work?\\n\\nFirecrawl is best suited for business websites, docs and help centers. We currently don\\'t support social media platforms.\\n\\nWho can benefit from using Firecrawl?\\n\\nFirecrawl is tailored for LLM engineers, data scientists, AI researchers, and developers looking to harness web data for training machine learning models, market research, content aggregation, and more. It simplifies the data preparation process, allowing professionals to focus on insights and model development.\\n\\nIs Firecrawl open-source?\\n\\nYes, it is. You can check out the repository on GitHub. Keep in mind that this repository is currently in its early stages of development. We are in the process of merging custom modules into this mono repository.\\n\\n#### Scraping & Crawling\\n\\nHow does Firecrawl handle dynamic content on websites?\\n\\nUnlike traditional web scrapers, Firecrawl is equipped to handle dynamic content rendered with JavaScript. It ensures comprehensive data collection from all accessible subpages, making it a reliable tool for scraping websites that rely heavily on JS for content delivery.\\n\\nWhy is it not crawling all the pages?\\n\\nThere are a few reasons why Firecrawl may not be able to crawl all the pages of a website. Some common reasons include rate limiting, and anti-scraping mechanisms, disallowing the crawler from accessing certain pages. If you\\'re experiencing issues with the crawler, please reach out to our support team at hello@firecrawl.com.\\n\\nCan Firecrawl crawl websites without a sitemap?\\n\\nYes, Firecrawl can access and crawl all accessible subpages of a website, even in the absence of a sitemap. This feature enables users to gather data from a wide array of web sources with minimal setup.\\n\\nWhat formats can Firecrawl convert web data into?\\n\\nFirecrawl specializes in converting web data into clean, well-formatted markdown. This format is particularly suited for LLM applications, offering a structured yet flexible way to represent web content.\\n\\nHow does Firecrawl ensure the cleanliness of the data?\\n\\nFirecrawl employs advanced algorithms to clean and structure the scraped data, removing unnecessary elements and formatting the content into readable markdown. This process ensures that the data is ready for use in LLM applications without further preprocessing.\\n\\nIs Firecrawl suitable for large-scale data scraping projects?\\n\\nAbsolutely. Firecrawl offers various pricing plans, including a Scale plan that supports scraping of millions of pages. With features like caching and scheduled syncs, it\\'s designed to efficiently handle large-scale data scraping and continuous updates, making it ideal for enterprises and large projects.\\n\\nDoes it respect robots.txt?\\n\\nYes, Firecrawl crawler respects the rules set in a website\\'s robots.txt file. If you notice any issues with the way Firecrawl interacts with your website, you can adjust the robots.txt file to control the crawler\\'s behavior. Firecrawl user agent name is \\'FirecrawlAgent\\'. If you notice any behavior that is not expected, please let us know at hello@firecrawl.com.\\n\\nWhat measures does Firecrawl take to handle web scraping challenges like rate limits and caching?\\n\\nFirecrawl is built to navigate common web scraping challenges, including reverse proxies, rate limits, and caching. It smartly manages requests and employs caching techniques to minimize bandwidth usage and avoid triggering anti-scraping mechanisms, ensuring reliable data collection.\\n\\nDoes Firecrawl handle captcha or authentication?\\n\\nFirecrawl avoids captcha by using stealth proxyies. When it encounters captcha, it attempts to solve it automatically, but this is not always possible. We are working to add support for more captcha solving methods. Firecrawl can handle authentication by providing auth headers to the API.\\n\\n#### API Related\\n\\nWhere can I find my API key?\\n\\nClick on the dashboard button on the top navigation menu when logged in and you will find your API key in the main screen and under API Keys.\\n\\n#### Billing\\n\\nIs Firecrawl free?\\n\\nFirecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Standard or Scale plans for more credits.\\n\\nIs there a pay per use plan instead of monthly?\\n\\nNo we do not currently offer a pay per use plan, instead you can upgrade to our Standard or Growth plans for more credits and higher rate limits.\\n\\nHow many credit does scraping, crawling, and extraction cost?\\n\\nScraping costs 1 credit per page. Crawling costs 1 credit per page.\\n\\nDo you charge for failed requests (scrape, crawl, extract)?\\n\\nWe do not charge for any failed requests (scrape, crawl, extract). Please contact support at help@firecrawl.dev if you have any questions.\\n\\nWhat payment methods do you accept?\\n\\nWe accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.\\n\\n[🔥](/)\\n\\n© A product by Mendable.ai - All rights reserved.\\n\\n[StatusStatus](https://firecrawl.betteruptime.com)\\n[Terms of ServiceTerms of Service](/terms-of-service)\\n[Privacy PolicyPrivacy Policy](/privacy-policy)\\n\\n[Twitter](https://twitter.com/mendableai)\\n[GitHub](https://github.com/mendableai)\\n[Discord](https://discord.gg/gSmWdAkdwd)\\n\\n###### Helpful Links\\n\\n*   [Status](https://firecrawl.betteruptime.com/)\\n    \\n*   [Pricing](/pricing)\\n    \\n*   [Blog](https://www.firecrawl.dev/blog)\\n    \\n*   [Docs](https://docs.firecrawl.dev)\\n    \\n\\nBacked by![Y Combinator Logo](https://www.firecrawl.dev/images/yc.svg)\\n\\n![SOC 2 Type II](https://www.firecrawl.dev/soc2type2badge.png)\\n\\n###### Resources\\n\\n*   [Community](#0)\\n    \\n*   [Terms of service](#0)\\n    \\n*   [Collaboration features](#0)\\n    \\n\\n###### Legals\\n\\n*   [Refund policy](#0)\\n    \\n*   [Terms & Conditions](#0)\\n    \\n*   [Privacy policy](#0)\\n    \\n*   [Brand Kit](#0)')"
+       "Document(metadata={'ogUrl': 'https://www.firecrawl.dev/', 'title': 'Home - Firecrawl', 'robots': 'follow, index', 'ogImage': 'https://www.firecrawl.dev/og.png?123', 'ogTitle': 'Firecrawl', 'sitemap': {'lastmod': '2024-08-12T00:28:16.681Z', 'changefreq': 'weekly'}, 'keywords': 'Firecrawl,Markdown,Data,Mendable,Langchain', 'sourceURL': 'https://www.firecrawl.dev/', 'ogSiteName': 'Firecrawl', 'description': 'Firecrawl crawls and converts any website into clean markdown.', 'ogDescription': 'Turn any website into LLM-ready data.', 'pageStatusCode': 200, 'ogLocaleAlternate': []}, page_content='Introducing [Smart Crawl!](https://www.firecrawl.dev/smart-crawl)\\n Join the waitlist to turn any website into an API with AI\\n\\n\\n\\n[🔥 Firecrawl](/)\\n\\n*   [Playground](/playground)\\n    \\n*   [Docs](https://docs.firecrawl.dev)\\n    \\n*   [Pricing](/pricing)\\n    \\n*   [Blog](/blog)\\n    \\n*   Beta Features\\n\\n[Log In](/signin)\\n[Log In](/signin)\\n[Sign Up](/signin/signup)\\n 8.9k\\n\\n[💥 Get 2 months free with yearly plan](/pricing)\\n\\nTurn websites into  \\n_LLM-ready_ data\\n=====================================\\n\\nPower your AI apps with clean data crawled from any website. It\\'s also open-source.\\n\\nStart for free (500 credits)Start for free[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\n\\nA product by\\n\\n[![Mendable Logo](https://www.firecrawl.dev/images/mendable_logo_transparent.png)Mendable](https://mendable.ai)\\n\\n![Example Webpage](https://www.firecrawl.dev/multiple-websites.png)\\n\\nCrawl, Scrape, Clean\\n--------------------\\n\\nWe crawl all accessible subpages and give you clean markdown for each. No sitemap required.\\n\\n    \\n      [\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/\",\\\\\\n          \"markdown\": \"## Welcome to Firecrawl\\\\\\n            Firecrawl is a web scraper that allows you to extract the content of a webpage.\"\\\\\\n        },\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/features\",\\\\\\n          \"markdown\": \"## Features\\\\\\n            Discover how Firecrawl\\'s cutting-edge features can \\\\\\n            transform your data operations.\"\\\\\\n        },\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/pricing\",\\\\\\n          \"markdown\": \"## Pricing Plans\\\\\\n            Choose the perfect plan that fits your needs.\"\\\\\\n        },\\\\\\n        {\\\\\\n          \"url\": \"https://www.firecrawl.dev/about\",\\\\\\n          \"markdown\": \"## About Us\\\\\\n            Learn more about Firecrawl\\'s mission and the \\\\\\n            team behind our innovative platform.\"\\\\\\n        }\\\\\\n      ]\\n      \\n\\nNote: The markdown has been edited for display purposes.\\n\\nTrusted by Top Companies\\n------------------------\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/zapier.png)](https://www.zapier.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/gamma.svg)](https://gamma.app)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/nvidia-com.png)](https://www.nvidia.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/teller-io.svg)](https://www.teller.io)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/stackai.svg)](https://www.stack-ai.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/palladiumdigital-co-uk.svg)](https://www.palladiumdigital.co.uk)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/worldwide-casting-com.svg)](https://www.worldwide-casting.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/open-gov-sg.png)](https://www.open.gov.sg)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/bain-com.svg)](https://www.bain.com)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/demand-io.svg)](https://www.demand.io)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/nocodegarden-io.png)](https://www.nocodegarden.io)\\n\\n[![Customer Logo](https://www.firecrawl.dev/logos/cyberagent-co-jp.svg)](https://www.cyberagent.co.jp)\\n\\nIntegrate today\\n---------------\\n\\nEnhance your applications with top-tier web scraping and crawling capabilities.\\n\\n#### Scrape\\n\\nExtract markdown or structured data from websites quickly and efficiently.\\n\\n#### Crawling\\n\\nNavigate and retrieve data from all accessible subpages, even without a sitemap.\\n\\nNode.js\\n\\nPython\\n\\ncURL\\n\\n1\\n\\n2\\n\\n3\\n\\n4\\n\\n5\\n\\n6\\n\\n7\\n\\n8\\n\\n9\\n\\n10\\n\\n// npm install @mendable/firecrawl-js  \\n  \\nimport FirecrawlApp from \\'@mendable/firecrawl-js\\';  \\n  \\nconst app \\\\= new FirecrawlApp({ apiKey: \"fc-YOUR\\\\_API\\\\_KEY\" });  \\n  \\n// Scrape a website:  \\nconst scrapeResult \\\\= await app.scrapeUrl(\\'firecrawl.dev\\');  \\n  \\nconsole.log(scrapeResult.data.markdown)\\n\\n#### Use well-known tools\\n\\nAlready fully integrated with the greatest existing tools and workflows.\\n\\n[![LlamaIndex](https://www.firecrawl.dev/logos/llamaindex.svg)](https://docs.llamaindex.ai/en/stable/examples/data_connectors/WebPageDemo/#using-firecrawl-reader/)\\n[![Langchain](https://www.firecrawl.dev/integrations/langchain.png)](https://python.langchain.com/v0.2/docs/integrations/document_loaders/firecrawl/)\\n[![Dify](https://www.firecrawl.dev/logos/dify.png)](https://dify.ai/blog/dify-ai-blog-integrated-with-firecrawl/)\\n[![Dify](https://www.firecrawl.dev/integrations/langflow_2.png)](https://www.langflow.org/)\\n[![Flowise](https://www.firecrawl.dev/integrations/flowise.png)](https://flowiseai.com/)\\n[![CrewAI](https://www.firecrawl.dev/integrations/crewai.png)](https://crewai.com/)\\n\\n#### Start for free, scale easily\\n\\nKick off your journey for free and scale seamlessly as your project expands.\\n\\n[Try it out](/signin/signup)\\n\\n#### Open-source\\n\\nDeveloped transparently and collaboratively. Join our community of contributors.\\n\\n[Check out our repo](https://github.com/mendableai/firecrawl)\\n\\nWe handle the hard stuff\\n------------------------\\n\\nRotating proxies, caching, rate limits, js-blocked content and more\\n\\n#### Crawling\\n\\nFirecrawl crawls all accessible subpages, even without a sitemap.\\n\\n#### Dynamic content\\n\\nFirecrawl gathers data even if a website uses javascript to render content.\\n\\n#### To Markdown\\n\\nFirecrawl returns clean, well formatted markdown - ready for use in LLM applications\\n\\n#### Crawling Orchestration\\n\\nFirecrawl orchestrates the crawling process in parallel for the fastest results.\\n\\n#### Caching\\n\\nFirecrawl caches content, so you don\\'t have to wait for a full scrape unless new content exists.\\n\\n#### Built for AI\\n\\nBuilt by LLM engineers, for LLM engineers. Giving you clean data the way you want it.\\n\\nOur wall of love\\n\\nDon\\'t take our word for it\\n--------------------------\\n\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\n\\nGreg Kamradt\\n\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\n\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\n\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\n\\nAmit Naik\\n\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\n\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. 👏\\n\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\n\\nJerry Liu\\n\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\n\\nFirecrawl is awesome 🔥 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\n\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\n\\nBardia Pourvakil\\n\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\n\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\'t recommend them enough.\\n\\n![latentsauce 🧘🏽](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\n\\nlatentsauce 🧘🏽\\n\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\n\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl ❤️❤️❤️\\n\\n![Greg Kamradt](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-02.0afeb750.jpg&w=96&q=75)\\n\\nGreg Kamradt\\n\\n[@GregKamradt](https://twitter.com/GregKamradt/status/1780300642197840307)\\n\\nLLM structured data via API, handling requests, cleaning, and crawling. Enjoyed the early preview.\\n\\n![Amit Naik](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-03.ff5dbe11.jpg&w=96&q=75)\\n\\nAmit Naik\\n\\n[@suprgeek](https://twitter.com/suprgeek/status/1780338213351035254)\\n\\n#llm success with RAG relies on Retrieval. Firecrawl by @mendableai structures web content for processing. 👏\\n\\n![Jerry Liu](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-04.76bef0df.jpg&w=96&q=75)\\n\\nJerry Liu\\n\\n[@jerryjliu0](https://twitter.com/jerryjliu0/status/1781122933349572772)\\n\\nFirecrawl is awesome 🔥 Turns web pages into structured markdown for LLM apps, thanks to @mendableai.\\n\\n![Bardia Pourvakil](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-01.025350bc.jpeg&w=96&q=75)\\n\\nBardia Pourvakil\\n\\n[@thepericulum](https://twitter.com/thepericulum/status/1781397799487078874)\\n\\nThese guys ship. I wanted types for their node SDK, and less than an hour later, I got them. Can\\'t recommend them enough.\\n\\n![latentsauce 🧘🏽](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-07.c2285d35.jpeg&w=96&q=75)\\n\\nlatentsauce 🧘🏽\\n\\n[@latentsauce](https://twitter.com/latentsauce/status/1781738253927735331)\\n\\nFirecrawl simplifies data preparation significantly, exactly what I was hoping for. Thank you for creating Firecrawl ❤️❤️❤️\\n\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\n\\nMichael Ning\\n\\n[](#)\\n\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\n\\n![Alex Reibman 🖇️](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\n\\nAlex Reibman 🖇️\\n\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\n\\nMoved our internal agent\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\n\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\n\\nMichael\\n\\n[@michael\\\\_chomsky](#)\\n\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\n\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\n\\nPaul Scott\\n\\n[@palebluepaul](https://twitter.com/palebluepaul)\\n\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\n\\n![Michael Ning](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-05.76d7cd3e.png&w=96&q=75)\\n\\nMichael Ning\\n\\n[](#)\\n\\nFirecrawl is impressive, saving us 2/3 the tokens and allowing gpt3.5turbo use over gpt4. Major savings in time and money.\\n\\n![Alex Reibman 🖇️](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-06.4ee7cf5a.jpeg&w=96&q=75)\\n\\nAlex Reibman 🖇️\\n\\n[@AlexReibman](https://twitter.com/AlexReibman/status/1780299595484131836)\\n\\nMoved our internal agent\\'s web scraping tool from Apify to Firecrawl because it benchmarked 50x faster with AgentOps.\\n\\n![Michael](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-08.0bed40be.jpeg&w=96&q=75)\\n\\nMichael\\n\\n[@michael\\\\_chomsky](#)\\n\\nI really like some of the design decisions Firecrawl made, so I really want to share with others.\\n\\n![Paul Scott](https://www.firecrawl.dev/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Ftestimonial-09.d303b5b4.png&w=96&q=75)\\n\\nPaul Scott\\n\\n[@palebluepaul](https://twitter.com/palebluepaul)\\n\\nAppreciating your lean approach, Firecrawl ticks off everything on our list without the cost prohibitive overkill.\\n\\nFlexible Pricing\\n----------------\\n\\nStart for free, then scale as you grow\\n\\nYearly (17% off)Yearly (2 months free)Monthly\\n\\nFree Plan\\n---------\\n\\n500 credits\\n\\n$0/month\\n\\n*   Scrape 500 pages\\n*   5 /scrape per min\\n*   1 /crawl per min\\n\\nGet Started\\n\\nHobby\\n-----\\n\\n3,000 credits\\n\\n$16/month\\n\\n*   Scrape 3,000 pages\\n*   10 /scrape per min\\n*   3 /crawl per min\\n\\nSubscribe\\n\\nStandardMost Popular\\n--------------------\\n\\n100,000 credits\\n\\n$83/month\\n\\n*   Scrape 100,000 pages\\n*   50 /scrape per min\\n*   10 /crawl per min\\n\\nSubscribe\\n\\nGrowth\\n------\\n\\n500,000 credits\\n\\n$333/month\\n\\n*   Scrape 500,000 pages\\n*   500 /scrape per min\\n*   50 /crawl per min\\n*   Priority Support\\n\\nSubscribe\\n\\nEnterprise Plan\\n---------------\\n\\nUnlimited credits. Custom RPMs.\\n\\nTalk to us\\n\\n*   Top priority support\\n*   Feature Acceleration\\n*   SLAs\\n*   Account Manager\\n*   Custom rate limits volume\\n*   Custom concurrency limits\\n*   Beta features access\\n*   CEO\\'s number\\n\\n\\\\* a /scrape refers to the [scrape](https://docs.firecrawl.dev/api-reference/endpoint/scrape)\\n API endpoint.\\n\\n\\\\* a /crawl refers to the [crawl](https://docs.firecrawl.dev/api-reference/endpoint/crawl)\\n API endpoint.\\n\\nScrape Credits\\n--------------\\n\\nScrape credits are consumed for each API request, varying by endpoint and feature.\\n\\n| Features | Credits per page |\\n| --- | --- |\\n| Scrape(/scrape) | 1   |\\n| Crawl(/crawl) | 1   |\\n| Search(/search) | 1   |\\n| Scrape + LLM extraction (/scrape) | 50  |\\n\\n[🔥](/)\\n\\nReady to _Build?_\\n-----------------\\n\\nStart scraping web data for your AI apps today.  \\nNo credit card needed.\\n\\n[Get Started](/signin)\\n\\n[Talk to us](https://calendly.com/d/cj83-ngq-knk/meet-firecrawl)\\n\\nFAQ\\n---\\n\\nFrequently asked questions about Firecrawl\\n\\n#### General\\n\\nWhat is Firecrawl?\\n\\nFirecrawl turns entire websites into clean, LLM-ready markdown or structured data. Scrape, crawl and extract the web with a single API. Ideal for AI companies looking to empower their LLM applications with web data.\\n\\nWhat sites work?\\n\\nFirecrawl is best suited for business websites, docs and help centers. We currently don\\'t support social media platforms.\\n\\nWho can benefit from using Firecrawl?\\n\\nFirecrawl is tailored for LLM engineers, data scientists, AI researchers, and developers looking to harness web data for training machine learning models, market research, content aggregation, and more. It simplifies the data preparation process, allowing professionals to focus on insights and model development.\\n\\nIs Firecrawl open-source?\\n\\nYes, it is. You can check out the repository on GitHub. Keep in mind that this repository is currently in its early stages of development. We are in the process of merging custom modules into this mono repository.\\n\\n#### Scraping & Crawling\\n\\nHow does Firecrawl handle dynamic content on websites?\\n\\nUnlike traditional web scrapers, Firecrawl is equipped to handle dynamic content rendered with JavaScript. It ensures comprehensive data collection from all accessible subpages, making it a reliable tool for scraping websites that rely heavily on JS for content delivery.\\n\\nWhy is it not crawling all the pages?\\n\\nThere are a few reasons why Firecrawl may not be able to crawl all the pages of a website. Some common reasons include rate limiting, and anti-scraping mechanisms, disallowing the crawler from accessing certain pages. If you\\'re experiencing issues with the crawler, please reach out to our support team at hello@firecrawl.com.\\n\\nCan Firecrawl crawl websites without a sitemap?\\n\\nYes, Firecrawl can access and crawl all accessible subpages of a website, even in the absence of a sitemap. This feature enables users to gather data from a wide array of web sources with minimal setup.\\n\\nWhat formats can Firecrawl convert web data into?\\n\\nFirecrawl specializes in converting web data into clean, well-formatted markdown. This format is particularly suited for LLM applications, offering a structured yet flexible way to represent web content.\\n\\nHow does Firecrawl ensure the cleanliness of the data?\\n\\nFirecrawl employs advanced algorithms to clean and structure the scraped data, removing unnecessary elements and formatting the content into readable markdown. This process ensures that the data is ready for use in LLM applications without further preprocessing.\\n\\nIs Firecrawl suitable for large-scale data scraping projects?\\n\\nAbsolutely. Firecrawl offers various pricing plans, including a Scale plan that supports scraping of millions of pages. With features like caching and scheduled syncs, it\\'s designed to efficiently handle large-scale data scraping and continuous updates, making it ideal for enterprises and large projects.\\n\\nDoes it respect robots.txt?\\n\\nYes, Firecrawl crawler respects the rules set in a website\\'s robots.txt file. If you notice any issues with the way Firecrawl interacts with your website, you can adjust the robots.txt file to control the crawler\\'s behavior. Firecrawl user agent name is \\'FirecrawlAgent\\'. If you notice any behavior that is not expected, please let us know at hello@firecrawl.com.\\n\\nWhat measures does Firecrawl take to handle web scraping challenges like rate limits and caching?\\n\\nFirecrawl is built to navigate common web scraping challenges, including reverse proxies, rate limits, and caching. It smartly manages requests and employs caching techniques to minimize bandwidth usage and avoid triggering anti-scraping mechanisms, ensuring reliable data collection.\\n\\nDoes Firecrawl handle captcha or authentication?\\n\\nFirecrawl avoids captcha by using stealth proxyies. When it encounters captcha, it attempts to solve it automatically, but this is not always possible. We are working to add support for more captcha solving methods. Firecrawl can handle authentication by providing auth headers to the API.\\n\\n#### API Related\\n\\nWhere can I find my API key?\\n\\nClick on the dashboard button on the top navigation menu when logged in and you will find your API key in the main screen and under API Keys.\\n\\n#### Billing\\n\\nIs Firecrawl free?\\n\\nFirecrawl is free for the first 500 scraped pages (500 free credits). After that, you can upgrade to our Standard or Scale plans for more credits.\\n\\nIs there a pay per use plan instead of monthly?\\n\\nNo we do not currently offer a pay per use plan, instead you can upgrade to our Standard or Growth plans for more credits and higher rate limits.\\n\\nHow many credit does scraping, crawling, and extraction cost?\\n\\nScraping costs 1 credit per page. Crawling costs 1 credit per page.\\n\\nDo you charge for failed requests (scrape, crawl, extract)?\\n\\nWe do not charge for any failed requests (scrape, crawl, extract). Please contact support at help@firecrawl.dev if you have any questions.\\n\\nWhat payment methods do you accept?\\n\\nWe accept payments through Stripe which accepts most major credit cards, debit cards, and PayPal.\\n\\n[🔥](/)\\n\\n© A product by Mendable.ai - All rights reserved.\\n\\n[StatusStatus](https://firecrawl.betteruptime.com)\\n[Terms of ServiceTerms of Service](/terms-of-service)\\n[Privacy PolicyPrivacy Policy](/privacy-policy)\\n\\n[Twitter](https://twitter.com/mendableai)\\n[GitHub](https://github.com/mendableai)\\n[Discord](https://discord.gg/gSmWdAkdwd)\\n\\n###### Helpful Links\\n\\n*   [Status](https://firecrawl.betteruptime.com/)\\n    \\n*   [Pricing](/pricing)\\n    \\n*   [Blog](https://www.firecrawl.dev/blog)\\n    \\n*   [Docs](https://docs.firecrawl.dev)\\n    \\n\\nBacked by![Y Combinator Logo](https://www.firecrawl.dev/images/yc.svg)\\n\\n![SOC 2 Type II](https://www.firecrawl.dev/soc2type2badge.png)\\n\\n###### Resources\\n\\n*   [Community](#0)\\n    \\n*   [Terms of service](#0)\\n    \\n*   [Collaboration features](#0)\\n    \\n\\n###### Legals\\n\\n*   [Refund policy](#0)\\n    \\n*   [Terms & Conditions](#0)\\n    \\n*   [Privacy policy](#0)\\n    \\n*   [Brand Kit](#0)')"
       ]
      },
      "execution_count": 4,
@@ -118,14 +118,14 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 8,
    "metadata": {},
    "outputs": [
     {
      "name": "stdout",

----------------------------------------

File: docs/docs/integrations/document_loaders/github.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -164,7 +164,7 @@
    },
    "outputs": [],
    "source": [
-    "from langchain.document_loaders import GithubFileLoader"
+    "from langchain_community.document_loaders import GithubFileLoader"
    ]
   },
   {

----------------------------------------

File: docs/docs/integrations/document_loaders/index.mdx
Status: added
Changes: +45 -0
Diff:
@@ -0,0 +1,45 @@
+---
+sidebar_position: 0
+sidebar_class_name: hidden
+---
+
+# Document loaders
+
+import { CategoryTable, IndexTable } from "@theme/FeatureTables";
+
+DocumentLoaders load data into the standard LangChain Document format.
+
+Each DocumentLoader has its own specific parameters, but they can all be invoked in the same way with the .load method.
+An example use case is as follows:
+

----------------------------------------

File: docs/docs/integrations/document_loaders/json.ipynb
Status: added
Changes: +348 -0
Diff:
@@ -0,0 +1,348 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# JSONLoader\n",
+    "\n",
+    "This notebook provides a quick overview for getting started with JSON [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all JSONLoader features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html).\n",
+    "\n",
+    "- TODO: Add any other relevant links, like information about underlying API, etc.\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/json/)|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [JSONLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.json_loader.JSONLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ✅ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| JSONLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access JSON document loader you'll need to install the `langchain-community` integration package as well as the ``jq`` python package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are required to use the `JSONLoader` class."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community** and **jq**:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install -qU langchain_community jq "
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Initialization\n",
+    "\n",
+    "Now we can instantiate our model object and load documents:\n",
+    "\n",
+    "- TODO: Update model instantiation with relevant params."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from langchain_community.document_loaders import JSONLoader\n",
+    "\n",
+    "loader = JSONLoader(\n",
+    "    file_path=\"./example_data/facebook_chat.json\",\n",
+    "    jq_schema=\".messages[].content\",\n",
+    "    text_content=False,\n",
+    ")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Load"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "Document(metadata={'source': '/Users/isaachershenson/Documents/langchain/docs/docs/integrations/document_loaders/example_data/facebook_chat.json', 'seq_num': 1}, page_content='Bye!')"
+      ]
+     },
+     "execution_count": 2,
+     "metadata": {},
+     "output_type": "execute_result"
+    }

----------------------------------------

File: docs/docs/integrations/document_loaders/mathpix.ipynb
Status: added
Changes: +178 -0
Diff:
@@ -0,0 +1,178 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# MathPixPDFLoader\n",
+    "\n",
+    "Inspired by Daniel Gross's snippet here: [https://gist.github.com/danielgross/3ab4104e14faccc12b49200843adab21](https://gist.github.com/danielgross/3ab4104e14faccc12b49200843adab21)\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | JS support|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [MathPixPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.MathpixPDFLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ❌ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| MathPixPDFLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Sign up for Mathpix and [create an API key](https://mathpix.com/docs/ocr/creating-an-api-key) to set the `MATHPIX_API_KEY` variables in your environment"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if \"MATHPIX_API_KEY\" not in os.environ:\n",
+    "    os.environ[\"MATHPIX_API_KEY\"] = getpass.getpass(\"Enter your Mathpix API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },

----------------------------------------

File: docs/docs/integrations/document_loaders/pdfminer.ipynb
Status: added
Changes: +317 -0

----------------------------------------

File: docs/docs/integrations/document_loaders/pdfplumber.ipynb
Status: added
Changes: +183 -0
Diff:
@@ -0,0 +1,183 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# PDFPlumber\n",
+    "\n",
+    "Like PyMuPDF, the output Documents contain detailed metadata about the PDF and its pages, and returns one document per page.\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | JS support|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [PDFPlumberLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PDFPlumberLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ❌ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| PDFPlumberLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed to use this loader."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community**."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [

----------------------------------------

File: docs/docs/integrations/document_loaders/pymupdf.ipynb
Status: added
Changes: +185 -0
Diff:
@@ -0,0 +1,185 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# PyMuPDF\n",
+    "\n",
+    "`PyMuPDF` is optimized for speed, and contains detailed metadata about the PDF and its pages. It returns one document per page.\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | JS support|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [PyMuPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyMuPDFLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ❌ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| PyMuPDFLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed to use the `PyMuPDFLoader`."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community** and **pymupdf**."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install -qU langchain-community pymupdf"

----------------------------------------

File: docs/docs/integrations/document_loaders/pypdfdirectory.ipynb
Status: added
Changes: +187 -0
Diff:
@@ -0,0 +1,187 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# PyPDFDirectoryLoader\n",
+    "\n",
+    "This loader loads all PDF files from a specific directory.\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "\n",
+    "| Class | Package | Local | Serializable | JS support|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [PyPDFDirectoryLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFDirectoryLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ❌ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| PyPDFDirectoryLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed for this loader."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community**."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [

----------------------------------------

File: docs/docs/integrations/document_loaders/pypdfium2.ipynb
Status: added
Changes: +188 -0
Diff:
@@ -0,0 +1,188 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# PyPDFium2Loader\n",
+    "\n",
+    "\n",
+    "This notebook provides a quick overview for getting started with PyPDFium2 [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | JS support|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [PyPDFium2Loader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFium2Loader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ❌ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| PyPDFium2Loader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "\n",
+    "To access PyPDFium2 document loader you'll need to install the `langchain-community` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community**."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},

----------------------------------------

File: docs/docs/integrations/document_loaders/pypdfloader.ipynb
Status: modified
Changes: +32 -12
Diff:
@@ -6,7 +6,7 @@
    "source": [
     "# PyPDFLoader\n",
     "\n",
-    "This notebook provides a quick overview for getting started with `PyPDF` [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html).\n",
+    "This notebook provides a quick overview for getting started with `PyPDF` [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all DocumentLoader features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.PyPDFLoader.html).\n",
     "\n",
     "\n",
     "## Overview\n",
@@ -43,7 +43,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "%pip install -qU langchain_community"
+    "%pip install -qU langchain_community pypdf"
    ]
   },
   {
@@ -122,7 +122,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 5,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [
     {
@@ -131,21 +131,41 @@
        "6"
       ]
      },
-     "execution_count": 5,

----------------------------------------

File: docs/docs/integrations/document_loaders/recursive_url.ipynb
Status: modified
Changes: +4 -4
Diff:
@@ -229,14 +229,14 @@
     }
    ],
    "source": [
-    "page = []\n",
+    "pages = []\n",
     "for doc in loader.lazy_load():\n",
-    "    page.append(doc)\n",
-    "    if len(page) >= 10:\n",
+    "    pages.append(doc)\n",

----------------------------------------

File: docs/docs/integrations/document_loaders/scrapingant.ipynb
Status: modified
Changes: +34 -30
Diff:
@@ -41,25 +41,19 @@
   {
    "cell_type": "markdown",
    "metadata": {},
-   "source": "## Instantiation"
+   "source": [
+    "## Instantiation"
+   ]
   },
   {
    "cell_type": "code",
+   "execution_count": 6,
    "metadata": {
     "ExecuteTime": {
      "end_time": "2024-07-22T18:18:50.903258Z",
      "start_time": "2024-07-22T18:18:35.265390Z"
     }
    },
-   "source": [
-    "from langchain_community.document_loaders import ScrapingAntLoader\n",
-    "\n",
-    "scrapingant_loader = ScrapingAntLoader(\n",
-    "    [\"https://scrapingant.com/\", \"https://example.com/\"],  # List of URLs to scrape\n",
-    "    api_key=\"<YOUR_SCRAPINGANT_TOKEN>\",  # Get your API key from https://scrapingant.com/\n",
-    "    continue_on_failure=True,  # Ignore unprocessable web pages and log their exceptions\n",
-    ")"
-   ],
    "outputs": [
     {
      "name": "stdout",
@@ -69,21 +63,41 @@
      ]
     }
    ],
-   "execution_count": 6
+   "source": [
+    "from langchain_community.document_loaders import ScrapingAntLoader\n",
+    "\n",
+    "scrapingant_loader = ScrapingAntLoader(\n",
+    "    [\"https://scrapingant.com/\", \"https://example.com/\"],  # List of URLs to scrape\n",
+    "    api_key=\"<YOUR_SCRAPINGANT_TOKEN>\",  # Get your API key from https://scrapingant.com/\n",
+    "    continue_on_failure=True,  # Ignore unprocessable web pages and log their exceptions\n",
+    ")"
+   ]
   },
   {
    "cell_type": "markdown",
    "metadata": {},

----------------------------------------

File: docs/docs/integrations/document_loaders/sitemap.ipynb
Status: modified
Changes: +149 -24
Diff:
@@ -6,9 +6,54 @@
    "source": [
     "# Sitemap\n",
     "\n",
-    "Extends from the `WebBaseLoader`, `SitemapLoader` loads a sitemap from a given URL, and then scrape and load all pages in the sitemap, returning each page as a Document.\n",
+    "Extends from the `WebBaseLoader`, `SitemapLoader` loads a sitemap from a given URL, and then scrapes and loads all pages in the sitemap, returning each page as a Document.\n",
     "\n",
-    "The scraping is done concurrently.  There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren't concerned about being a good citizen, or you control the scrapped server, or don't care about load. Note, while this will speed up the scraping process, but it may cause the server to block you.  Be careful!"
+    "The scraping is done concurrently. There are reasonable limits to concurrent requests, defaulting to 2 per second.  If you aren't concerned about being a good citizen, or you control the scrapped server, or don't care about load you can increase this limit. Note, while this will speed up the scraping process, it may cause the server to block you. Be careful!\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/web_loaders/sitemap/)|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [SiteMapLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.sitemap.SitemapLoader.html#langchain_community.document_loaders.sitemap.SitemapLoader) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ✅ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| SiteMapLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access SiteMap document loader you'll need to install the `langchain-community` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed to run this."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community**."
    ]
   },
   {
@@ -17,21 +62,36 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "%pip install --upgrade --quiet  nest_asyncio"
+    "%pip install -qU langchain-community"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Fix notebook asyncio bug"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 13,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [],
    "source": [
-    "# fixes a bug with asyncio and jupyter\n",

----------------------------------------

File: docs/docs/integrations/document_loaders/unstructured_markdown.ipynb
Status: added
Changes: +269 -0
Diff:
@@ -0,0 +1,269 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# UnstructuredMarkdownLoader\n",
+    "\n",
+    "This notebook provides a quick overview for getting started with UnstructuredMarkdown [document loader](https://python.langchain.com/v0.2/docs/concepts/#document-loaders). For detailed documentation of all __ModuleName__Loader features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/unstructured/)|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [UnstructuredMarkdownLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.markdown.UnstructuredMarkdownLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ❌ | ❌ | ✅ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| UnstructuredMarkdownLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access UnstructuredMarkdownLoader document loader you'll need to install the `langchain-community` integration package and the `unstructured` python package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed to use this loader."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community** and **unstructured**"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install -qU langchain_community unstructured"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Initialization\n",
+    "\n",
+    "Now we can instantiate our model object and load documents. \n",
+    "\n",
+    "You can run the loader in one of two modes: \"single\" and \"elements\". If you use \"single\" mode, the document will be returned as a single `Document` object. If you use \"elements\" mode, the unstructured library will split the document into elements such as `Title` and `NarrativeText`. You can pass in additional `unstructured` kwargs after mode to apply different `unstructured` settings."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 10,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
+    "\n",
+    "loader = UnstructuredMarkdownLoader(\n",
+    "    \"./example_data/example.md\",\n",
+    "    mode=\"single\",\n",
+    "    strategy=\"fast\",\n",

----------------------------------------

File: docs/docs/integrations/document_loaders/unstructured_pdfloader.ipynb
Status: added
Changes: +284 -0
Diff:
@@ -0,0 +1,284 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "# UnstructuredPDFLoader\n",
+    "\n",
+    "## Overview\n",
+    "\n",
+    "[Unstructured](https://unstructured-io.github.io/unstructured/) supports a common interface for working with unstructured or semi-structured file formats, such as Markdown or PDF. LangChain's [UnstructuredPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html) integrates with Unstructured to parse PDF documents into LangChain [Document](https://api.python.langchain.com/en/latest/documents/langchain_core.documents.base.Document.html) objects.\n",
+    "\n",
+    "Please see [this page](/docs/integrations/providers/unstructured/) for more information on installing system requirements.\n",
+    "\n",
+    "\n",
+    "### Integration details\n",
+    "\n",
+    "\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/document_loaders/file_loaders/unstructured/)|\n",
+    "| :--- | :--- | :---: | :---: |  :---: |\n",
+    "| [UnstructuredPDFLoader](https://api.python.langchain.com/en/latest/document_loaders/langchain_community.document_loaders.pdf.UnstructuredPDFLoader.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ✅ | ❌ | ✅ | \n",
+    "### Loader features\n",
+    "| Source | Document Lazy Loading | Native Async Support\n",
+    "| :---: | :---: | :---: | \n",
+    "| UnstructuredPDFLoader | ✅ | ❌ | \n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "No credentials are needed to use this loader."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
+    "# os.environ[\"LANGSMITH_TRACING\"] = \"true\""
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "Install **langchain_community** and **unstructured**."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install -qU langchain-community unstructured"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Initialization\n",
+    "\n",
+    "Now we can initialize our loader:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from langchain_community.document_loaders import UnstructuredPDFLoader\n",
+    "\n",
+    "file_path = \"./example_data/layout-parser-paper.pdf\"\n",
+    "loader = UnstructuredPDFLoader(file_path)"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Load"

----------------------------------------

File: docs/docs/integrations/document_loaders/url.ipynb
Status: modified
Changes: +3 -1
Diff:
@@ -138,6 +138,8 @@
    "source": [
     "## Playwright URL Loader\n",
     "\n",
+    ">[Playwright](https://github.com/microsoft/playwright) is an open-source automation tool developed by `Microsoft` that allows you to programmatically control and automate web browsers. It is designed for end-to-end testing, scraping, and automating tasks across various web browsers such as `Chromium`, `Firefox`, and `WebKit`.\n",
+    "\n",
     "This covers how to load HTML documents from a list of URLs using the `PlaywrightURLLoader`.\n",
     "\n",
     "[Playwright](https://playwright.dev/) enables reliable end-to-end testing for modern web apps.\n",
@@ -224,7 +226,7 @@

----------------------------------------

File: docs/docs/integrations/document_loaders/web_base.ipynb
Status: modified
Changes: +75 -16
Diff:
@@ -44,7 +44,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "%pip install -qU langchain_community"
+    "%pip install -qU langchain_community beautifulsoup4"
    ]
   },
   {
@@ -250,34 +250,90 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
+   "execution_count": 2,
    "id": "303d2f4e",
    "metadata": {},
    "outputs": [
     {
-     "data": {
-      "text/plain": [
-       "Document(metadata={'source': 'https://www.espn.com/', 'title': 'ESPN - Serving Sports Fans. Anytime. Anywhere.', 'description': 'Visit ESPN for live scores, highlights and sports news. Stream exclusive games on ESPN+ and play fantasy sports.', 'language': 'en'}, page_content=\"\\n\\n\\n\\n\\n\\n\\n\\n\\nESPN - Serving Sports Fans. Anytime. Anywhere.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n        Skip to main content\\n    \\n\\n        Skip to navigation\\n    \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n<\\n\\n>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nMenuESPN\\n\\n\\n\\n\\n\\nscores\\n\\n\\n\\nNFLNBAMLBOlympicsSoccerWNBA…BoxingCFLNCAACricketF1GolfHorseLLWSMMANASCARNBA G LeagueNBA Summer LeagueNCAAFNCAAMNCAAWNHLNWSLPLLProfessional WrestlingRacingRN BBRN FBRugbySports BettingTennisX GamesUFLMore ESPNFantasyWatchESPN BETESPN+\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n  \\n\\nSubscribe Now\\n\\n\\n\\n\\n\\nBoxing: Crawford vs. Madrimov (ESPN+ PPV)\\n\\n\\n\\n\\n\\n\\n\\nPFL Playoffs: Heavyweights & Women's Flyweights\\n\\n\\n\\n\\n\\n\\n\\nMLB\\n\\n\\n\\n\\n\\n\\n\\nLittle League Baseball: Regionals\\n\\n\\n\\n\\n\\n\\n\\nIn The Arena: Serena Williams\\n\\n\\n\\n\\n\\n\\n\\nThe 30 College Football Playoff Contenders\\n\\n\\nQuick Links\\n\\n\\n\\n\\n2024 Paris Olympics\\n\\n\\n\\n\\n\\n\\n\\nOlympics: Everything to Know\\n\\n\\n\\n\\n\\n\\n\\nMLB Standings\\n\\n\\n\\n\\n\\n\\n\\nSign up: Fantasy Football\\n\\n\\n\\n\\n\\n\\n\\nWNBA Rookie Tracker\\n\\n\\n\\n\\n\\n\\n\\nNBA Free Agency Buzz\\n\\n\\n\\n\\n\\n\\n\\nLittle League Baseball, Softball\\n\\n\\n\\n\\n\\n\\n\\nESPN Radio: Listen Live\\n\\n\\n\\n\\n\\n\\n\\nWatch Golf on ESPN\\n\\n\\n\\n\\n\\n\\nFavorites\\n\\n\\n\\n\\n\\n\\n      Manage Favorites\\n      \\n\\n\\n\\nCustomize ESPNCreate AccountLog InFantasy\\n\\n\\n\\n\\nFootball\\n\\n\\n\\n\\n\\n\\n\\nBaseball\\n\\n\\n\\n\\n\\n\\n\\nBasketball\\n\\n\\n\\n\\n\\n\\n\\nHockey\\n\\n\\nESPN Sites\\n\\n\\n\\n\\nESPN Deportes\\n\\n\\n\\n\\n\\n\\n\\nAndscape\\n\\n\\n\\n\\n\\n\\n\\nespnW\\n\\n\\n\\n\\n\\n\\n\\nESPNFC\\n\\n\\n\\n\\n\\n\\n\\nX Games\\n\\n\\n\\n\\n\\n\\n\\nSEC Network\\n\\n\\nESPN Apps\\n\\n\\n\\n\\nESPN\\n\\n\\n\\n\\n\\n\\n\\nESPN Fantasy\\n\\n\\n\\n\\n\\n\\n\\nTournament Challenge\\n\\n\\nFollow ESPN\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\n\\n\\nX/Twitter\\n\\n\\n\\n\\n\\n\\n\\nInstagram\\n\\n\\n\\n\\n\\n\\n\\nSnapchat\\n\\n\\n\\n\\n\\n\\n\\nTikTok\\n\\n\\n\\n\\n\\n\\n\\nYouTube\\n\\n\\nCollege football's most entertaining conference? Why the 16-team Big 12 is wiiiiiide open this seasonLong known as one of the sport's most unpredictable conferences, the new-look Big 12 promises another dose of chaos.11hBill ConnellyScott Winters/Icon SportswireUSC, Oregon and the quest to bulk up for the Big TenTo improve on D, the Trojans wanted to bulk up for a new league. They're not the only team trying to do that.10hAdam RittenbergThe 30 teams that can reach the CFPConnelly's best games of the 2024 seasonTOP HEADLINESTeam USA sets world record in 4x400 mixed relayGermany beats France, undefeated in men's hoopsU.S. men's soccer exits Games after Morocco routHungary to protest Khelif's Olympic participationKobe's Staples Center locker sells for record $2.9MDjokovic, Alcaraz to meet again, this time for goldKerr: Team USA lineups based on players' rolesMarchand wins 200m IM; McEvoy takes 50 freeScouting Shedeur Sanders' NFL futureLATEST FROM PARISBreakout stars, best moments and what comes next: Breaking down the Games halfway throughAt the midpoint of the Olympics, we look back at some of the best moments and forward at what's still to come in the second week.35mESPNMustafa Yalcin/Anadolu via Getty ImagesThe numbers behind USA's world record in 4x400 mixed relay4h0:46Medal trackerFull resultsFull coverage of the OlympicsPRESEASON HAS BEGUN!New kickoff rules on display to start Hall of Fame Game19h0:41McAfee on NFL's new kickoff: It looks like a practice drill6h1:11NFL's new kickoff rules debut to mixed reviewsTexans-Bears attracts more bets than MLBTOP RANK BOXINGSATURDAY ON ESPN+ PPVWhy Terence Crawford is playing the long game for a chance to face CaneloCrawford is approaching Saturday's marquee matchup against Israil Madrimov with his sights set on landing a bigger one next: against Canelo Alvarez.10hMike CoppingerMark Robinson/Matchroom BoxingBradley's take: Crawford's power vs. Israil Madrimov's disciplined styleTimothy Bradley Jr. breaks down the junior middleweight title fight.2dTimothy Bradley Jr.Buy Crawford vs. Madrimov on ESPN+ PPVChance to impress for Madrimov -- and UzbekistanHOW FRIDAY WENTMORE FROM THE PARIS OLYMPICSGrant Fisher makes U.S. track history, Marchand wins 4th gold and more Friday at the Paris GamesSha'Carri Richardson made her long-awaited Olympic debut during the women's 100m preliminary round on Friday. Here's everything else you might have missed from Paris.31mESPNGetty ImagesU.S. men's loss to Morocco is a wake-up call before World CupOutclassed by Morocco, the U.S. men's Olympic team can take plenty of lessons with the World Cup on the horizon.4hSam BordenFull coverage of the OlympicsOLYMPIC MEN'S HOOPS SCOREBOARDFRIDAY'S GAMESOLYMPIC STANDOUTSWhy Simone Biles is now Stephen A.'s No. 1 Olympian7h0:58Alcaraz on the cusp of history after securing spot in gold medal match8h0:59Simone Biles' gymnastics titles: Olympics, Worlds, more statsOLYMPIC MEN'S SOCCER SCOREBOARDFRIDAY'S GAMESTRADE DEADLINE FALLOUTOlney: Eight big questions for traded MLB playersCan Jazz Chisholm Jr. handle New York? Is Jack Flaherty healthy? Will Jorge Soler's defense play? Key questions for players in new places.10hBuster OlneyWinslow Townson/Getty ImagesRanking the top prospects who changed teams at the MLB trade deadlineYou know the major leaguers who moved by now -- but what about the potential stars of tomorrow?1dKiley McDanielMLB Power RankingsSeries odds: Dodgers still on top; Phillies, Yanks behind them Top HeadlinesTeam USA sets world record in 4x400 mixed relayGermany beats France, undefeated in men's hoopsU.S. men's soccer exits Games after Morocco routHungary to protest Khelif's Olympic participationKobe's Staples Center locker sells for record $2.9MDjokovic, Alcaraz to meet again, this time for goldKerr: Team USA lineups based on players' rolesMarchand wins 200m IM; McEvoy takes 50 freeScouting Shedeur Sanders' NFL futureFavorites FantasyManage FavoritesFantasy HomeCustomize ESPNCreate AccountLog InICYMI0:47Nelson Palacio rips an incredible goal from outside the boxNelson Palacio scores an outside-of-the-box goal for Real Salt Lake in the 79th minute. \\n\\n\\nMedal Tracker\\n\\n\\n\\nCountries\\nAthletes\\n\\nOverall Medal Leaders43USA36FRA31CHNIndividual Medal LeadersGoldCHN 13FRA 11AUS 11SilverUSA 18FRA 12GBR 10BronzeUSA 16FRA 13CHN 9Overall Medal Leaders4MarchandMarchand3O'CallaghanO'Callaghan3McIntoshMcIntoshIndividual Medal LeadersGoldMarchand 4O'Callaghan 3McIntosh 2SilverSmith 3Huske 2Walsh 2BronzeYufei 3Bhaker 2Haughey 2\\n\\n\\nFull Medal Tracker\\n\\n\\nBest of ESPN+ESPNCollege Football Playoff 2024: 30 teams can reach postseasonHeather Dinich analyzes the teams with at least a 10% chance to make the CFP.AP Photo/Ross D. FranklinNFL Hall of Fame predictions: Who will make the next 10 classes?When will Richard Sherman and Marshawn Lynch make it? Who could join Aaron Donald in 2029? Let's map out each Hall of Fame class until 2034.Thearon W. Henderson/Getty ImagesMLB trade deadline 2024: Ranking prospects who changed teamsYou know the major leaguers who moved by now -- but what about the potential stars of tomorrow who went the other way in those deals? Trending NowIllustration by ESPNRanking the top 100 professional athletes since 2000Who tops our list of the top athletes since 2000? We're unveiling the top 25, including our voters' pick for the No. 1 spot.Photo by Kevin C. Cox/Getty Images2024 NFL offseason recap: Signings, coach moves, new rulesThink you missed something in the NFL offseason? We've got you covered with everything important that has happened since February.Stacy Revere/Getty ImagesTop 25 college football stadiums: Rose Bowl, Michigan and moreFourteen of ESPN's college football writers rank the 25 best stadiums in the sport. Who's No. 1, who missed the cut and what makes these stadiums so special?ESPNInside Nate Robinson's silent battle -- and his fight to liveFor nearly 20 years Nate Robinson has been fighting a silent battle -- one he didn't realize until recently could end his life. Sign up to play the #1 Fantasy game!Create A LeagueJoin Public LeagueReactivate A LeagueMock Draft NowSign up for FREE!Create A LeagueJoin a Public LeagueReactivate a LeaguePractice With a Mock DraftSign up for FREE!Create A LeagueJoin a Public LeagueReactivate a LeaguePractice with a Mock DraftGet a custom ESPN experienceEnjoy the benefits of a personalized accountSelect your favorite leagues, teams and players and get the latest scores, news and updates that matter most to you. \\n\\nESPN+\\n\\n\\n\\n\\nBoxing: Crawford vs. Madrimov (ESPN+ PPV)\\n\\n\\n\\n\\n\\n\\n\\nPFL Playoffs: Heavyweights & Women's Flyweights\\n\\n\\n\\n\\n\\n\\n\\nMLB\\n\\n\\n\\n\\n\\n\\n\\nLittle League Baseball: Regionals\\n\\n\\n\\n\\n\\n\\n\\nIn The Arena: Serena Williams\\n\\n\\n\\n\\n\\n\\n\\nThe 30 College Football Playoff Contenders\\n\\n\\nQuick Links\\n\\n\\n\\n\\n2024 Paris Olympics\\n\\n\\n\\n\\n\\n\\n\\nOlympics: Everything to Know\\n\\n\\n\\n\\n\\n\\n\\nMLB Standings\\n\\n\\n\\n\\n\\n\\n\\nSign up: Fantasy Football\\n\\n\\n\\n\\n\\n\\n\\nWNBA Rookie Tracker\\n\\n\\n\\n\\n\\n\\n\\nNBA Free Agency Buzz\\n\\n\\n\\n\\n\\n\\n\\nLittle League Baseball, Softball\\n\\n\\n\\n\\n\\n\\n\\nESPN Radio: Listen Live\\n\\n\\n\\n\\n\\n\\n\\nWatch Golf on ESPN\\n\\n\\nFantasy\\n\\n\\n\\n\\nFootball\\n\\n\\n\\n\\n\\n\\n\\nBaseball\\n\\n\\n\\n\\n\\n\\n\\nBasketball\\n\\n\\n\\n\\n\\n\\n\\nHockey\\n\\n\\nESPN Sites\\n\\n\\n\\n\\nESPN Deportes\\n\\n\\n\\n\\n\\n\\n\\nAndscape\\n\\n\\n\\n\\n\\n\\n\\nespnW\\n\\n\\n\\n\\n\\n\\n\\nESPNFC\\n\\n\\n\\n\\n\\n\\n\\nX Games\\n\\n\\n\\n\\n\\n\\n\\nSEC Network\\n\\n\\nESPN Apps\\n\\n\\n\\n\\nESPN\\n\\n\\n\\n\\n\\n\\n\\nESPN Fantasy\\n\\n\\n\\n\\n\\n\\n\\nTournament Challenge\\n\\n\\nFollow ESPN\\n\\n\\n\\n\\nFacebook\\n\\n\\n\\n\\n\\n\\n\\nX/Twitter\\n\\n\\n\\n\\n\\n\\n\\nInstagram\\n\\n\\n\\n\\n\\n\\n\\nSnapchat\\n\\n\\n\\n\\n\\n\\n\\nTikTok\\n\\n\\n\\n\\n\\n\\n\\nYouTube\\n\\n\\nTerms of UsePrivacy PolicyYour US State Privacy RightsChildren's Online Privacy PolicyInterest-Based AdsAbout Nielsen MeasurementDo Not Sell or Share My Personal InformationContact UsDisney Ad Sales SiteWork for ESPNCorrectionsESPN BET is owned and operated by PENN Entertainment, Inc. and its subsidiaries ('PENN'). ESPN BET is available in states where PENN is licensed to offer sports wagering. Must be 21+ to wager. If you or someone you know has a gambling problem and wants help, call 1-800-GAMBLER.Copyright: © 2024 ESPN Enterprises, Inc. All rights reserved.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\")"
-      ]
-     },
-     "execution_count": 6,
-     "metadata": {},
-     "output_type": "execute_result"
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "\n",
+      "\n",
+      "\n",
+      "\n",
+      "\n",
+      "\n",
+      "\n",
+      "\n",
+      "\n",
+      "ESPN - Serving Sports Fans. Anytime. Anywhere.\n",
+      "\n",
+      "\n",
+      "\n",
+      "\n",

----------------------------------------

File: docs/docs/integrations/document_loaders/youtube_transcript.ipynb
Status: modified
Changes: +33 -31
Diff:
@@ -15,45 +15,47 @@
   },
   {
    "cell_type": "code",
+   "execution_count": null,
    "id": "427d5745",
    "metadata": {},
-   "source": "from langchain_community.document_loaders import YoutubeLoader",
    "outputs": [],
-   "execution_count": null
+   "source": [
+    "from langchain_community.document_loaders import YoutubeLoader"
+   ]
   },
   {
    "cell_type": "code",
+   "execution_count": null,
    "id": "34a25b57",
    "metadata": {
     "scrolled": true
    },
+   "outputs": [],
    "source": [
     "%pip install --upgrade --quiet  youtube-transcript-api"
-   ],
-   "outputs": [],
-   "execution_count": null
+   ]
   },
   {
    "cell_type": "code",
+   "execution_count": null,
    "id": "bc8b308a",
    "metadata": {},
+   "outputs": [],
    "source": [
     "loader = YoutubeLoader.from_youtube_url(\n",
     "    \"https://www.youtube.com/watch?v=QsYGlZkevEg\", add_video_info=False\n",
     ")"
-   ],
-   "outputs": [],
-   "execution_count": null
+   ]
   },
   {
    "cell_type": "code",
+   "execution_count": null,
    "id": "d073dd36",
    "metadata": {},
+   "outputs": [],
    "source": [
     "loader.load()"
-   ],
-   "outputs": [],
-   "execution_count": null
+   ]
   },

----------------------------------------

File: docs/docs/integrations/document_transformers/openvino_rerank.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -331,8 +331,8 @@
     }
    ],
    "source": [
-    "from langchain.embeddings import OpenVINOEmbeddings\n",
     "from langchain_community.document_loaders import TextLoader\n",
+    "from langchain_community.embeddings import OpenVINOEmbeddings\n",
     "from langchain_community.vectorstores import FAISS\n",
     "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
     "\n",

----------------------------------------

File: docs/docs/integrations/graphs/amazon_neptune_sparql.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -245,8 +245,8 @@
    "outputs": [],
    "source": [
     "import boto3\n",
-    "from langchain.chains.graph_qa.neptune_sparql import NeptuneSparqlQAChain\n",
     "from langchain_aws import ChatBedrock\n",
+    "from langchain_community.chains.graph_qa.neptune_sparql import NeptuneSparqlQAChain\n",
     "from langchain_community.graphs import NeptuneRdfGraph\n",
     "\n",
     "host = \"<your host>\"\n",

----------------------------------------

File: docs/docs/integrations/graphs/azure_cosmosdb_gremlin.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -65,7 +65,7 @@
    "outputs": [],
    "source": [
     "import nest_asyncio\n",
-    "from langchain.chains.graph_qa.gremlin import GremlinQAChain\n",
+    "from langchain_community.chains.graph_qa.gremlin import GremlinQAChain\n",
     "from langchain_community.graphs import GremlinGraph\n",
     "from langchain_community.graphs.graph_document import GraphDocument, Node, Relationship\n",
     "from langchain_core.documents import Document\n",

----------------------------------------

File: docs/docs/integrations/graphs/networkx.ipynb
Status: modified
Changes: +2 -2
Diff:
@@ -49,7 +49,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.indexes import GraphIndexCreator\n",
+    "from langchain_community.graphs.index_creator import GraphIndexCreator\n",
     "from langchain_openai import OpenAI"
    ]
   },
@@ -252,7 +252,7 @@

----------------------------------------

File: docs/docs/integrations/llms/anthropic.ipynb
Status: modified
Changes: +1 -9
Diff:
@@ -23,7 +23,7 @@
     "# AnthropicLLM\n",
     "\n",
     ":::caution\n",
-    "You are currently on a page documenting the use of Anthropic legacy Claude 2 models as [text completion models](/docs/concepts/#llms). The latest and most popular Anthropic models are [chat completion models](/docs/concepts/#chat-models).\n",
+    "You are currently on a page documenting the use of Anthropic legacy Claude 2 models as [text completion models](/docs/concepts/#llms). The latest and most popular Anthropic models are [chat completion models](/docs/concepts/#chat-models), and the text completion models have been deprecated.\n",
     "\n",
     "You are probably looking for [this page instead](/docs/integrations/chat/anthropic/).\n",
     ":::\n",
@@ -115,14 +115,6 @@

----------------------------------------

File: docs/docs/integrations/llms/clarifai.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -226,7 +226,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "# Intialize the parameters as dict.\n",
+    "# Initialize the parameters as dict.\n",
     "params = dict(temperature=str(0.3), max_tokens=100)"
    ]
   },

----------------------------------------

File: docs/docs/integrations/llms/cohere.ipynb
Status: modified
Changes: +42 -22
Diff:
@@ -15,7 +15,14 @@
     "\n",
     ">[Cohere](https://cohere.ai/about) is a Canadian startup that provides natural language processing models that help companies improve human-machine interactions.\n",
     "\n",
-    "Head to the [API reference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.cohere.Cohere.html) for detailed documentation of all attributes and methods."
+    "Head to the [API reference](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.cohere.Cohere.html) for detailed documentation of all attributes and methods.\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/llms/cohere/) | Package downloads | Package latest |\n",
+    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
+    "| [Cohere](https://api.python.langchain.com/en/latest/llms/langchain_community.llms.cohere.Cohere.html) | [langchain_community](https://api.python.langchain.com/en/latest/community_api_reference.html) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_community?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_community?style=flat-square&label=%20) |\n"
    ]
   },
   {
@@ -29,34 +36,43 @@
     "\n",
     "The integration lives in the `langchain-community` package. We also need to install the `cohere` package itself. We can install these with:\n",
     "\n",
-    "```bash\n",
-    "pip install -U langchain-community langchain-cohere\n",
-    "```\n",
+    "### Credentials\n",
     "\n",
-    "We'll also need to get a [Cohere API key](https://cohere.com/) and set the `COHERE_API_KEY` environment variable:"
+    "We'll need to get a [Cohere API key](https://cohere.com/) and set the `COHERE_API_KEY` environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
+   "execution_count": null,
    "id": "3f5dc9d7-65e3-4b5b-9086-3327d016cfe0",
    "metadata": {
     "tags": []
    },

----------------------------------------

File: docs/docs/integrations/llms/databricks.ipynb
Status: modified
Changes: +4 -1
Diff:
@@ -61,7 +61,10 @@
     "import os\n",
     "\n",
     "os.environ[\"DATABRICKS_HOST\"] = \"https://your-workspace.cloud.databricks.com\"\n",
-    "os.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass(\"Enter your Databricks access token: \")"
+    "if \"DATABRICKS_TOKEN\" not in os.environ:\n",
+    "    os.environ[\"DATABRICKS_TOKEN\"] = getpass.getpass(\n",
+    "        \"Enter your Databricks access token: \"\n",
+    "    )"
    ]

----------------------------------------

File: docs/docs/integrations/llms/fireworks.ipynb
Status: modified
Changes: +93 -48
Diff:
@@ -15,56 +15,88 @@
     "\n",
     ">[Fireworks](https://app.fireworks.ai/) accelerates product development on generative AI by creating an innovative AI experiment and production platform. \n",
     "\n",
-    "This example goes over how to use LangChain to interact with `Fireworks` models."
+    "This example goes over how to use LangChain to interact with `Fireworks` models.\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.1/docs/integrations/llms/fireworks/) | Package downloads | Package latest |\n",
+    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
+    "| [Fireworks](https://api.python.langchain.com/en/latest/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks) | [langchain_fireworks](https://api.python.langchain.com/en/latest/fireworks_api_reference.html) | ❌ | ❌ | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain_fireworks?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain_fireworks?style=flat-square&label=%20) |"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "ccff689e",
+   "metadata": {},
+   "source": [
+    "## Setup\n",
+    "\n",
+    "### Credentials \n",
+    "\n",
+    "Sign in to [Fireworks AI](http://fireworks.ai) for the an API Key to access our models, and make sure it is set as the `FIREWORKS_API_KEY` environment variable.\n",
+    "3. Set up your model using a model id. If the model is not set, the default model is fireworks-llama-v2-7b-chat. See the full, most up-to-date model list on [fireworks.ai](https://fireworks.ai)."
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "fb345268",
+   "execution_count": 1,
+   "id": "9ca87a2e",
    "metadata": {},
    "outputs": [],
    "source": [
-    "%pip install -qU langchain-fireworks"
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if \"FIREWORKS_API_KEY\" not in os.environ:\n",
+    "    os.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass(\"Fireworks API Key:\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "e42ced7e",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "You need to install the `langchain_fireworks` python package for the rest of the notebook to work."
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 2,
-   "id": "60b6dbb2",
+   "id": "ca824723",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Note: you may need to restart the kernel to use updated packages.\n"
+     ]
+    }
+   ],
    "source": [
-    "from langchain_fireworks import Fireworks"
+    "%pip install -qU langchain-fireworks"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "ccff689e",
+   "id": "acc24d0c",
    "metadata": {},
    "source": [
-    "# Setup\n",
-    "\n",
-    "1. Make sure the `langchain-fireworks` package is installed in your environment.\n",
-    "2. Sign in to [Fireworks AI](http://fireworks.ai) for the an API Key to access our models, and make sure it is set as the `FIREWORKS_API_KEY` environment variable.\n",
-    "3. Set up your model using a model id. If the model is not set, the default model is fireworks-llama-v2-7b-chat. See the full, most up-to-date model list on [fireworks.ai](https://fireworks.ai)."
+    "## Instantiation"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 3,
-   "id": "9ca87a2e",
+   "id": "d285fd7f",

----------------------------------------

File: docs/docs/integrations/llms/friendli.ipynb
Status: modified
Changes: +10 -37
Diff:
@@ -40,12 +40,7 @@
    "execution_count": 1,
    "metadata": {},
    "outputs": [],
-   "source": [
-    "import getpass\n",
-    "import os\n",
-    "\n",
-    "os.environ[\"FRIENDLI_TOKEN\"] = getpass.getpass(\"Friendi Personal Access Token: \")"
-   ]
+   "source": ["import getpass\nimport os\n\nif \"FRIENDLI_TOKEN\" not in os.environ:\n    os.environ[\"FRIENDLI_TOKEN\"] = getpass.getpass(\"Friendi Personal Access Token: \")"]
   },
   {
    "cell_type": "markdown",
@@ -59,11 +54,7 @@
    "execution_count": 2,
    "metadata": {},
    "outputs": [],
-   "source": [
-    "from langchain_community.llms.friendli import Friendli\n",
-    "\n",
-    "llm = Friendli(model=\"mixtral-8x7b-instruct-v0-1\", max_tokens=100, temperature=0)"
-   ]
+   "source": ["from langchain_community.llms.friendli import Friendli\n\nllm = Friendli(model=\"mixtral-8x7b-instruct-v0-1\", max_tokens=100, temperature=0)"]
   },
   {
    "cell_type": "markdown",
@@ -97,9 +88,7 @@
      "output_type": "execute_result"
     }
    ],
-   "source": [
-    "llm.invoke(\"Tell me a joke.\")"
-   ]
+   "source": ["llm.invoke(\"Tell me a joke.\")"]
   },
   {
    "cell_type": "code",
@@ -118,9 +107,7 @@

----------------------------------------

File: docs/docs/integrations/llms/index.mdx
Status: added
Changes: +30 -0
Diff:
@@ -0,0 +1,30 @@
+---
+sidebar_position: 0
+sidebar_class_name: hidden
+keywords: [compatibility]
+---
+
+# LLMs
+
+:::caution

----------------------------------------

File: docs/docs/integrations/llms/konko.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -74,7 +74,7 @@
     }
    ],
    "source": [
-    "from langchain.llms import Konko\n",
+    "from langchain_community.llms import Konko\n",
     "\n",
     "llm = Konko(model=\"mistralai/mistral-7b-v0.1\", temperature=0.1, max_tokens=128)\n",
     "\n",

----------------------------------------

File: docs/docs/integrations/llms/openai.ipynb
Status: modified
Changes: +122 -67
Diff:
@@ -19,127 +19,139 @@
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 1,
-   "id": "5d71df86-8a17-4283-83d7-4e46e7c06c44",
-   "metadata": {
-    "tags": []
-   },
-   "outputs": [],
+   "cell_type": "markdown",
+   "id": "74312161",
+   "metadata": {},
    "source": [
-    "# get a token: https://platform.openai.com/account/api-keys\n",
+    "## Overview\n",
+    "\n",
+    "### Integration details\n",
+    "| Class | Package | Local | Serializable | [JS support](https://js.langchain.com/v0.2/docs/integrations/chat/openai) | Package downloads | Package latest |\n",
+    "| :--- | :--- | :---: | :---: |  :---: | :---: | :---: |\n",
+    "| [ChatOpenAI](https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html) | [langchain-openai](https://api.python.langchain.com/en/latest/openai_api_reference.html) | ❌ | beta | ✅ | ![PyPI - Downloads](https://img.shields.io/pypi/dm/langchain-openai?style=flat-square&label=%20) | ![PyPI - Version](https://img.shields.io/pypi/v/langchain-openai?style=flat-square&label=%20) |\n",
+    "\n",
     "\n",
-    "from getpass import getpass\n",
+    "## Setup\n",
     "\n",
-    "OPENAI_API_KEY = getpass()"
+    "To access OpenAI models you'll need to create an OpenAI account, get an API key, and install the `langchain-openai` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to https://platform.openai.com to sign up to OpenAI and generate an API key. Once you've done this set the OPENAI_API_KEY environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
-   "id": "5472a7cd-af26-48ca-ae9b-5f6ae73c74d2",
-   "metadata": {
-    "tags": []
-   },
-   "outputs": [],
+   "execution_count": null,
+   "id": "efcdb2b6",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Enter your OpenAI API key:  ········\n"
+     ]
+    }
+   ],
    "source": [
+    "import getpass\n",
     "import os\n",
     "\n",
-    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
+    "if \"OPENAI_API_KEY\" not in os.environ:\n",
+    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "129a3275",
+   "id": "f5d528fa",
    "metadata": {},
    "source": [
-    "Should you need to specify your organization ID, you can use the following cell. However, it is not required if you are only part of a single organization or intend to use your default organization. You can check your default organization [here](https://platform.openai.com/account/api-keys).\n",
-    "\n",
-    "To specify your organization, you can use this:\n",
-    "```python\n",
-    "OPENAI_ORGANIZATION = getpass()\n",
-    "\n",
-    "os.environ[\"OPENAI_ORGANIZATION\"] = OPENAI_ORGANIZATION\n",
-    "```"
+    "If you want to get automated best in-class tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
-   "id": "6fb585dd",
-   "metadata": {
-    "tags": []
-   },
+   "execution_count": null,
+   "id": "52fa46e8",
+   "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain_core.prompts import PromptTemplate\n",
-    "from langchain_openai import OpenAI"

----------------------------------------

File: docs/docs/integrations/llms/runhouse.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -7,7 +7,7 @@
    "source": [
     "# Runhouse\n",
     "\n",
-    "The [Runhouse](https://github.com/run-house/runhouse) allows remote compute and data across environments and users. See the [Runhouse docs](https://runhouse-docs.readthedocs-hosted.com/en/latest/).\n",
+    "[Runhouse](https://github.com/run-house/runhouse) allows remote compute and data across environments and users. See the [Runhouse docs](https://www.run.house/docs).\n",
     "\n",
     "This example goes over how to use LangChain and [Runhouse](https://github.com/run-house/runhouse) to interact with models hosted on your own GPU, or on-demand GPUs on AWS, GCP, AWS, or Lambda.\n",
     "\n",

----------------------------------------

File: docs/docs/integrations/memory/motorhead_memory.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -19,7 +19,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.memory.motorhead_memory import MotorheadMemory"
+    "from langchain_community.memory.motorhead_memory import MotorheadMemory"
    ]
   },
   {

----------------------------------------

File: docs/docs/integrations/memory/zep_memory.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -48,7 +48,7 @@
     "from uuid import uuid4\n",
     "\n",
     "from langchain.agents import AgentType, initialize_agent\n",
-    "from langchain.memory import ZepMemory\n",
+    "from langchain_community.memory.zep_memory import ZepMemory\n",
     "from langchain_community.retrievers import ZepRetriever\n",
     "from langchain_community.utilities import WikipediaAPIWrapper\n",
     "from langchain_core.messages import AIMessage, HumanMessage\n",

----------------------------------------

File: docs/docs/integrations/memory/zep_memory_cloud.ipynb
Status: modified
Changes: +2 -1
Diff:
@@ -69,11 +69,12 @@
    "source": [
     "from uuid import uuid4\n",
     "\n",
-    "from langchain.agents import AgentType, Tool, initialize_agent\n",
+    "from langchain.agents import AgentType, initialize_agent\n",
     "from langchain_community.memory.zep_cloud_memory import ZepCloudMemory\n",
     "from langchain_community.retrievers import ZepCloudRetriever\n",
     "from langchain_community.utilities import WikipediaAPIWrapper\n",
     "from langchain_core.messages import AIMessage, HumanMessage\n",

----------------------------------------

File: docs/docs/integrations/platforms/aws.mdx
Status: modified
Changes: +2 -2
Diff:
@@ -308,7 +308,7 @@ See a [usage example](/docs/integrations/graphs/amazon_neptune_open_cypher).
 ```python
 from langchain_community.graphs import NeptuneGraph
 from langchain_community.graphs import NeptuneAnalyticsGraph
-from langchain.chains import NeptuneOpenCypherQAChain
+from langchain_community.chains.graph_qa.neptune_cypher import NeptuneOpenCypherQAChain
 ```
 
 ### Amazon Neptune with SPARQL
@@ -317,7 +317,7 @@ See a [usage example](/docs/integrations/graphs/amazon_neptune_sparql).

----------------------------------------

File: docs/docs/integrations/platforms/huggingface.mdx
Status: modified
Changes: +1 -1
Diff:
@@ -122,5 +122,5 @@ pip install transformers huggingface_hub
 See a [usage example](/docs/integrations/tools/huggingface_tools).
 
 ```python
-from langchain.agents import load_huggingface_tool
+from langchain_community.agent_toolkits.load_tools import load_huggingface_tool
 ```

----------------------------------------

File: docs/docs/integrations/platforms/microsoft.mdx
Status: modified
Changes: +38 -0
Diff:
@@ -237,6 +237,26 @@ See a [usage example](/docs/integrations/document_loaders/microsoft_onenote).
 from langchain_community.document_loaders.onenote import OneNoteLoader
 ```
 
+### Playwright URL Loader
+
+>[Playwright](https://github.com/microsoft/playwright) is an open-source automation tool 
+> developed by `Microsoft` that allows you to programmatically control and automate 
+> web browsers. It is designed for end-to-end testing, scraping, and automating 
+> tasks across various web browsers such as `Chromium`, `Firefox`, and `WebKit`.
+
+
+First, let's install dependencies:
+
+```bash
+pip install playwright unstructured
+```

----------------------------------------

File: docs/docs/integrations/providers/github.mdx
Status: modified
Changes: +1 -2
Diff:
@@ -18,6 +18,5 @@ There are two document loaders available for GitHub.
 See a [usage example](/docs/integrations/document_loaders/github).
 
 ```python
-from langchain_community.document_loaders import GitHubIssuesLoader
-from langchain.document_loaders import GithubFileLoader
+from langchain_community.document_loaders import GitHubIssuesLoader, GithubFileLoader
 ```

----------------------------------------

File: docs/docs/integrations/providers/ieit_systems.mdx
Status: added
Changes: +31 -0
Diff:
@@ -0,0 +1,31 @@
+# IEIT Systems
+
+>[IEIT Systems](https://en.ieisystem.com/) is a Chinese information technology company 
+> established in 1999. It provides the IT infrastructure products, solutions, 
+> and services, innovative IT products and solutions across cloud computing, 
+> big data, and artificial intelligence.
+
+
+## LLMs

----------------------------------------

File: docs/docs/integrations/providers/iflytek.mdx
Status: added
Changes: +38 -0
Diff:
@@ -0,0 +1,38 @@
+# iFlytek
+
+>[iFlytek](https://www.iflytek.com) is a Chinese information technology company 
+> established in 1999. It creates voice recognition software and 
+> voice-based internet/mobile products covering education, communication, 
+> music, intelligent toys industries.
+
+
+## Installation and Setup
+
+- Get `SparkLLM` app_id, api_key and api_secret from [iFlyTek SparkLLM API Console](https://console.xfyun.cn/services/bm3) (for more info, see [iFlyTek SparkLLM Intro](https://xinghuo.xfyun.cn/sparkapi)).
+- Install the Python package (not for the embedding models):

----------------------------------------

File: docs/docs/integrations/providers/konko.mdx
Status: modified
Changes: +1 -1
Diff:
@@ -41,7 +41,7 @@ See a usage [example](/docs/integrations/llms/konko).
 - **Completion with mistralai/Mistral-7B-v0.1:**
 
   ```python
-  from langchain.llms import Konko
+  from langchain_community.llms import Konko
   llm = Konko(max_tokens=800, model='mistralai/Mistral-7B-v0.1')
   prompt = "Generate a Product Description for Apple Iphone 15"
   response = llm.invoke(prompt)

----------------------------------------

File: docs/docs/integrations/providers/llamacpp.mdx
Status: modified
Changes: +34 -10
Diff:
@@ -1,26 +1,50 @@
 # Llama.cpp
 
-This page covers how to use [llama.cpp](https://github.com/ggerganov/llama.cpp) within LangChain.
-It is broken into two parts: installation and setup, and then references to specific Llama-cpp wrappers.
+>[llama.cpp python](https://github.com/abetlen/llama-cpp-python) library is a simple Python bindings for `@ggerganov`
+>[llama.cpp](https://github.com/ggerganov/llama.cpp).
+>
+>This package provides:
+>
+> - Low-level access to C API via ctypes interface.
+> - High-level Python API for text completion
+>   - `OpenAI`-like API
+>   - `LangChain` compatibility
+>   - `LlamaIndex` compatibility
+> - OpenAI compatible web server
+>   - Local Copilot replacement
+>   - Function Calling support
+>   - Vision API support
+>   - Multiple Models

----------------------------------------

File: docs/docs/integrations/providers/maritalk.mdx
Status: added
Changes: +21 -0
Diff:
@@ -0,0 +1,21 @@
+# MariTalk
+
+>[MariTalk](https://www.maritaca.ai/en) is an LLM-based chatbot trained to meet the needs of Brazil.
+
+## Installation and Setup
+
+You have to get the MariTalk API key.
+
+You also need to install the `httpx` Python package.

----------------------------------------

File: docs/docs/integrations/providers/mlflow_tracking.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -167,7 +167,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.schema.output_parser import StrOutputParser\n",
+    "from langchain_core.output_parsers import StrOutputParser\n",
     "from langchain_core.prompts import ChatPromptTemplate\n",
     "from langchain_openai import ChatOpenAI\n",
     "\n",

----------------------------------------

File: docs/docs/integrations/providers/mlx.mdx
Status: added
Changes: +34 -0
Diff:
@@ -0,0 +1,34 @@
+# MLX
+
+>[MLX](https://ml-explore.github.io/mlx/build/html/index.html) is a `NumPy`-like array framework 
+> designed for efficient and flexible machine learning on `Apple` silicon, 
+> brought to you by `Apple machine learning research`.
+
+
+## Installation and Setup
+
+Install several Python packages:

----------------------------------------

File: docs/docs/integrations/providers/motorhead.mdx
Status: modified
Changes: +1 -1
Diff:
@@ -12,5 +12,5 @@ See instructions at [Motörhead](https://github.com/getmetal/motorhead) for runn
 See a [usage example](/docs/integrations/memory/motorhead_memory).
 
 ```python
-from langchain.memory import MotorheadMemory
+from langchain_community.memory import MotorheadMemory
 ```

----------------------------------------

File: docs/docs/integrations/providers/octoai.mdx
Status: added
Changes: +37 -0
Diff:
@@ -0,0 +1,37 @@
+# OctoAI
+
+>[OctoAI](https://docs.octoai.cloud/docs) offers easy access to efficient compute 
+> and enables users to integrate their choice of AI models into applications. 
+> The `OctoAI` compute service helps you run, tune, and scale AI applications easily.
+
+
+## Installation and Setup
+
+- Install the `openai` Python package:
+  ```bash

----------------------------------------

File: docs/docs/integrations/providers/perplexity.mdx
Status: added
Changes: +25 -0
Diff:
@@ -0,0 +1,25 @@
+# Perplexity
+
+>[Perplexity](https://www.perplexity.ai/pro) is the most powerful way to search 
+> the internet with unlimited Pro Search, upgraded AI models, unlimited file upload, 
+> image generation, and API credits.
+>
+> You can check a [list of available models](https://docs.perplexity.ai/docs/model-cards).
+
+## Installation and Setup

----------------------------------------

File: docs/docs/integrations/providers/vectara/vectara_chat.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -108,7 +108,7 @@
    },
    "outputs": [],
    "source": [
-    "from langchain.document_loaders import TextLoader\n",
+    "from langchain_community.document_loaders import TextLoader\n",
     "\n",
     "loader = TextLoader(\"state_of_the_union.txt\")\n",
     "documents = loader.load()\n",

----------------------------------------

File: docs/docs/integrations/providers/zep.mdx
Status: modified
Changes: +2 -2
Diff:
@@ -86,7 +86,7 @@ See a [Perpetual Memory Example here](/docs/integrations/memory/zep_cloud_chat_m
 
 You can use `ZepCloudMemory` together with agents that support Memory.
 ```python
-from langchain.memory import ZepCloudMemory
+from langchain_community.memory import ZepCloudMemory
 ```
 
 See a [Memory RAG Example here](/docs/integrations/memory/zep_memory_cloud).
@@ -117,4 +117,4 @@ MMR search is useful for ensuring that the retrieved documents are diverse and n

----------------------------------------

File: docs/docs/integrations/providers/zhipuai.mdx
Status: added
Changes: +18 -0
Diff:
@@ -0,0 +1,18 @@
+# Zhipu AI
+
+>[Zhipu AI](https://www.zhipuai.cn/en/aboutus), originating from the technological 
+> advancements of `Tsinghua University's Computer Science Department`, 
+> is an artificial intelligence company with the mission of teaching machines 
+> to think like humans. Its world-leading AI team has developed the cutting-edge 
+> large language and multimodal models and built the high-precision billion-scale 
+> knowledge graphs, the combination of which uniquely empowers us to create a powerful 
+> data- and knowledge-driven cognitive engine towards artificial general intelligence.

----------------------------------------

File: docs/docs/integrations/retrievers/arxiv.ipynb
Status: modified
Changes: +4 -6
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "id": "00a924a0-57e2-43fa-95dc-3ea48a56d3a5",
    "metadata": {},
    "source": [
@@ -17,8 +17,6 @@

----------------------------------------

File: docs/docs/integrations/retrievers/azure_ai_search.ipynb
Status: modified
Changes: +4 -5
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "id": "f9a62e19-b00b-4f6c-a700-1e500e4c290a",
    "metadata": {},
    "source": [
@@ -17,7 +17,6 @@

----------------------------------------

File: docs/docs/integrations/retrievers/bedrock.ipynb
Status: modified
Changes: +4 -6
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "id": "b0872249-1af5-4d54-b816-1babad7a8c9e",
    "metadata": {},
    "source": [
@@ -17,8 +17,6 @@

----------------------------------------

File: docs/docs/integrations/retrievers/dria_index.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -76,7 +76,7 @@
    },
    "outputs": [],
    "source": [
-    "from langchain.retrievers import DriaRetriever\n",
+    "from langchain_community.retrievers import DriaRetriever\n",
     "\n",
     "api_key = os.getenv(\"DRIA_API_KEY\")\n",
     "retriever = DriaRetriever(api_key=api_key)"

----------------------------------------

File: docs/docs/integrations/retrievers/elasticsearch_retriever.ipynb
Status: modified
Changes: +4 -5
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "id": "41ccce84-f6d9-4ba0-8281-22cbf29f20d3",
    "metadata": {},
    "source": [
@@ -17,7 +17,6 @@

----------------------------------------

File: docs/docs/integrations/retrievers/google_vertex_ai_search.ipynb
Status: modified
Changes: +4 -6
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "metadata": {},
    "source": [
     "---\n",
@@ -15,8 +15,6 @@

----------------------------------------

File: docs/docs/integrations/retrievers/index.mdx
Status: modified
Changes: +8 -12
Diff:
@@ -3,6 +3,8 @@ sidebar_position: 0
 sidebar_class_name: hidden
 ---
 
+import {CategoryTable, IndexTable} from '@theme/FeatureTables'
+
 # Retrievers
 
 A [retriever](/docs/concepts/#retrievers) is an interface that returns documents given an unstructured query.
@@ -22,20 +24,14 @@ This page lists custom retrievers, implemented via subclassing [BaseRetriever](/
 
 The below retrievers allow you to index and search a custom corpus of documents.

----------------------------------------

File: docs/docs/integrations/retrievers/milvus_hybrid_search.ipynb
Status: modified
Changes: +3 -7
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "metadata": {},
    "source": [
     "---\n",
@@ -15,8 +15,6 @@

----------------------------------------

File: docs/docs/integrations/retrievers/self_query/milvus_self_query.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -379,4 +379,4 @@
  },
  "nbformat": 4,
  "nbformat_minor": 4
-}
\ No newline at end of file
+}

----------------------------------------

File: docs/docs/integrations/retrievers/self_query/vectara_self_query.ipynb
Status: modified
Changes: +2 -1
Diff:
@@ -85,13 +85,14 @@
    "source": [
     "import os\n",
     "\n",
+    "from langchain_core.documents import Document\n",
+    "\n",
     "os.environ[\"VECTARA_API_KEY\"] = \"<YOUR_VECTARA_API_KEY>\"\n",
     "os.environ[\"VECTARA_CORPUS_ID\"] = \"<YOUR_VECTARA_CORPUS_ID>\"\n",
     "os.environ[\"VECTARA_CUSTOMER_ID\"] = \"<YOUR_VECTARA_CUSTOMER_ID>\"\n",
     "\n",

----------------------------------------

File: docs/docs/integrations/retrievers/tavily.ipynb
Status: modified
Changes: +4 -5
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "metadata": {},
    "source": [
     "---\n",
@@ -15,16 +15,15 @@

----------------------------------------

File: docs/docs/integrations/retrievers/thirdai_neuraldb.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -23,7 +23,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.retrievers import NeuralDBRetriever\n",
+    "from langchain_community.retrievers import NeuralDBRetriever\n",
     "\n",
     "# From scratch\n",
     "retriever = NeuralDBRetriever.from_scratch(thirdai_key=\"your-thirdai-key\")\n",

----------------------------------------

File: docs/docs/integrations/retrievers/wikipedia.ipynb
Status: modified
Changes: +4 -4
Diff:
@@ -1,7 +1,7 @@
 {
  "cells": [
   {
-   "cell_type": "markdown",
+   "cell_type": "raw",
    "id": "62727aaa-bcff-4087-891c-e539f824ee1f",
    "metadata": {},
    "source": [
@@ -24,9 +24,9 @@

----------------------------------------

File: docs/docs/integrations/retrievers/zep_memorystore.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -60,7 +60,7 @@
     "import time\n",
     "from uuid import uuid4\n",
     "\n",
-    "from langchain.memory import ZepMemory\n",
+    "from langchain_community.memory.zep_memory import ZepMemory\n",
     "from langchain_core.messages import AIMessage, HumanMessage\n",
     "\n",
     "# Set this to your Zep server URL\n",

----------------------------------------

File: docs/docs/integrations/retrievers/zilliz_cloud_pipeline.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -219,4 +219,4 @@
  },
  "nbformat": 4,
  "nbformat_minor": 2
-}
\ No newline at end of file
+}

----------------------------------------

File: docs/docs/integrations/text_embedding/ai21.ipynb
Status: modified
Changes: +180 -48
Diff:
@@ -2,116 +2,248 @@
  "cells": [
   {
    "cell_type": "raw",
-   "id": "c2923bd1",
+   "id": "afaf8039",
    "metadata": {},
    "source": [
     "---\n",
-    "sidebar_label: AI21 Labs\n",
+    "sidebar_label: AI21\n",
     "---"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "cc3c6ef6bbd57ce9",
-   "metadata": {
-    "collapsed": false
-   },
+   "id": "9a3d6f34",
+   "metadata": {},
    "source": [
     "# AI21Embeddings\n",
     "\n",
-    "This notebook covers how to get started with AI21 embedding models.\n",
+    "This will help you get started with AI21 embedding models using LangChain. For detailed documentation on `AI21Embeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_ai21.embeddings.AI21Embeddings.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"AI21\" />\n",
     "\n",
-    "## Installation"
+    "## Setup\n",
+    "\n",
+    "To access AI21 embedding models you'll need to create an AI21 account, get an API key, and install the `langchain-ai21` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to [https://docs.ai21.com/](https://docs.ai21.com/) to sign up to AI21 and generate an API key. Once you've done this set the `AI21_API_KEY` environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "4c3bef91",
+   "execution_count": 2,
+   "id": "36521c2a",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if not os.getenv(\"AI21_API_KEY\"):\n",
+    "    os.environ[\"AI21_API_KEY\"] = getpass.getpass(\"Enter your AI21 API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "c84fb993",
+   "metadata": {},
+   "source": [
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "id": "39a4953b",
    "metadata": {},
    "outputs": [],
    "source": [
-    "!pip install -qU langchain-ai21"
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "2b4f3e15",
+   "id": "d9664366",
    "metadata": {},
    "source": [
-    "## Environment Setup\n",
+    "### Installation\n",
     "\n",
-    "We'll need to get a [AI21 API key](https://docs.ai21.com/) and set the `AI21_API_KEY` environment variable:\n"
+    "The LangChain AI21 integration lives in the `langchain-ai21` package:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "62e0dbc3",
-   "metadata": {
-    "tags": []
-   },

----------------------------------------

File: docs/docs/integrations/text_embedding/azureopenai.ipynb
Status: modified
Changes: +156 -90
Diff:
@@ -2,195 +2,261 @@
  "cells": [
   {
    "cell_type": "raw",
-   "id": "0aed0743",
+   "id": "afaf8039",
    "metadata": {},
    "source": [
     "---\n",
-    "keywords: [AzureOpenAIEmbeddings]\n",
+    "sidebar_label: AzureOpenAI\n",
     "---"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "c3852491",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
-    "# Azure OpenAI\n",
+    "# AzureOpenAIEmbeddings\n",
     "\n",
-    "Let's load the Azure OpenAI Embedding class with environment variables set to indicate to use Azure endpoints."
+    "This will help you get started with AzureOpenAI embedding models using LangChain. For detailed documentation on `AzureOpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.azure.AzureOpenAIEmbeddings.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"AzureOpenAI\" />\n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access AzureOpenAI embedding models you'll need to create an Azure account, get an API key, and install the `langchain-openai` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "You’ll need to have an Azure OpenAI instance deployed. You can deploy a version on Azure Portal following this [guide](https://learn.microsoft.com/en-us/azure/ai-services/openai/how-to/create-resource?pivots=web-portal).\n",
+    "\n",
+    "Once you have your instance running, make sure you have the name of your instance and key. You can find the key in the Azure Portal, under the “Keys and Endpoint” section of your instance.\n",
+    "\n",
+    "```bash\n",
+    "AZURE_OPENAI_ENDPOINT=<YOUR API ENDPOINT>\n",
+    "AZURE_OPENAI_API_KEY=<YOUR_KEY>\n",
+    "AZURE_OPENAI_API_VERSION=\"2024-02-01\"\n",
+    "```"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "228faf0c",
+   "execution_count": 8,
+   "id": "36521c2a",
    "metadata": {},
    "outputs": [],
    "source": [
-    "%pip install --upgrade --quiet langchain-openai"
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
+    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your AzureOpenAI API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "c84fb993",
+   "metadata": {},
+   "source": [
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
-   "id": "8a6ed30d-806f-4800-b5fd-d04126be9060",
+   "execution_count": 9,
+   "id": "39a4953b",
    "metadata": {},
    "outputs": [],
    "source": [
-    "import os\n",
-    "\n",
-    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"...\"\n",
-    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://<your-endpoint>.openai.azure.com/\""
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 2,
-   "id": "20179bc7-3f71-4909-be12-d38bce009b18",
+   "cell_type": "markdown",
+   "id": "d9664366",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "from langchain_openai import AzureOpenAIEmbeddings\n",
+    "### Installation\n",
     "\n",
-    "embeddings = AzureOpenAIEmbeddings(\n",
-    "    azure_deployment=\"<your-embeddings-deployment-name>\",\n",
-    "    openai_api_version=\"2023-05-15\",\n",
-    ")"
+    "The LangChain AzureOpenAI integration lives in the `langchain-openai` package:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
-   "id": "f8cb9dca-738b-450f-9986-5c3efd3c6eb3",
+   "execution_count": null,
+   "id": "64853226",
    "metadata": {},
    "outputs": [],
    "source": [

----------------------------------------

File: docs/docs/integrations/text_embedding/bge_huggingface.ipynb
Status: modified
Changes: +5 -3
Diff:
@@ -43,10 +43,12 @@
    ]
   },
   {
-   "metadata": {},
    "cell_type": "markdown",
-   "source": "Note that you need to pass `query_instruction=\"\"` for `model_name=\"BAAI/bge-m3\"` see [FAQ BGE M3](https://huggingface.co/BAAI/bge-m3#faq). ",
-   "id": "f35d54e529c4cb77"
+   "id": "f35d54e529c4cb77",
+   "metadata": {},

----------------------------------------

File: docs/docs/integrations/text_embedding/cohere.ipynb
Status: modified
Changes: +174 -38
Diff:
@@ -1,105 +1,246 @@
 {
  "cells": [
+  {
+   "cell_type": "raw",
+   "id": "afaf8039",
+   "metadata": {},
+   "source": [
+    "---\n",
+    "sidebar_label: Cohere\n",
+    "---"
+   ]
+  },
   {
    "cell_type": "markdown",
-   "id": "42f76e43",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
-    "# Cohere\n",
+    "# CohereEmbeddings\n",
+    "\n",
+    "This will help you get started with Cohere embedding models using LangChain. For detailed documentation on `CohereEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_cohere.embeddings.CohereEmbeddings.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"Cohere\" />\n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access Cohere embedding models you'll need to create a/an Cohere account, get an API key, and install the `langchain-cohere` integration package.\n",
     "\n",
-    "Let's load the Cohere Embedding class."
+    "### Credentials\n",
+    "\n",
+    "\n",
+    "Head to [cohere.com](https://cohere.com) to sign up to Cohere and generate an API key. Once you’ve done this set the COHERE_API_KEY environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 1,
-   "id": "1bfad19b",
+   "execution_count": 8,
+   "id": "36521c2a",
    "metadata": {},
    "outputs": [],
    "source": [
     "import getpass\n",
     "import os\n",
     "\n",
-    "os.environ[\"COHERE_API_KEY\"] = getpass.getpass()"
+    "if not os.getenv(\"COHERE_API_KEY\"):\n",
+    "    os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "c84fb993",
+   "metadata": {},
+   "source": [
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 2,
-   "id": "6b82f59f",
+   "execution_count": 9,
+   "id": "39a4953b",
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain_cohere import CohereEmbeddings"
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d9664366",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "The LangChain Cohere integration lives in the `langchain-cohere` package:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
-   "id": "26895c60",
+   "execution_count": null,
+   "id": "64853226",

----------------------------------------

File: docs/docs/integrations/text_embedding/fireworks.ipynb
Status: modified
Changes: +182 -33
Diff:
@@ -1,19 +1,88 @@
 {
  "cells": [
+  {
+   "cell_type": "raw",
+   "id": "afaf8039",
+   "metadata": {},
+   "source": [
+    "---\n",
+    "sidebar_label: Fireworks\n",
+    "---"
+   ]
+  },
   {
    "cell_type": "markdown",
-   "id": "b14a24db",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
     "# FireworksEmbeddings\n",
     "\n",
-    "This notebook explains how to use Fireworks Embeddings, which is included in the langchain_fireworks package, to embed texts in langchain. We use the default nomic-ai v1.5 model in this example."
+    "This will help you get started with Fireworks embedding models using LangChain. For detailed documentation on `FireworksEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_fireworks.embeddings.FireworksEmbeddings.html).\n",
+    "\n",
+    "## Overview\n",
+    "\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"Fireworks\" />\n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access Fireworks embedding models you'll need to create a Fireworks account, get an API key, and install the `langchain-fireworks` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to [fireworks.ai](https://fireworks.ai/) to sign up to Fireworks and generate an API key. Once you’ve done this set the FIREWORKS_API_KEY environment variable:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "id": "36521c2a",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if not os.getenv(\"FIREWORKS_API_KEY\"):\n",
+    "    os.environ[\"FIREWORKS_API_KEY\"] = getpass.getpass(\"Enter your Fireworks API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "c84fb993",
+   "metadata": {},
+   "source": [
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "39a4953b",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d9664366",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "The LangChain Fireworks integration lives in the `langchain-fireworks` package:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "0ab948fc",
+   "id": "64853226",
    "metadata": {},
    "outputs": [],
    "source": [
@@ -22,83 +91,163 @@
   },
   {
    "cell_type": "markdown",
-   "id": "67c637ca",
+   "id": "45dd1724",

----------------------------------------

File: docs/docs/integrations/text_embedding/index.mdx
Status: modified
Changes: +8 -104
Diff:
@@ -5,110 +5,14 @@ sidebar_class_name: hidden
 
 # Embedding models
 
-**Embedding model** classes are implemented by inheriting the [Embeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_core.embeddings.Embeddings.html) class.
+import { CategoryTable, IndexTable } from "@theme/FeatureTables";
 
-This table lists all 100 derived classes.
+[Embedding models](/docs/concepts#embedding-models) create a vector representation of a piece of text.
 
+This page documents integrations with various model providers that allow you to use embeddings in LangChain.
 
-| Namespace 🔻 | Class |
-|------------|---------|
-| langchain.chains.hyde.base | [HypotheticalDocumentEmbedder](https://api.python.langchain.com/en/latest/chains/langchain.chains.hyde.base.HypotheticalDocumentEmbedder.html) |
-| langchain.embeddings.cache | [CacheBackedEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.cache.CacheBackedEmbeddings.html) |
-| langchain_ai21.embeddings | [AI21Embeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_ai21.embeddings.AI21Embeddings.html) |
-| langchain_aws.embeddings.bedrock | [BedrockEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_aws.embeddings.bedrock.BedrockEmbeddings.html) |
-| langchain_cohere.embeddings | [CohereEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_cohere.embeddings.CohereEmbeddings.html) |
-| langchain_community.embeddings.aleph_alpha | [AlephAlphaAsymmetricSemanticEmbedding](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.aleph_alpha.AlephAlphaAsymmetricSemanticEmbedding.html) |
-| langchain_community.embeddings.aleph_alpha | [AlephAlphaSymmetricSemanticEmbedding](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.aleph_alpha.AlephAlphaSymmetricSemanticEmbedding.html) |
-| langchain_community.embeddings.anyscale | [AnyscaleEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.anyscale.AnyscaleEmbeddings.html) |
-| langchain_community.embeddings.awa | [AwaEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.awa.AwaEmbeddings.html) |
-| langchain_community.embeddings.azure_openai | [AzureOpenAIEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.azure_openai.AzureOpenAIEmbeddings.html) |
-| langchain_community.embeddings.baichuan | [BaichuanTextEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.baichuan.BaichuanTextEmbeddings.html) |
-| langchain_community.embeddings.baidu_qianfan_endpoint | [QianfanEmbeddingsEndpoint](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.baidu_qianfan_endpoint.QianfanEmbeddingsEndpoint.html) |
-| langchain_community.embeddings.bedrock | [BedrockEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.bedrock.BedrockEmbeddings.html) |
-| langchain_community.embeddings.bookend | [BookendEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.bookend.BookendEmbeddings.html) |
-| langchain_community.embeddings.clarifai | [ClarifaiEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.clarifai.ClarifaiEmbeddings.html) |
-| langchain_community.embeddings.cloudflare_workersai | [CloudflareWorkersAIEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.cloudflare_workersai.CloudflareWorkersAIEmbeddings.html) |
-| langchain_community.embeddings.clova | [ClovaEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.clova.ClovaEmbeddings.html) |
-| langchain_community.embeddings.cohere | [CohereEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.cohere.CohereEmbeddings.html) |
-| langchain_community.embeddings.dashscope | [DashScopeEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.dashscope.DashScopeEmbeddings.html) |
-| langchain_community.embeddings.databricks | [DatabricksEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.databricks.DatabricksEmbeddings.html) |
-| langchain_community.embeddings.deepinfra | [DeepInfraEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.deepinfra.DeepInfraEmbeddings.html) |
-| langchain_community.embeddings.edenai | [EdenAiEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.edenai.EdenAiEmbeddings.html) |
-| langchain_community.embeddings.elasticsearch | [ElasticsearchEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.elasticsearch.ElasticsearchEmbeddings.html) |
-| langchain_community.embeddings.embaas | [EmbaasEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.embaas.EmbaasEmbeddings.html) |
-| langchain_community.embeddings.ernie | [ErnieEmbeddings](https://api.python.langchain.com/en/latest/embeddings/langchain_community.embeddings.ernie.ErnieEmbeddings.html) |

----------------------------------------

File: docs/docs/integrations/text_embedding/llamacpp.ipynb
Status: modified
Changes: +18 -4
Diff:
@@ -4,9 +4,23 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "# Llama-cpp\n",
+    "# Llama.cpp\n",
     "\n",
-    "This notebook goes over how to use Llama-cpp embeddings within LangChain"
+    ">[llama.cpp python](https://github.com/abetlen/llama-cpp-python) library is a simple Python bindings for `@ggerganov`\n",
+    ">[llama.cpp](https://github.com/ggerganov/llama.cpp).\n",
+    ">\n",
+    ">This package provides:\n",

----------------------------------------

File: docs/docs/integrations/text_embedding/mistralai.ipynb
Status: modified
Changes: +184 -21
Diff:
@@ -1,81 +1,244 @@
 {
  "cells": [
+  {
+   "cell_type": "raw",
+   "id": "afaf8039",
+   "metadata": {},
+   "source": [
+    "---\n",
+    "sidebar_label: MistralAI\n",
+    "---"
+   ]
+  },
   {
    "cell_type": "markdown",
-   "id": "b14a24db",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
-    "# MistralAI\n",
+    "# MistralAIEmbeddings\n",
+    "\n",
+    "This will help you get started with MistralAI embedding models using LangChain. For detailed documentation on `MistralAIEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_mistralai.embeddings.MistralAIEmbeddings.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"MistralAI\" />\n",
     "\n",
-    "This notebook explains how to use MistralAIEmbeddings, which is included in the langchain_mistralai package, to embed texts in langchain."
+    "## Setup\n",
+    "\n",
+    "To access MistralAI embedding models you'll need to create a/an MistralAI account, get an API key, and install the `langchain-mistralai` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to [https://console.mistral.ai/](https://console.mistral.ai/) to sign up to MistralAI and generate an API key. Once you've done this set the MISTRALAI_API_KEY environment variable:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 1,
-   "id": "0ab948fc",
+   "id": "36521c2a",
    "metadata": {},
    "outputs": [],
    "source": [
-    "# pip install -U langchain-mistralai"
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if not os.getenv(\"MISTRALAI_API_KEY\"):\n",
+    "    os.environ[\"MISTRALAI_API_KEY\"] = getpass.getpass(\"Enter your MistralAI API key: \")"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "67c637ca",
+   "id": "c84fb993",
    "metadata": {},
    "source": [
-    "## import the library"
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
    "execution_count": 2,
-   "id": "5709b030",
+   "id": "39a4953b",
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain_mistralai import MistralAIEmbeddings"
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d9664366",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "The LangChain MistralAI integration lives in the `langchain-mistralai` package:"

----------------------------------------

File: docs/docs/integrations/text_embedding/nomic.ipynb
Status: modified
Changes: +184 -51
Diff:
@@ -12,121 +12,254 @@
   },
   {
    "cell_type": "markdown",
-   "id": "e49f1e0d",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
     "# NomicEmbeddings\n",
     "\n",
-    "This notebook covers how to get started with Nomic embedding models.\n",
+    "This will help you get started with Nomic embedding models using LangChain. For detailed documentation on `NomicEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_nomic.embeddings.NomicEmbeddings.html).\n",
     "\n",
-    "## Installation"
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"Nomic\" />\n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access Nomic embedding models you'll need to create a/an Nomic account, get an API key, and install the `langchain-nomic` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to [https://atlas.nomic.ai/](https://atlas.nomic.ai/) to sign up to Nomic and generate an API key. Once you've done this set the `NOMIC_API_KEY` environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "4c3bef91",
+   "execution_count": 2,
+   "id": "36521c2a",
    "metadata": {},
    "outputs": [],
    "source": [
-    "# install package\n",
-    "!pip install -U langchain-nomic"
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if not os.getenv(\"NOMIC_API_KEY\"):\n",
+    "    os.environ[\"NOMIC_API_KEY\"] = getpass.getpass(\"Enter your Nomic API key: \")"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "2b4f3e15",
+   "id": "c84fb993",
    "metadata": {},
    "source": [
-    "## Environment Setup\n",
-    "\n",
-    "Make sure to set the following environment variables:\n",
-    "\n",
-    "- `NOMIC_API_KEY`\n",
-    "\n",
-    "## Usage"
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "62e0dbc3",
-   "metadata": {
-    "tags": []
-   },
+   "execution_count": 3,
+   "id": "39a4953b",
+   "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain_nomic.embeddings import NomicEmbeddings\n",
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d9664366",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
     "\n",
-    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")"
+    "The LangChain Nomic integration lives in the `langchain-nomic` package:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "12fcfb4b",
+   "execution_count": 2,
+   "id": "64853226",
    "metadata": {},
-   "outputs": [],
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",

----------------------------------------

File: docs/docs/integrations/text_embedding/ollama.ipynb
Status: modified
Changes: +178 -69
Diff:
@@ -12,34 +12,20 @@
   },
   {
    "cell_type": "markdown",
-   "id": "e49f1e0d",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
     "# OllamaEmbeddings\n",
     "\n",
-    "This notebook covers how to get started with Ollama embedding models.\n",
+    "This will help you get started with Ollama embedding models using LangChain. For detailed documentation on `OllamaEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_ollama.embeddings.OllamaEmbeddings.html).\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"Ollama\" />\n",
     "\n",
-    "## Installation"
-   ]
-  },
-  {
-   "cell_type": "raw",
-   "id": "57f50aa5",
-   "metadata": {
-    "vscode": {
-     "languageId": "raw"
-    }
-   },
-   "source": [
-    "# install package\n",
-    "%pip install langchain_ollama"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "2b4f3e15",
-   "metadata": {},
-   "source": [
     "## Setup\n",
     "\n",
     "First, follow [these instructions](https://github.com/jmorganca/ollama) to set up and run a local Ollama instance:\n",
@@ -60,86 +46,209 @@
     "* View the [Ollama documentation](https://github.com/jmorganca/ollama) for more commands. Run `ollama help` in the terminal to see available commands too.\n",
     "\n",
     "\n",
-    "## Usage"
+    "### Credentials\n",
+    "\n",
+    "There is no built-in auth mechanism for Ollama."
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "c84fb993",
+   "metadata": {},
+   "source": [
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 4,
-   "id": "62e0dbc3",
-   "metadata": {
-    "tags": []
-   },
+   "execution_count": 1,
+   "id": "39a4953b",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d9664366",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
+    "\n",
+    "The LangChain Ollama integration lives in the `langchain-ollama` package:"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "64853226",
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "Note: you may need to restart the kernel to use updated packages.\n"
+     ]
+    }
+   ],

----------------------------------------

File: docs/docs/integrations/text_embedding/openai.ipynb
Status: modified
Changes: +132 -157
Diff:
@@ -2,277 +2,257 @@
  "cells": [
   {
    "cell_type": "raw",
-   "id": "ae8077b8",
-   "metadata": {
-    "vscode": {
-     "languageId": "raw"
-    }
-   },
+   "id": "afaf8039",
+   "metadata": {},
    "source": [
     "---\n",
+    "sidebar_label: OpenAI\n",
     "keywords: [openaiembeddings]\n",
     "---"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "278b6c63",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
-    "# OpenAI\n",
+    "# OpenAIEmbeddings\n",
+    "\n",
+    "This will help you get started with OpenAI embedding models using LangChain. For detailed documentation on `OpenAIEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.base.OpenAIEmbeddings.html).\n",
+    "\n",
+    "\n",
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"OpenAI\" />\n",
     "\n",
-    "Let's load the OpenAI Embedding class."
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "40ff98ff-58e9-4716-8788-227a5c3f473d",
-   "metadata": {},
-   "source": [
     "## Setup\n",
     "\n",
-    "First we install langchain-openai and set the required env vars"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "c66c4613-6c67-40ca-b3b1-c026750d1742",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "%pip install -qU langchain-openai"
+    "To access OpenAI embedding models you'll need to create a/an OpenAI account, get an API key, and install the `langchain-openai` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to [platform.openai.com](https://platform.openai.com) to sign up to OpenAI and generate an API key. Once you’ve done this set the OPENAI_API_KEY environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "62e3710e-55a0-44fb-ba51-2f1d520dfc38",
+   "execution_count": 6,
+   "id": "36521c2a",
    "metadata": {},
    "outputs": [],
    "source": [
     "import getpass\n",
     "import os\n",
     "\n",
-    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
+    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
+    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
    ]
   },
   {
-   "cell_type": "code",
-   "execution_count": 1,
-   "id": "0be1af71",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "from langchain_openai import OpenAIEmbeddings"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 5,
-   "id": "2c66e5da",
+   "cell_type": "markdown",
+   "id": "c84fb993",
    "metadata": {},
-   "outputs": [],
    "source": [
-    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "id": "01370375",
+   "execution_count": 7,
+   "id": "39a4953b",
    "metadata": {},
    "outputs": [],
    "source": [
-    "text = \"This is a test document.\""
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "f012c222-3fa9-470a-935c-758b2048d9af",
+   "id": "d9664366",
    "metadata": {},
    "source": [
-    "## Usage\n",
-    "### Embed query"
+    "### Installation\n",
+    "\n",
+    "The LangChain OpenAI integration lives in the `langchain-openai` package:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 7,
-   "id": "bfb6142c",
+   "execution_count": null,
+   "id": "64853226",
    "metadata": {},
-   "outputs": [

----------------------------------------

File: docs/docs/integrations/text_embedding/pinecone.ipynb
Status: modified
Changes: +53 -53
Diff:
@@ -2,40 +2,45 @@
  "cells": [
   {
    "cell_type": "markdown",
+   "id": "f4b5d823fee826c2",
+   "metadata": {
+    "collapsed": false
+   },
    "source": [
     "# Pinecone Embeddings\n",
     "\n",
     "Pinecone's inference API can be accessed via `PineconeEmbeddings`. Providing text embeddings via the Pinecone service. We start by installing prerequisite libraries:"
-   ],
-   "metadata": {
-    "collapsed": false
-   },
-   "id": "f4b5d823fee826c2"
+   ]
   },
   {
    "cell_type": "code",
-   "outputs": [],
-   "source": [
-    "!pip install -qU \"langchain-pinecone>=0.2.0\" "
-   ],
+   "execution_count": null,
+   "id": "3bc5d3a5ed7f5ce3",
    "metadata": {
     "collapsed": false
    },
-   "id": "3bc5d3a5ed7f5ce3",
-   "execution_count": null
+   "outputs": [],
+   "source": [
+    "!pip install -qU \"langchain-pinecone>=0.2.0\" "
+   ]
   },
   {
    "cell_type": "markdown",
-   "source": [
-    "Next, we [sign up / log in to Pinecone](https://app.pinecone.io) to get our API key:"
-   ],
+   "id": "62a77d25c3fd8bd5",
    "metadata": {
     "collapsed": false
    },
-   "id": "62a77d25c3fd8bd5"
+   "source": [
+    "Next, we [sign up / log in to Pinecone](https://app.pinecone.io) to get our API key:"
+   ]
   },
   {
    "cell_type": "code",
+   "execution_count": null,
+   "id": "8162dbcbcf7d3d55",
+   "metadata": {
+    "collapsed": false
+   },
    "outputs": [],
    "source": [
     "import os\n",

----------------------------------------

File: docs/docs/integrations/text_embedding/together.ipynb
Status: modified
Changes: +188 -45
Diff:
@@ -12,101 +12,244 @@
   },
   {
    "cell_type": "markdown",
-   "id": "e49f1e0d",
+   "id": "9a3d6f34",
    "metadata": {},
    "source": [
     "# TogetherEmbeddings\n",
     "\n",
-    "This notebook covers how to get started with open source embedding models hosted in the Together AI API.\n",
+    "This will help you get started with Together embedding models using LangChain. For detailed documentation on `TogetherEmbeddings` features and configuration options, please refer to the [API reference](https://api.python.langchain.com/en/latest/embeddings/langchain_together.embeddings.TogetherEmbeddings.html).\n",
     "\n",
-    "## Installation"
+    "## Overview\n",
+    "### Integration details\n",
+    "\n",
+    "import { ItemTable } from \"@theme/FeatureTables\";\n",
+    "\n",
+    "<ItemTable category=\"text_embedding\" item=\"Together\" />\n",
+    "\n",
+    "## Setup\n",
+    "\n",
+    "To access Together embedding models you'll need to create a/an Together account, get an API key, and install the `langchain-together` integration package.\n",
+    "\n",
+    "### Credentials\n",
+    "\n",
+    "Head to [https://api.together.xyz/](https://api.together.xyz/) to sign up to Together and generate an API key. Once you've done this set the TOGETHER_API_KEY environment variable:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "4c3bef91",
+   "execution_count": 1,
+   "id": "36521c2a",
    "metadata": {},
    "outputs": [],
    "source": [
-    "# install package\n",
-    "%pip install --upgrade --quiet  langchain-together"
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "if not os.getenv(\"TOGETHER_API_KEY\"):\n",
+    "    os.environ[\"TOGETHER_API_KEY\"] = getpass.getpass(\"Enter your Together API key: \")"
    ]
   },
   {
    "cell_type": "markdown",
-   "id": "2b4f3e15",
+   "id": "c84fb993",
    "metadata": {},
    "source": [
-    "## Environment Setup\n",
-    "\n",
-    "Make sure to set the following environment variables:\n",
-    "\n",
-    "- `TOGETHER_API_KEY`\n",
-    "\n",
-    "## Usage\n",
-    "\n",
-    "First, select a supported model from [this list](https://docs.together.ai/docs/embedding-models). In the following example, we will use `togethercomputer/m2-bert-80M-8k-retrieval`."
+    "If you want to get automated tracing of your model calls you can also set your [LangSmith](https://docs.smith.langchain.com/) API key by uncommenting below:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "62e0dbc3",
-   "metadata": {
-    "tags": []
-   },
+   "execution_count": 2,
+   "id": "39a4953b",
+   "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain_together.embeddings import TogetherEmbeddings\n",
+    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
+    "# os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "d9664366",
+   "metadata": {},
+   "source": [
+    "### Installation\n",
     "\n",
-    "embeddings = TogetherEmbeddings(model=\"togethercomputer/m2-bert-80M-8k-retrieval\")"
+    "The LangChain Together integration lives in the `langchain-together` package:"
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": null,
-   "id": "12fcfb4b",
+   "execution_count": 3,

----------------------------------------

File: docs/docs/integrations/tools/connery.ipynb
Status: modified
Changes: +127 -15
Diff:
@@ -4,12 +4,9 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "# Connery Action Tool\n",
+    "# Connery Toolkit and Tools\n",
     "\n",
-    "Using this tool, you can integrate individual Connery Action into your LangChain agent.\n",
-    "\n",
-    "If you want to use more than one Connery Action in your agent,\n",
-    "check out the [Connery Toolkit](/docs/integrations/tools/connery_toolkit) documentation.\n",
+    "Using the Connery toolkit and tools, you can integrate Connery Actions into your LangChain agent.\n",
     "\n",
     "## What is Connery?\n",
     "\n",
@@ -25,33 +22,136 @@
     "- GitHub: https://github.com/connery-io/connery\n",
     "- Documentation: https://docs.connery.io\n",
     "\n",
-    "## Prerequisites\n",
+    "## Setup\n",
+    "\n",
+    "### Installation\n",
+    "\n",
+    "You need to install the `langchain_community` package to use the Connery tools."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install -qU langchain-community"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "### Credentials\n",
     "\n",
     "To use Connery Actions in your LangChain agent, you need to do some preparation:\n",
     "\n",
     "1. Set up the Connery runner using the [Quickstart](https://docs.connery.io/docs/runner/quick-start/) guide.\n",
     "2. Install all the plugins with the actions you want to use in your agent.\n",
-    "3. Set environment variables `CONNERY_RUNNER_URL` and `CONNERY_RUNNER_API_KEY` so the toolkit can communicate with the Connery Runner.\n",
+    "3. Set environment variables `CONNERY_RUNNER_URL` and `CONNERY_RUNNER_API_KEY` so the toolkit can communicate with the Connery Runner."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import getpass\n",
+    "import os\n",
+    "\n",
+    "for key in [\"CONNERY_RUNNER_URL\", \"CONNERY_RUNNER_API_KEY\"]:\n",
+    "    if key not in os.environ:\n",
+    "        os.environ[key] = getpass.getpass(f\"Please enter the value for {key}: \")"
+   ]

----------------------------------------

File: docs/docs/integrations/tools/connery_toolkit.ipynb
Status: removed
Changes: +0 -145
Diff:
@@ -1,145 +0,0 @@
-{
- "cells": [
-  {
-   "cell_type": "markdown",
-   "metadata": {},
-   "source": [
-    "# Connery Toolkit\n",
-    "\n",
-    "Using this toolkit, you can integrate Connery Actions into your LangChain agent.\n",
-    "\n",
-    "If you want to use only one particular Connery Action in your agent,\n",
-    "check out the [Connery Action Tool](/docs/integrations/tools/connery) documentation.\n",
-    "\n",
-    "## What is Connery?\n",
-    "\n",
-    "Connery is an open-source plugin infrastructure for AI.\n",
-    "\n",
-    "With Connery, you can easily create a custom plugin with a set of actions and seamlessly integrate them into your LangChain agent.\n",
-    "Connery will take care of critical aspects such as runtime, authorization, secret management, access management, audit logs, and other vital features.\n",
-    "\n",
-    "Furthermore, Connery, supported by our community, provides a diverse collection of ready-to-use open-source plugins for added convenience.\n",
-    "\n",
-    "Learn more about Connery:\n",
-    "\n",
-    "- GitHub: https://github.com/connery-io/connery\n",
-    "- Documentation: https://docs.connery.io\n",
-    "\n",
-    "## Prerequisites\n",
-    "\n",
-    "To use Connery Actions in your LangChain agent, you need to do some preparation:\n",
-    "\n",
-    "1. Set up the Connery runner using the [Quickstart](https://docs.connery.io/docs/runner/quick-start/) guide.\n",
-    "2. Install all the plugins with the actions you want to use in your agent.\n",
-    "3. Set environment variables `CONNERY_RUNNER_URL` and `CONNERY_RUNNER_API_KEY` so the toolkit can communicate with the Connery Runner.\n",
-    "\n",
-    "## Example of using Connery Toolkit\n",
-    "\n",
-    "In the example below, we create an agent that uses two Connery Actions to summarize a public webpage and send the summary by email:\n",
-    "\n",
-    "1. **Summarize public webpage** action from the [Summarization](https://github.com/connery-io/summarization-plugin) plugin.\n",
-    "2. **Send email** action from the [Gmail](https://github.com/connery-io/gmail) plugin.\n",
-    "\n",
-    "You can see a LangSmith trace of this example [here](https://smith.langchain.com/public/4af5385a-afe9-46f6-8a53-57fe2d63c5bc/r)."
-   ]
-  },
-  {
-   "cell_type": "code",

----------------------------------------

File: docs/docs/integrations/tools/financial_datasets.ipynb
Status: modified
Changes: +14 -0
Diff:
@@ -2,6 +2,7 @@
  "cells": [
   {
    "cell_type": "markdown",
+   "id": "9f9afdec",
    "metadata": {
     "collapsed": false
    },
@@ -21,6 +22,7 @@
   {
    "cell_type": "code",
    "execution_count": null,
+   "id": "0c9e4bc1",
    "metadata": {
     "collapsed": false
    },
@@ -35,6 +37,7 @@
   {
    "cell_type": "code",
    "execution_count": null,
+   "id": "0938e69e",
    "metadata": {
     "collapsed": false
    },
@@ -45,6 +48,7 @@
   },
   {
    "cell_type": "markdown",
+   "id": "a362df50",
    "metadata": {
     "collapsed": false
    },
@@ -114,6 +118,7 @@
   },
   {
    "cell_type": "markdown",
+   "id": "6cd0b36e",

----------------------------------------

File: docs/docs/integrations/tools/gmail.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -243,7 +243,7 @@
    "source": [
     "## API reference\n",
     "\n",
-    "For detailed documentation of all `GmailToolkit` features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/agent_toolkits/langchain_community.agent_toolkits.slack.toolkit.SlackToolkit.html)."
+    "For detailed documentation of all `GmailToolkit` features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/agent_toolkits/langchain_community.agent_toolkits.gmail.toolkit.GmailToolkit.html)."
    ]
   }
  ],

----------------------------------------

File: docs/docs/integrations/tools/huggingface_tools.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -49,7 +49,7 @@
     }
    ],
    "source": [
-    "from langchain.agents import load_huggingface_tool\n",
+    "from langchain_community.agent_toolkits.load_tools import load_huggingface_tool\n",
     "\n",
     "tool = load_huggingface_tool(\"lysandre/hf-model-downloads\")\n",
     "\n",

----------------------------------------

File: docs/docs/integrations/tools/openapi.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -169,7 +169,7 @@
    "outputs": [],
    "source": [
     "import spotipy.util as util\n",
-    "from langchain.requests import RequestsWrapper\n",
+    "from langchain_community.utilities.requests import RequestsWrapper\n",
     "\n",
     "\n",
     "def construct_spotify_auth_headers(raw_spec: dict):\n",

----------------------------------------

File: docs/docs/integrations/tools/playwright.ipynb
Status: modified
Changes: +5 -3
Diff:
@@ -6,6 +6,8 @@
    "source": [
     "# PlayWright Browser Toolkit\n",
     "\n",
+    ">[Playwright](https://github.com/microsoft/playwright) is an open-source automation tool developed by `Microsoft` that allows you to programmatically control and automate web browsers. It is designed for end-to-end testing, scraping, and automating tasks across various web browsers such as `Chromium`, `Firefox`, and `WebKit`.\n",
+    "\n",
     "This toolkit is used to interact with the browser. While other tools (like the `Requests` tools) are fine for static sites, `PlayWright Browser` toolkits let your agent navigate the web and interact with dynamically rendered sites. \n",
     "\n",
     "Some tools bundled within the `PlayWright Browser` toolkit include:\n",
@@ -296,7 +298,8 @@
       "```\n",
       "\n",

----------------------------------------

File: docs/docs/integrations/tools/polygon.ipynb
Status: modified
Changes: +476 -199

----------------------------------------

File: docs/docs/integrations/tools/polygon_toolkit.ipynb
Status: removed
Changes: +0 -187
Diff:
@@ -1,187 +0,0 @@
-{
- "cells": [
-  {
-   "cell_type": "markdown",
-   "id": "e6fd05db-21c2-4227-9900-0840bc62cb31",
-   "metadata": {},
-   "source": [
-    "# Polygon IO Toolkit\n",
-    "\n",
-    "This notebook shows how to use agents to interact with the [Polygon IO](https://polygon.io/) toolkit. The toolkit provides access to Polygon's Stock Market Data API."
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "a4da342d",
-   "metadata": {},
-   "source": [
-    "## Example Use\n",
-    "\n",
-    "\n",
-    "### Setup"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "id": "c17b33e0",
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "%pip install --upgrade --quiet langchain-community > /dev/null"
-   ]
-  },
-  {
-   "cell_type": "markdown",
-   "id": "3cd00ad2",
-   "metadata": {},
-   "source": [
-    "Get your Polygon IO API key [here](https://polygon.io/), and then set it below.\n",
-    "Note that the tool used in this example requires a \"Stocks Advanced\" subscription"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 6,
-   "id": "a180a2b8",
-   "metadata": {},
-   "outputs": [
-    {
-     "name": "stdout",
-     "output_type": "stream",
-     "text": [
-      "········\n"
-     ]
-    }
-   ],
-   "source": [
-    "import getpass\n",
-    "import os\n",
-    "\n",
-    "os.environ[\"POLYGON_API_KEY\"] = getpass.getpass()"

----------------------------------------

File: docs/docs/integrations/vectorstores/aperturedb.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -138,7 +138,7 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
+    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
     "\n",
     "text_splitter = RecursiveCharacterTextSplitter()\n",
     "documents = text_splitter.split_documents(docs)"

----------------------------------------

File: docs/docs/integrations/vectorstores/azure_cosmos_db.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -355,7 +355,7 @@
   {
    "cell_type": "code",
    "execution_count": null,
-   "id": "b63c73c7e905001c",
+   "id": "50bb4346",
    "metadata": {},
    "outputs": [],
    "source": []

----------------------------------------

File: docs/docs/integrations/vectorstores/index.mdx
Status: modified
Changes: +7 -19
Diff:
@@ -1,29 +1,17 @@
 ---
 sidebar_position: 0
 sidebar_class_name: hidden
-keywords: [compatibility]
-custom_edit_url:
 ---
 
 # Vectorstores
 
-## Features 
+import { CategoryTable, IndexTable } from "@theme/FeatureTables";

----------------------------------------

File: docs/docs/integrations/vectorstores/infinispanvs.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -119,8 +119,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.embeddings import HuggingFaceEmbeddings\n",
     "from langchain_core.embeddings import Embeddings\n",
+    "from langchain_huggingface import HuggingFaceEmbeddings\n",
     "\n",
     "model_name = \"sentence-transformers/all-MiniLM-L12-v2\"\n",
     "hf = HuggingFaceEmbeddings(model_name=model_name)"

----------------------------------------

File: docs/docs/integrations/vectorstores/manticore_search.ipynb
Status: modified
Changes: +2 -2
Diff:
@@ -174,9 +174,9 @@
    },
    "outputs": [],
    "source": [
-    "from langchain.text_splitter import CharacterTextSplitter\n",
     "from langchain_community.embeddings import GPT4AllEmbeddings\n",
-    "from langchain_community.vectorstores import ManticoreSearch, ManticoreSearchSettings"
+    "from langchain_community.vectorstores import ManticoreSearch, ManticoreSearchSettings\n",
+    "from langchain_text_splitters import CharacterTextSplitter"
    ]

----------------------------------------

File: docs/docs/integrations/vectorstores/qdrant.ipynb
Status: modified
Changes: +3 -3
Diff:
@@ -34,7 +34,7 @@
    },
    "outputs": [],
    "source": [
-    "%pip install -qU langchain-qdrant 'qdrant-client[fastembed]'"
+    "%pip install -qU langchain-qdrant"
    ]
   },
   {
@@ -628,7 +628,7 @@

----------------------------------------

File: docs/docs/integrations/vectorstores/upstash.ipynb
Status: modified
Changes: +146 -102
Diff:
@@ -43,7 +43,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 37,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -87,18 +87,18 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "[Document(page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.', metadata={'source': '../../how_to/state_of_the_union.txt'}),\n",
-       " Document(page_content='Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters.', metadata={'source': '../../how_to/state_of_the_union.txt'}),\n",
-       " Document(page_content='Putin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland.', metadata={'source': '../../how_to/state_of_the_union.txt'})]"
+       "[Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet. Justices of the Supreme Court. My fellow Americans.  \\n\\nLast year COVID-19 kept us apart. This year we are finally together again. \\n\\nTonight, we meet as Democrats Republicans and Independents. But most importantly as Americans. \\n\\nWith a duty to one another to the American people to the Constitution. \\n\\nAnd with an unwavering resolve that freedom will always triumph over tyranny. \\n\\nSix days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to his menacing ways. But he badly miscalculated. \\n\\nHe thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined. \\n\\nHe met the Ukrainian people. \\n\\nFrom President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.'),\n",
+       " Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending their homeland. \\n\\nIn this struggle as President Zelenskyy said in his speech to the European Parliament “Light will win over darkness.” The Ukrainian Ambassador to the United States is here tonight. \\n\\nLet each of us here tonight in this Chamber send an unmistakable signal to Ukraine and to the world. \\n\\nPlease rise if you are able and show that, Yes, we the United States of America stand with the Ukrainian people. \\n\\nThroughout our history we’ve learned this lesson when dictators do not pay a price for their aggression they cause more chaos.   \\n\\nThey keep moving.   \\n\\nAnd the costs and the threats to America and the world keep rising.   \\n\\nThat’s why the NATO Alliance was created to secure peace and stability in Europe after World War 2. \\n\\nThe United States is a member along with 29 other nations. \\n\\nIt matters. American diplomacy matters. American resolve matters.'),\n",
+       " Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='Putin’s latest attack on Ukraine was premeditated and unprovoked. \\n\\nHe rejected repeated efforts at diplomacy. \\n\\nHe thought the West and NATO wouldn’t respond. And he thought he could divide us at home. Putin was wrong. We were ready.  Here is what we did.   \\n\\nWe prepared extensively and carefully. \\n\\nWe spent months building a coalition of other freedom-loving nations from Europe and the Americas to Asia and Africa to confront Putin. \\n\\nI spent countless hours unifying our European allies. We shared with the world in advance what we knew Putin was planning and precisely how he would try to falsely justify his aggression.  \\n\\nWe countered Russia’s lies with truth.   \\n\\nAnd now that he has acted the free world is holding him accountable. \\n\\nAlong with twenty-seven members of the European Union including France, Germany, Italy, as well as countries like the United Kingdom, Canada, Japan, Korea, Australia, New Zealand, and many others, even Switzerland.')]"
       ]
      },
-     "execution_count": 17,
+     "execution_count": 6,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -126,20 +126,20 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 35,
+   "execution_count": 7,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "['82b3781b-817c-4a4d-8f8b-cbd07c1d005a',\n",
-       " 'a20e0a49-29d8-465e-8eae-0bc5ac3d24dc',\n",
-       " 'c19f4108-b652-4890-873e-d4cad00f1b1a',\n",
-       " '23d1fcf9-6ee1-4638-8c70-0f5030762301',\n",
-       " '2d775784-825d-4627-97a3-fee4539d8f58']"
+       "['247aa3ae-9be9-43e2-98e4-48f94f920749',\n",
+       " 'c4dfc886-0a2d-497c-b2b7-d923a5cb3832',\n",
+       " '0350761d-ca68-414e-b8db-7eca78cb0d18',\n",
+       " '902fe5eb-8543-486a-bd5f-79858a7a8af1',\n",
+       " '28875612-c672-4de4-b40a-3b658c72036a']"
       ]
      },
-     "execution_count": 35,
+     "execution_count": 7,
      "metadata": {},
      "output_type": "execute_result"
     }
@@ -154,33 +154,116 @@
    "cell_type": "markdown",
    "metadata": {},
    "source": [
-    "store"
+    "## Querying\n",
+    "\n",
+    "The database can be queried using a vector or a text prompt.\n",
+    "If a text prompt is used, it's first converted into embedding and then queried.\n",
+    "\n",
+    "The `k` parameter specifies how many results to return from the query."
    ]
   },
   {
    "cell_type": "code",
-   "execution_count": 27,
+   "execution_count": 8,
    "metadata": {},
    "outputs": [
     {
      "data": {
       "text/plain": [
-       "['fe1f7a7b-42e2-4828-88b0-5b449c49fe86',\n",
-       " '154a0021-a99c-427e-befb-f0b2b18ed83c',\n",
-       " 'a8218226-18a9-4ab5-ade5-5a71b19a7831',\n",
-       " '62b7ef97-83bf-4b6d-8c93-f471796244dc',\n",
-       " 'ab43fd2e-13df-46d4-8cf7-e6e16506e4bb',\n",
-       " '6841e7f9-adaa-41d9-af3d-0813ee52443f',\n",
-       " '45dda5a1-f0c1-4ac7-9acb-50253e4ee493']"
+       "[Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='If you travel 20 miles east of Columbus, Ohio, you’ll find 1,000 empty acres of land. \\n\\nIt won’t look like much, but if you stop and look closely, you’ll see a “Field of dreams,” the ground on which America’s future will be built. \\n\\nThis is where Intel, the American company that helped build Silicon Valley, is going to build its $20 billion semiconductor “mega site”. \\n\\nUp to eight state-of-the-art factories in one place. 10,000 new good-paying jobs. \\n\\nSome of the most sophisticated manufacturing in the world to make computer chips the size of a fingertip that power the world and our everyday lives. \\n\\nSmartphones. The Internet. Technology we have yet to invent. \\n\\nBut that’s just the beginning. \\n\\nIntel’s CEO, Pat Gelsinger, who is here tonight, told me they are ready to increase their investment from  \\n$20 billion to $100 billion. \\n\\nThat would be one of the biggest investments in manufacturing in American history. \\n\\nAnd all they’re waiting for is for you to pass this bill.'),\n",
+       " Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='So let’s not wait any longer. Send it to my desk. I’ll sign it.  \\n\\nAnd we will really take off. \\n\\nAnd Intel is not alone. \\n\\nThere’s something happening in America. \\n\\nJust look around and you’ll see an amazing story. \\n\\nThe rebirth of the pride that comes from stamping products “Made In America.” The revitalization of American manufacturing.   \\n\\nCompanies are choosing to build new factories here, when just a few years ago, they would have built them overseas. \\n\\nThat’s what is happening. Ford is investing $11 billion to build electric vehicles, creating 11,000 jobs across the country. \\n\\nGM is making the largest investment in its history—$7 billion to build electric vehicles, creating 4,000 jobs in Michigan. \\n\\nAll told, we created 369,000 new manufacturing jobs in America just last year. \\n\\nPowered by people I’ve met like JoJo Burgess, from generations of union steelworkers from Pittsburgh, who’s here with us tonight.'),\n",
+       " Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='When we use taxpayer dollars to rebuild America – we are going to Buy American: buy American products to support American jobs. \\n\\nThe federal government spends about $600 Billion a year to keep the country safe and secure. \\n\\nThere’s been a law on the books for almost a century \\nto make sure taxpayers’ dollars support American jobs and businesses. \\n\\nEvery Administration says they’ll do it, but we are actually doing it. \\n\\nWe will buy American to make sure everything from the deck of an aircraft carrier to the steel on highway guardrails are made in America. \\n\\nBut to compete for the best jobs of the future, we also need to level the playing field with China and other competitors. \\n\\nThat’s why it is so important to pass the Bipartisan Innovation Act sitting in Congress that will make record investments in emerging technologies and American manufacturing. \\n\\nLet me give you one example of why it’s so important to pass it.'),\n",
+       " Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='Last month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. \\n\\nIt’s based on DARPA—the Defense Department project that led to the Internet, GPS, and so much more.  \\n\\nARPA-H will have a singular purpose—to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more. \\n\\nA unity agenda for the nation. \\n\\nWe can do this. \\n\\nMy fellow Americans—tonight , we have gathered in a sacred space—the citadel of our democracy. \\n\\nIn this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done great things. \\n\\nWe have fought for freedom, expanded liberty, defeated totalitarianism and terror.'),\n",
+       " Document(metadata={'source': '../../how_to/state_of_the_union.txt'}, page_content='And based on the projections, more of the country will reach that point across the next couple of weeks. \\n\\nThanks to the progress we have made this past year, COVID-19 need no longer control our lives.  \\n\\nI know some are talking about “living with COVID-19”. Tonight – I say that we will never just accept living with COVID-19. \\n\\nWe will continue to combat the virus as we do other diseases. And because this is a virus that mutates and spreads, we will stay on guard. \\n\\nHere are four common sense steps as we move forward safely.  \\n\\nFirst, stay protected with vaccines and treatments. We know how incredibly effective vaccines are. If you’re vaccinated and boosted you have the highest degree of protection. \\n\\nWe will never give up on vaccinating more Americans. Now, I know parents with kids under 5 are eager to see a vaccine authorized for their children. \\n\\nThe scientists are working hard to get that done and we’ll be ready with plenty of vaccines when they do.')]"
       ]
      },
-     "execution_count": 27,
+     "execution_count": 8,
      "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "store.add_texts(\n",
+    "result = store.similarity_search(\"technology\", k=5)\n",
+    "result"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "metadata": {},
+   "source": [
+    "## Querying with score\n",
+    "\n",
+    "The score of the query can be included for every result. \n",
+    "\n",
+    "> The score returned in the query requests is a normalized value between 0 and 1, where 1 indicates the highest similarity and 0 the lowest regardless of the similarity function used. For more information look at the [docs](https://upstash.com/docs/vector/overall/features#vector-similarity-functions)."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 9,
+   "metadata": {},
+   "outputs": [
+    {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [

----------------------------------------

File: docs/docs/tutorials/agents.ipynb
Status: modified
Changes: +5 -5
Diff:
@@ -71,11 +71,11 @@
     "from langchain_anthropic import ChatAnthropic\n",
     "from langchain_community.tools.tavily_search import TavilySearchResults\n",
     "from langchain_core.messages import HumanMessage\n",
-    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
+    "from langgraph.checkpoint.memory import MemorySaver\n",
     "from langgraph.prebuilt import create_react_agent\n",
     "\n",
     "# Create the agent\n",
-    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
+    "memory = MemorySaver()\n",

----------------------------------------

File: docs/docs/tutorials/local_rag.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -87,8 +87,8 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
     "from langchain_community.document_loaders import WebBaseLoader\n",
+    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
     "\n",
     "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
     "data = loader.load()\n",

----------------------------------------

File: docs/docs/tutorials/qa_chat_history.ipynb
Status: modified
Changes: +4 -9
Diff:
@@ -857,9 +857,9 @@
    "metadata": {},
    "outputs": [],
    "source": [
-    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
+    "from langgraph.checkpoint.memory import MemorySaver\n",
     "\n",
-    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
+    "memory = MemorySaver()\n",
     "\n",
     "agent_executor = create_react_agent(llm, tools, checkpointer=memory)"

----------------------------------------

File: docs/docs/versions/migrating_chains/constitutional_chain.ipynb
Status: added
Changes: +332 -0
Diff:
@@ -0,0 +1,332 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "b57124cc-60a0-4c18-b7ce-3e483d1024a2",
+   "metadata": {},
+   "source": [
+    "---\n",
+    "title: Migrating from ConstitutionalChain\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "ce8457ed-c0b1-4a74-abbd-9d3d2211270f",
+   "metadata": {},
+   "source": [
+    "[ConstitutionalChain](https://api.python.langchain.com/en/latest/chains/langchain.chains.constitutional_ai.base.ConstitutionalChain.html) allowed for a LLM to critique and revise generations based on [principles](https://api.python.langchain.com/en/latest/chains/langchain.chains.constitutional_ai.models.ConstitutionalPrinciple.html), structured as combinations of critique and revision requests. For example, a principle might include a request to identify harmful content, and a request to rewrite the content.\n",
+    "\n",
+    "In `ConstitutionalChain`, this structure of critique requests and associated revisions was formatted into a LLM prompt and parsed out of string responses. This is more naturally achieved via [structured output](/docs/how_to/structured_output/) features of chat models. We can construct a simple chain in [LangGraph](https://langchain-ai.github.io/langgraph/) for this purpose. Some advantages of this approach include:\n",
+    "\n",
+    "- Leverage tool-calling capabilities of chat models that have been fine-tuned for this purpose;\n",
+    "- Reduce parsing errors from extracting expression from a string LLM response;\n",
+    "- Delegation of instructions to [message roles](/docs/concepts/#messages) (e.g., chat models can understand what a `ToolMessage` represents without the need for additional prompting);\n",
+    "- Support for streaming, both of individual tokens and chain steps."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "b99b47ec",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install --upgrade --quiet langchain-openai"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "717c8673",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import os\n",
+    "from getpass import getpass\n",
+    "\n",
+    "os.environ[\"OPENAI_API_KEY\"] = getpass()"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "e3621b62-a037-42b8-8faa-59575608bb8b",
+   "metadata": {},
+   "source": [
+    "## Legacy\n",
+    "\n",
+    "<details open>"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "id": "f91c9809-8ee7-4e38-881d-0ace4f6ea883",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "from langchain.chains import ConstitutionalChain, LLMChain\n",
+    "from langchain.chains.constitutional_ai.models import ConstitutionalPrinciple\n",
+    "from langchain_core.prompts import PromptTemplate\n",
+    "from langchain_openai import OpenAI\n",
+    "\n",
+    "llm = OpenAI()\n",
+    "\n",
+    "qa_prompt = PromptTemplate(\n",
+    "    template=\"Q: {question} A:\",\n",
+    "    input_variables=[\"question\"],\n",
+    ")\n",
+    "qa_chain = LLMChain(llm=llm, prompt=qa_prompt)\n",
+    "\n",
+    "constitutional_chain = ConstitutionalChain.from_llm(\n",
+    "    llm=llm,\n",
+    "    chain=qa_chain,\n",
+    "    constitutional_principles=[\n",
+    "        ConstitutionalPrinciple(\n",
+    "            critique_request=\"Tell if this answer is good.\",\n",
+    "            revision_request=\"Give a better answer.\",\n",
+    "        )\n",
+    "    ],\n",
+    "    return_intermediate_steps=True,\n",
+    ")\n",
+    "\n",
+    "result = constitutional_chain.invoke(\"What is the meaning of life?\")"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "id": "fa3d11a1-ac1f-4a9a-9ab3-b7b244daa506",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'question': 'What is the meaning of life?',\n",
+       " 'output': 'The meaning of life is a deeply personal and ever-evolving concept. It is a journey of self-discovery and growth, and can be different for each individual. Some may find meaning in relationships, others in achieving their goals, and some may never find a concrete answer. Ultimately, the meaning of life is what we make of it.',\n",
+       " 'initial_output': ' The meaning of life is a subjective concept that can vary from person to person. Some may believe that the purpose of life is to find happiness and fulfillment, while others may see it as a journey of self-discovery and personal growth. Ultimately, the meaning of life is something that each individual must determine for themselves.',\n",
+       " 'critiques_and_revisions': [('This answer is good in that it recognizes and acknowledges the subjective nature of the question and provides a valid and thoughtful response. However, it could have also mentioned that the meaning of life is a complex and deeply personal concept that can also change and evolve over time for each individual. Critique Needed.',\n",
+       "   'The meaning of life is a deeply personal and ever-evolving concept. It is a journey of self-discovery and growth, and can be different for each individual. Some may find meaning in relationships, others in achieving their goals, and some may never find a concrete answer. Ultimately, the meaning of life is what we make of it.')]}"
+      ]

----------------------------------------

File: docs/docs/versions/migrating_chains/conversation_retrieval_chain.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -58,11 +58,11 @@
    "outputs": [],
    "source": [
     "# Load docs\n",
-    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
     "from langchain_community.document_loaders import WebBaseLoader\n",
     "from langchain_community.vectorstores import FAISS\n",
     "from langchain_openai.chat_models import ChatOpenAI\n",
     "from langchain_openai.embeddings import OpenAIEmbeddings\n",
+    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",

----------------------------------------

File: docs/docs/versions/migrating_chains/index.mdx
Status: modified
Changes: +2 -0
Diff:
@@ -45,5 +45,7 @@ The below pages assist with migration from various specific chains to LCEL and L
 - [RefineDocumentsChain](/docs/versions/migrating_chains/refine_docs_chain)
 - [LLMRouterChain](/docs/versions/migrating_chains/llm_router_chain)
 - [MultiPromptChain](/docs/versions/migrating_chains/multi_prompt_chain)
+- [LLMMathChain](/docs/versions/migrating_chains/llm_math_chain)
+- [ConstitutionalChain](/docs/versions/migrating_chains/constitutional_chain)
 
 Check out the [LCEL conceptual docs](/docs/concepts/#langchain-expression-language-lcel) and [LangGraph docs](https://langchain-ai.github.io/langgraph/) for more background information.
\ No newline at end of file

----------------------------------------

File: docs/docs/versions/migrating_chains/llm_math_chain.ipynb
Status: added
Changes: +281 -0
Diff:
@@ -0,0 +1,281 @@
+{
+ "cells": [
+  {
+   "cell_type": "markdown",
+   "id": "b57124cc-60a0-4c18-b7ce-3e483d1024a2",
+   "metadata": {},
+   "source": [
+    "---\n",
+    "title: Migrating from LLMMathChain\n",
+    "---"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "ce8457ed-c0b1-4a74-abbd-9d3d2211270f",
+   "metadata": {},
+   "source": [
+    "[`LLMMathChain`](https://api.python.langchain.com/en/latest/chains/langchain.chains.llm_math.base.LLMMathChain.html) enabled the evaluation of mathematical expressions generated by a LLM. Instructions for generating the expressions were formatted into the prompt, and the expressions were parsed out of the string response before evaluation using the [numexpr](https://numexpr.readthedocs.io/en/latest/user_guide.html) library.\n",
+    "\n",
+    "This is more naturally achieved via [tool calling](/docs/concepts/#functiontool-calling). We can equip a chat model with a simple calculator tool leveraging `numexpr` and construct a simple chain around it using [LangGraph](https://langchain-ai.github.io/langgraph/). Some advantages of this approach include:\n",
+    "\n",
+    "- Leverage tool-calling capabilities of chat models that have been fine-tuned for this purpose;\n",
+    "- Reduce parsing errors from extracting expression from a string LLM response;\n",
+    "- Delegation of instructions to [message roles](/docs/concepts/#messages) (e.g., chat models can understand what a `ToolMessage` represents without the need for additional prompting);\n",
+    "- Support for streaming, both of individual tokens and chain steps."
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "id": "b99b47ec",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "%pip install --upgrade --quiet numexpr"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "id": "717c8673",
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "import os\n",
+    "from getpass import getpass\n",
+    "\n",
+    "os.environ[\"OPENAI_API_KEY\"] = getpass()"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "e3621b62-a037-42b8-8faa-59575608bb8b",
+   "metadata": {},
+   "source": [
+    "## Legacy\n",
+    "\n",
+    "<details open>"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 1,
+   "id": "f91c9809-8ee7-4e38-881d-0ace4f6ea883",
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "{'question': 'What is 551368 divided by 82?', 'answer': 'Answer: 6724.0'}"
+      ]
+     },
+     "execution_count": 1,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "from langchain.chains import LLMMathChain\n",
+    "from langchain_core.prompts import ChatPromptTemplate\n",
+    "from langchain_openai import ChatOpenAI\n",
+    "\n",
+    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
+    "\n",
+    "chain = LLMMathChain.from_llm(llm)\n",
+    "\n",
+    "chain.invoke(\"What is 551368 divided by 82?\")"
+   ]
+  },
+  {
+   "cell_type": "markdown",
+   "id": "cdc3b527-c09e-4c77-9711-c3cc4506cd95",
+   "metadata": {},

----------------------------------------

File: docs/docs/versions/migrating_chains/retrieval_qa.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -57,11 +57,11 @@
    "outputs": [],
    "source": [
     "# Load docs\n",
-    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
     "from langchain_community.document_loaders import WebBaseLoader\n",
     "from langchain_community.vectorstores import FAISS\n",
     "from langchain_openai.chat_models import ChatOpenAI\n",
     "from langchain_openai.embeddings import OpenAIEmbeddings\n",
+    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",

----------------------------------------

File: docs/docusaurus.config.js
Status: modified
Changes: +12 -2
Diff:
@@ -165,9 +165,19 @@ const config = {
             label: "Integrations",
           },
           {
-            href: "https://api.python.langchain.com",
-            label: "API Reference",
+            type: "dropdown",
+            label: "API reference",
             position: "left",
+            items: [

----------------------------------------

File: docs/scripts/arxiv_references.py
Status: modified
Changes: +6 -5
Diff:
@@ -522,8 +522,11 @@ def generate_arxiv_references_page(file_name: Path, papers: list[ArxivPaper]) ->
 This page contains `arXiv` papers referenced in the LangChain Documentation, API Reference,
  Templates, and Cookbooks.
 
-From the opposite direction, scientists use LangChain in research and reference LangChain in the research papers. 
-Here you find [such papers](https://arxiv.org/search/?query=langchain&searchtype=all&source=header).
+From the opposite direction, scientists use `LangChain` in research and reference it in the research papers. 
+Here you find papers that reference:
+- [LangChain](https://arxiv.org/search/?query=langchain&searchtype=all&source=header)
+- [LangGraph](https://arxiv.org/search/?query=langgraph&searchtype=all&source=header)

----------------------------------------

File: docs/scripts/model_feat_table.py
Status: removed
Changes: +0 -312
Diff:
@@ -1,312 +0,0 @@
-import sys
-from pathlib import Path
-
-from langchain_community import llms
-from langchain_core.language_models.llms import LLM, BaseLLM
-
-LLM_IGNORE = ("FakeListLLM", "OpenAIChat", "PromptLayerOpenAIChat")
-LLM_FEAT_TABLE_CORRECTION = {
-    "TextGen": {"_astream": False, "_agenerate": False},
-    "Ollama": {
-        "_stream": False,
-    },
-    "PromptLayerOpenAI": {"batch_generate": False, "batch_agenerate": False},
-}
-CHAT_MODEL_IGNORE = ("FakeListChatModel", "HumanInputChatModel")
-
-CHAT_MODEL_FEAT_TABLE = {
-    "ChatAnthropic": {
-        "tool_calling": True,
-        "multimodal": True,
-        "package": "langchain-anthropic",
-        "link": "/docs/integrations/chat/anthropic/",
-    },
-    "ChatMistralAI": {
-        "tool_calling": True,
-        "json_model": True,
-        "package": "langchain-mistralai",
-        "link": "/docs/integrations/chat/mistralai/",
-    },
-    "ChatFireworks": {
-        "tool_calling": True,
-        "json_mode": True,
-        "package": "langchain-fireworks",
-        "link": "/docs/integrations/chat/fireworks/",
-    },
-    "AzureChatOpenAI": {
-        "tool_calling": True,
-        "json_mode": True,
-        "multimodal": True,
-        "package": "langchain-openai",
-        "link": "/docs/integrations/chat/azure_chat_openai/",
-    },
-    "ChatOpenAI": {
-        "tool_calling": True,
-        "json_mode": True,
-        "multimodal": True,
-        "package": "langchain-openai",
-        "link": "/docs/integrations/chat/openai/",
-    },
-    "ChatTogether": {
-        "tool_calling": True,
-        "json_mode": True,
-        "package": "langchain-together",
-        "link": "/docs/integrations/chat/together/",
-    },
-    "ChatVertexAI": {
-        "tool_calling": True,
-        "multimodal": True,
-        "package": "langchain-google-vertexai",
-        "link": "/docs/integrations/chat/google_vertex_ai_palm/",
-    },
-    "ChatGoogleGenerativeAI": {
-        "tool_calling": True,
-        "multimodal": True,
-        "package": "langchain-google-genai",
-        "link": "/docs/integrations/chat/google_generative_ai/",
-    },
-    "ChatGroq": {
-        "tool_calling": True,
-        "json_mode": True,
-        "package": "langchain-groq",
-        "link": "/docs/integrations/chat/groq/",
-    },
-    "ChatCohere": {
-        "tool_calling": True,
-        "package": "langchain-cohere",
-        "link": "/docs/integrations/chat/cohere/",
-    },
-    "ChatBedrock": {
-        "tool_calling": True,
-        "package": "langchain-aws",
-        "link": "/docs/integrations/chat/bedrock/",
-    },
-    "ChatHuggingFace": {
-        "tool_calling": True,
-        "local": True,
-        "package": "langchain-huggingface",
-        "link": "/docs/integrations/chat/huggingface/",
-    },
-    "ChatNVIDIA": {
-        "tool_calling": True,
-        "json_mode": False,
-        "local": True,
-        "multimodal": False,
-        "package": "langchain-nvidia-ai-endpoints",
-        "link": "/docs/integrations/chat/nvidia_ai_endpoints/",
-    },
-    "ChatOllama": {
-        "tool_calling": True,
-        "local": True,
-        "json_mode": True,
-        "package": "langchain-ollama",
-        "link": "/docs/integrations/chat/ollama/",

----------------------------------------

File: docs/scripts/tool_feat_table.py
Status: modified
Changes: +10 -0
Diff:
@@ -173,6 +173,10 @@
 
 # Tools
 
+[Tools](/docs/concepts/#tools) are utilities designed to be called by a model: their inputs are designed to be generated by models, and their outputs are designed to be passed back to models.
+
+A [toolkit](/docs/concepts#toolkits) is a collection of tools meant to be used together.
+
 :::info
 

----------------------------------------

File: docs/sidebars.js
Status: modified
Changes: +107 -85
Diff:
@@ -146,11 +146,12 @@ module.exports = {
         {
           type: "category",
           label: "Chat models",
-          collapsed: true,
+          collapsible: false,
           items: [
             {
               type: "autogenerated",
               dirName: "integrations/chat",
+              className: "hidden",
             },
           ],
           link: {
@@ -161,11 +162,12 @@ module.exports = {
         {
           type: "category",
           label: "LLMs",
-          collapsed: true,
+          collapsible: false,
           items: [
             {
               type: "autogenerated",
               dirName: "integrations/llms",
+              className: "hidden",
             },
           ],
           link: {
@@ -176,11 +178,12 @@ module.exports = {
         {
           type: "category",
           label: "Embedding models",
-          collapsed: true,
+          collapsible: false,
           items: [
             {
               type: "autogenerated",
               dirName: "integrations/text_embedding",
+              className: "hidden",
             },
           ],
           link: {
@@ -191,56 +194,44 @@ module.exports = {
         {
           type: "category",
           label: "Document loaders",
-          collapsed: true,
+          collapsible: false,
           items: [
             {
               type: "autogenerated",
               dirName: "integrations/document_loaders",
+              className: "hidden",
             },
           ],
           link: {
             type: "doc",
             id: "integrations/document_loaders/index",
           },
         },
-        {
-          type: "category",
-          label: "Document transformers",
-          collapsed: true,
-          items: [
-            {
-              type: "autogenerated",
-              dirName: "integrations/document_transformers",
-            },
-          ],
-          link: {
-            type: "generated-index",
-            slug: "integrations/document_transformers",
-          },
-        },
         {
           type: "category",
           label: "Vector stores",
-          collapsed: true,
+          collapsible: false,
           items: [
             {
               type: "autogenerated",
               dirName: "integrations/vectorstores",
+              className: "hidden",
             },
           ],
           link: {
-            type: "generated-index",
-            slug: "integrations/vectorstores",
+            type: "doc",
+            id: "integrations/vectorstores/index",
           },
         },
         {
           type: "category",
           label: "Retrievers",
-          collapsed: true,
+          collapsible: false,
           items: [
             {
               type: "autogenerated",

----------------------------------------

File: docs/src/theme/FeatureTables.js
Status: added
Changes: +886 -0
Diff:
@@ -0,0 +1,886 @@
+import React from "react";
+import {useCurrentSidebarCategory} from '@docusaurus/theme-common';
+import {
+  useDocById,
+} from '@docusaurus/theme-common/internal';
+
+const FEATURE_TABLES = {
+    chat: {
+        link: "/docs/integrations/chat",
+        columns: [
+            {title: "Provider", formatter: (item) => <a href={item.link}>{item.name}</a>},
+            {title: <a href="/docs/how_to/tool_calling">Tool calling</a>, formatter: (item) => item.tool_calling ? "✅" : "❌"},
+            {title: <a href="/docs/how_to/structured_output/">Structured output</a>, formatter: (item) => item.structured_output ? "✅" : "❌"},
+            {title: "JSON mode", formatter: (item) => item.json_mode ? "✅" : "❌"},
+            {title: "Local", formatter: (item) => item.local ? "✅" : "❌"},
+            {title: <a href="/docs/how_to/multimodal_inputs/">Multimodal</a>, formatter: (item) => item.multimodal ? "✅" : "❌"},
+            {title: "Package", formatter: (item) => <a href={item.apiLink}>{item.package}</a>},
+        ],
+        items: [
+            {
+                "name": "ChatAnthropic",
+                "package": "langchain-anthropic",
+                "link": "anthropic/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": true,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_anthropic.chat_models.ChatAnthropic.html#langchain_anthropic.chat_models.ChatAnthropic"
+            },
+            {
+                "name": "ChatMistralAI",
+                "package": "langchain-mistralai",
+                "link": "mistralai/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_mistralai.chat_models.ChatMistralAI.html#langchain_mistralai.chat_models.ChatMistralAI"
+            },
+            {
+                "name": "ChatFireworks",
+                "package": "langchain-fireworks",
+                "link": "fireworks/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": true,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_fireworks.chat_models.ChatFireworks.html#langchain_fireworks.chat_models.ChatFireworks"
+            },
+            {
+                "name": "AzureChatOpenAI",
+                "package": "langchain-openai",
+                "link": "azure_chat_openai/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": true,
+                "multimodal": true,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.azure.AzureChatOpenAI.html#langchain_openai.chat_models.azure.AzureChatOpenAI"
+            },
+            {
+                "name": "ChatOpenAI",
+                "package": "langchain-openai",
+                "link": "openai/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": true,
+                "multimodal": true,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html#langchain_openai.chat_models.base.ChatOpenAI"
+            },
+            {
+                "name": "ChatTogether",
+                "package": "langchain-together",
+                "link": "together/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": true,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_together.chat_models.ChatTogether.html#langchain_together.chat_models.ChatTogether"
+            },
+            {
+                "name": "ChatVertexAI",
+                "package": "langchain-google-vertexai",
+                "link": "google_vertex_ai_palm/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": true,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_google_vertexai.chat_models.ChatVertexAI.html#langchain_google_vertexai.chat_models.ChatVertexAI"
+            },
+            {
+                "name": "ChatGoogleGenerativeAI",
+                "package": "langchain-google-genai",
+                "link": "google_generative_ai/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": true,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_google_genai.chat_models.ChatGoogleGenerativeAI.html#langchain_google_genai.chat_models.ChatGoogleGenerativeAI"
+            },
+            {
+                "name": "ChatGroq",
+                "package": "langchain-groq",
+                "link": "groq/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": true,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_groq.chat_models.ChatGroq.html#langchain_groq.chat_models.ChatGroq"
+            },
+            {
+                "name": "ChatCohere",
+                "package": "langchain-cohere",
+                "link": "cohere/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_cohere.chat_models.ChatCohere.html#langchain_cohere.chat_models.ChatCohere"
+            },
+            {
+                "name": "ChatBedrock",
+                "package": "langchain-aws",
+                "link": "bedrock/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_aws.chat_models.bedrock.ChatBedrock.html#langchain_aws.chat_models.bedrock.ChatBedrock"
+            },
+            {
+                "name": "ChatHuggingFace",
+                "package": "langchain-huggingface",
+                "link": "huggingface/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": true,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_huggingface.chat_models.huggingface.ChatHuggingFace.html#langchain_huggingface.chat_models.huggingface.ChatHuggingFace",
+            },
+            {
+                "name": "ChatNVIDIA",
+                "package": "langchain-nvidia-ai-endpoints",
+                "link": "nvidia_ai_endpoints/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": true,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA.html#langchain_nvidia_ai_endpoints.chat_models.ChatNVIDIA"
+            },
+            {
+                "name": "ChatOllama",
+                "package": "langchain-ollama",
+                "link": "ollama/",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": true,
+                "multimodal": false,
+                "local": true,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_ollama.chat_models.ChatOllama.html#langchain_ollama.chat_models.ChatOllama"
+            },
+            {
+                "name": "ChatLlamaCpp",
+                "package": "langchain-community",
+                "link": "llamacpp",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": true,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_community.chat_models.llamacpp.ChatLlamaCpp.html#langchain_community.chat_models.llamacpp.ChatLlamaCpp"
+            },
+            {
+                "name": "ChatAI21",
+                "package": "langchain-ai21",
+                "link": "ai21",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false,
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_ai21.chat_models.ChatAI21.html#langchain_ai21.chat_models.ChatAI21"
+            },
+            {
+                "name": "ChatUpstage",
+                "package": "langchain-upstage",
+                "link": "upstage",
+                "structured_output": true,
+                "tool_calling": true,
+                "json_mode": false, 
+                "multimodal": false,
+                "local": false,
+                "apiLink": "https://api.python.langchain.com/en/latest/chat_models/langchain_upstage.chat_models.ChatUpstage.html#langchain_upstage.chat_models.ChatUpstage"
+            }
+        ],
+    },
+    llms: {
+        link: "/docs/integrations/llms",
+        columns: [
+            {title: "Provider", formatter: (item) => <a href={
+                item.link
+            }>{item.name}</a>},
+            {title: "Package", formatter: (item) => <a href={
+                item.apiLink
+            }>{item.package}</a>},
+        ],
+        items: [
+            {
+                name: "AI21LLM",
+                link: "ai21",
+                package: "langchain-ai21",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_ai21.llms.AI21LLM.html#langchain_ai21.llms.AI21LLM"
+            },
+            {
+                name: "AnthropicLLM",
+                link: "anthropic",
+                package: "langchain-anthropic",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_anthropic.llms.AnthropicLLM.html#langchain_anthropic.llms.AnthropicLLM"
+            },
+            {
+                name: "AzureOpenAI",
+                link: "azure_openai",
+                package: "langchain-openai",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.azure.AzureOpenAI.html#langchain_openai.llms.azure.AzureOpenAI"
+            },
+            {
+                name: "BedrockLLM",
+                link: "bedrock",
+                package: "langchain-aws",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_aws.llms.bedrock.BedrockLLM.html#langchain_aws.llms.bedrock.BedrockLLM"
+            },
+            {
+                name: "CohereLLM",
+                link: "cohere",
+                package: "langchain-cohere",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_cohere.llms.Cohere.html#langchain_cohere.llms.Cohere"
+            },
+            {
+                name: "FireworksLLM",
+                link: "fireworks",
+                package: "langchain-fireworks",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_fireworks.llms.Fireworks.html#langchain_fireworks.llms.Fireworks"
+            },
+            {
+                name: "OllamaLLM",
+                link: "ollama",
+                package: "langchain-ollama",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_ollama.llms.OllamaLLM.html#langchain_ollama.llms.OllamaLLM"
+            },
+            {
+                name: "OpenAILLM",
+                link: "openai",
+                package: "langchain-openai",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_openai.llms.base.OpenAI.html#langchain_openai.llms.base.OpenAI"
+            },
+            {
+                name: "TogetherLLM",
+                link: "together",
+                package: "langchain-together",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_together.llms.Together.html#langchain_together.llms.Together"
+            },
+            {
+                name: "VertexAILLM",
+                link: "google_vertexai",
+                package: "langchain-google_vertexai",
+                apiLink: "https://api.python.langchain.com/en/latest/llms/langchain_google_vertexai.llms.VertexAI.html#langchain_google_vertexai.llms.VertexAI"
+            },
+        ],
+    },
+    text_embedding: {
+        link: "/docs/integrations/text_embedding",
+        columns: [
+            {title: "Provider", formatter: (item) => <a href={item.link}>{item.name}</a>},
+            {title: "Package", formatter: (item) => <a href={item.apiLink}>{item.package}</a>},
+        ],
+        items:[
+            {
+                name: "AzureOpenAI",
+                link: "azureopenai",
+                package: "langchain-openai",
+                apiLink: "https://api.python.langchain.com/en/latest/embeddings/langchain_openai.embeddings.azure.AzureOpenAIEmbeddings.html#langchain_openai.embeddings.azure.AzureOpenAIEmbeddings"
+            },

----------------------------------------

File: docs/src/theme/FeatureTables.tsx
Status: removed
Changes: +0 -76
Diff:
@@ -1,76 +0,0 @@
-import React from "react";
-
-interface Column {
-    title: string | React.ReactNode;
-    formatter: (item: any) => React.ReactNode;
-}
-interface Category {
-    link: string;
-    columns: Column[];
-    items: any[];
-}
-
-const FeatureTables: Record<string, Category> = {
-    llms: {
-        link: "/docs/integrations/llms",
-        columns: [
-            {title: "Provider", formatter: (item) => <a href={item.link}>{item.name}</a>},
-            {title: "Package", formatter: (item) => <a href={`https://pypi.org/project/${item.package}/`}>{item.package}</a>},
-        ],
-        items:[
-            {
-                name: "Anthropic",
-                link: "anthropic.ipynb",
-                package: "langchain-anthropic",

----------------------------------------

File: docs/vercel.json
Status: modified
Changes: +16 -0
Diff:
@@ -78,13 +78,29 @@
       "source": "/v0.2/docs/integrations/toolkits/airbyte_structured_qa/",
       "destination": "/v0.2/docs/integrations/document_loaders/airbyte/"
     },
+    {
+      "source": "/v0.2/docs/integrations/tools/connery_toolkit/",
+      "destination": "/v0.2/docs/integrations/tools/connery/"
+    },
+    {
+      "source": "/v0.2/docs/integrations/tools/polygon_toolkit/",

----------------------------------------

File: docs/vercel_build.sh
Status: modified
Changes: +7 -0
Diff:
@@ -8,3 +8,10 @@ make build
 
 rm -rf docs
 mv build/output-new/docs ./
+
+mkdir static/api_reference
+
+git clone --depth=1 https://github.com/baskaryan/langchain-api-docs-build.git
+
+mv -r langchain-api-docs-build/api_reference_build/html/* static/api_reference/

----------------------------------------

File: libs/cli/langchain_cli/integration_template/docs/llms.ipynb
Status: modified
Changes: +1 -1
Diff:
@@ -34,7 +34,7 @@
     "\n",
     "## Setup\n",
     "\n",
-    "- [ ] TODO: Update with relevant info.\n",
+    "- TODO: Update with relevant info.\n",
     "\n",
     "To access __ModuleName__ models you'll need to create a/an __ModuleName__ account, get an API key, and install the `__package_name__` integration package.\n",
     "\n",

----------------------------------------

File: libs/cli/langchain_cli/integration_template/docs/retrievers.ipynb
Status: modified
Changes: +0 -1
Diff:
@@ -17,7 +17,6 @@
    "source": [
     "# __ModuleName__Retriever\n",
     "\n",
-    "## Overview\n",
     "- TODO: Make sure API reference link is correct.\n",
     "\n",
     "This will help you getting started with the __ModuleName__ [retriever](/docs/concepts/#retrievers). For detailed documentation of all __ModuleName__Retriever features and configurations head to the [API reference](https://api.python.langchain.com/en/latest/retrievers/__module_name__.retrievers.__ModuleName__.__ModuleName__Retriever.html).\n",

----------------------------------------

File: libs/cli/langchain_cli/integration_template/integration_template/tools.py
Status: modified
Changes: +2 -2
Diff:
@@ -57,12 +57,12 @@ class __ModuleName__Tool(BaseTool):
         .. code-block:: python
 
             # TODO: invoke args
-            tool.invoke({"args": {...}, "id": "1", "name": tool.name, "type": "tool_call})
+            tool.invoke({"args": {...}, "id": "1", "name": tool.name, "type": "tool_call"})
 
         .. code-block:: python
 
             # TODO: output of invocation

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/ainetwork/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import TYPE_CHECKING, List, Literal, Optional
 
 from langchain_core.pydantic_v1 import root_validator
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.ainetwork.app import AINAppOps

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/amadeus/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -4,9 +4,9 @@
 
 from langchain_core.language_models import BaseLanguageModel
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.amadeus.closest_airport import AmadeusClosestAirport

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/azure_ai_services.py
Status: modified
Changes: +1 -1
Diff:
@@ -3,8 +3,8 @@
 from typing import List
 
 from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.agent_toolkits.base import BaseToolkit
 from langchain_community.tools.azure_ai_services import (
     AzureAiServicesDocumentIntelligenceTool,
     AzureAiServicesImageAnalysisTool,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/azure_cognitive_services.py
Status: modified
Changes: +2 -1
Diff:
@@ -3,7 +3,8 @@
 import sys
 from typing import List
 
-from langchain_core.tools import BaseTool, BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
 from langchain_community.tools.azure_cognitive_services import (
     AzureCogsFormRecognizerTool,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/base.py
Status: modified
Changes: +1 -1
Diff:
@@ -1,5 +1,5 @@
 """Toolkits for agents."""
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools.base import BaseToolkit
 
 __all__ = ["BaseToolkit"]

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/cassandra_database/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import List
 
 from langchain_core.pydantic_v1 import Field
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.agent_toolkits.base import BaseToolkit
-from langchain_community.tools import BaseTool
 from langchain_community.tools.cassandra_database.tool import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/clickup/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -1,8 +1,8 @@
 from typing import Dict, List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.clickup.prompt import (
     CLICKUP_FOLDER_CREATE_PROMPT,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/cogniswitch/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -1,8 +1,8 @@
 from typing import List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.cogniswitch.tool import (
     CogniswitchKnowledgeRequest,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/connery/toolkit.py
Status: modified
Changes: +2 -1
Diff:
@@ -1,7 +1,8 @@
 from typing import List
 
 from langchain_core.pydantic_v1 import root_validator
-from langchain_core.tools import BaseTool, BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
 from langchain_community.tools.connery import ConneryService
 

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/file_management/toolkit.py
Status: modified
Changes: +1 -2
Diff:
@@ -3,10 +3,9 @@
 from typing import Dict, List, Optional, Type
 
 from langchain_core.pydantic_v1 import root_validator
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool, BaseToolkit
 from langchain_core.utils.pydantic import get_fields
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.file_management.copy import CopyFileTool

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/financial_datasets/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import List
 
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.financial_datasets.balance_sheets import BalanceSheets

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/github/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import Dict, List
 
 from langchain_core.pydantic_v1 import BaseModel, Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.github.prompt import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/gitlab/toolkit.py
Status: modified
Changes: +3 -3
Diff:
@@ -1,10 +1,10 @@
-"""GitHub Toolkit."""
+"""GitLab Toolkit."""
 
 from typing import Dict, List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/gmail/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import TYPE_CHECKING, List
 
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.gmail.create_draft import GmailCreateDraft

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/jira/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -1,8 +1,8 @@
 from typing import Dict, List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.jira.prompt import (
     JIRA_CATCH_ALL_PROMPT,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/json/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -2,9 +2,9 @@
 
 from typing import List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.json.tool import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/load_tools.py
Status: modified
Changes: +1 -2
Diff:
@@ -101,8 +101,7 @@
 from langchain_core.callbacks import BaseCallbackManager
 from langchain_core.callbacks import Callbacks
 from langchain_core.language_models import BaseLanguageModel
-from langchain_core.tools import BaseTool
-from langchain_core.tools import Tool
+from langchain_core.tools import BaseTool, Tool
 
 
 def _get_tools_requests_get() -> BaseTool:

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/multion/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -4,9 +4,9 @@
 
 from typing import List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.multion.close_session import MultionCloseSession

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/nasa/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -1,8 +1,8 @@
 from typing import Dict, List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.nasa.prompt import (
     NASA_CAPTIONS_PROMPT,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/nla/toolkit.py
Status: modified
Changes: +2 -1
Diff:
@@ -4,7 +4,8 @@
 
 from langchain_core.language_models import BaseLanguageModel
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseTool, BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
 from langchain_community.agent_toolkits.nla.tool import NLATool
 from langchain_community.tools.openapi.utils.openapi_utils import OpenAPISpec

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/office365/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import TYPE_CHECKING, List
 
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.office365.create_draft_message import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/openapi/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -5,12 +5,12 @@
 from typing import Any, List
 
 from langchain_core.language_models import BaseLanguageModel
-from langchain_core.tools import BaseToolkit, Tool
+from langchain_core.tools import BaseTool, Tool
+from langchain_core.tools.base import BaseToolkit
 
 from langchain_community.agent_toolkits.json.base import create_json_agent
 from langchain_community.agent_toolkits.json.toolkit import JsonToolkit

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/polygon/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -1,8 +1,8 @@
 from typing import List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.polygon import (
     PolygonAggregates,

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/powerbi/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -14,9 +14,9 @@
     SystemMessagePromptTemplate,
 )
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.powerbi.prompt import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/slack/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import TYPE_CHECKING, List
 
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.slack.get_channel import SlackGetChannel

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/spark_sql/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -4,9 +4,9 @@
 
 from langchain_core.language_models import BaseLanguageModel
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.spark_sql.tool import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/sql/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -4,9 +4,9 @@
 
 from langchain_core.language_models import BaseLanguageModel
 from langchain_core.pydantic_v1 import Field
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.sql_database.tool import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/steam/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -2,9 +2,9 @@
 
 from typing import List
 
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.steam.prompt import (

----------------------------------------

File: libs/community/langchain_community/agent_toolkits/zapier/toolkit.py
Status: modified
Changes: +2 -2
Diff:
@@ -3,9 +3,9 @@
 from typing import List
 
 from langchain_core._api import warn_deprecated
-from langchain_core.tools import BaseToolkit
+from langchain_core.tools import BaseTool
+from langchain_core.tools.base import BaseToolkit
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.zapier.tool import ZapierNLARunAction

----------------------------------------

File: libs/community/langchain_community/cache.py
Status: modified
Changes: +2 -2
Diff:
@@ -1614,7 +1614,7 @@ def get_md5(input_string: str) -> str:
 
 @deprecated(
     since="0.0.28",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_astradb.AstraDBCache",
 )
 class AstraDBCache(BaseCache):
@@ -1819,7 +1819,7 @@ def decorating_function(user_function: Callable) -> Callable:

----------------------------------------

File: libs/community/langchain_community/chains/natbot/__init__.py
Status: added
Changes: +8 -0
Diff:
@@ -0,0 +1,8 @@
+"""Implement a GPT-3 driven browser.
+
+Heavily influenced from https://github.com/nat/natbot
+"""
+
+from langchain_community.chains.natbot.base import NatBotChain
+
+__all__ = ["NatBotChain"]

----------------------------------------

File: libs/community/langchain_community/chains/natbot/base.py
Status: added
Changes: +3 -0
Diff:
@@ -0,0 +1,3 @@
+from langchain.chains import NatBotChain
+
+__all__ = ["NatBotChain"]

----------------------------------------

File: libs/community/langchain_community/chains/natbot/crawler.py
Status: added
Changes: +7 -0
Diff:
@@ -0,0 +1,7 @@
+from langchain.chains.natbot.crawler import (
+    Crawler,
+    ElementInViewPort,
+    black_listed_elements,
+)
+
+__all__ = ["ElementInViewPort", "Crawler", "black_listed_elements"]

----------------------------------------

File: libs/community/langchain_community/chains/natbot/prompt.py
Status: added
Changes: +3 -0
Diff:
@@ -0,0 +1,3 @@
+from langchain.chains.natbot.prompt import PROMPT
+
+__all__ = ["PROMPT"]

----------------------------------------

File: libs/community/langchain_community/chat_loaders/gmail.py
Status: modified
Changes: +1 -1
Diff:
@@ -65,7 +65,7 @@ def _get_message_data(service: Any, message: Any) -> ChatSession:
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GMailLoader",
 )
 class GMailLoader(BaseChatLoader):

----------------------------------------

File: libs/community/langchain_community/chat_message_histories/astradb.py
Status: modified
Changes: +1 -1
Diff:
@@ -27,7 +27,7 @@
 
 @deprecated(
     since="0.0.25",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_astradb.AstraDBChatMessageHistory",
 )
 class AstraDBChatMessageHistory(BaseChatMessageHistory):

----------------------------------------

File: libs/community/langchain_community/chat_message_histories/mongodb.py
Status: modified
Changes: +1 -1
Diff:
@@ -18,7 +18,7 @@
 
 @deprecated(
     since="0.0.25",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_mongodb.MongoDBChatMessageHistory",
 )
 class MongoDBChatMessageHistory(BaseChatMessageHistory):

----------------------------------------

File: libs/community/langchain_community/chat_message_histories/sql.py
Status: modified
Changes: +2 -2
Diff:
@@ -147,7 +147,7 @@ class SQLChatMessageHistory(BaseChatMessageHistory):
     """
 
     @property
-    @deprecated("0.2.2", removal="0.3.0", alternative="session_maker")
+    @deprecated("0.2.2", removal="1.0", alternative="session_maker")
     def Session(self) -> Union[scoped_session, async_sessionmaker]:
         return self.session_maker
 
@@ -185,7 +185,7 @@ def __init__(

----------------------------------------

File: libs/community/langchain_community/chat_models/anthropic.py
Status: modified
Changes: +1 -1
Diff:
@@ -73,7 +73,7 @@ def convert_messages_to_prompt_anthropic(
 
 @deprecated(
     since="0.0.28",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_anthropic.ChatAnthropic",
 )
 class ChatAnthropic(BaseChatModel, _AnthropicCommon):

----------------------------------------

File: libs/community/langchain_community/chat_models/azure_openai.py
Status: modified
Changes: +1 -1
Diff:
@@ -20,7 +20,7 @@
 
 @deprecated(
     since="0.0.10",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_openai.AzureChatOpenAI",
 )
 class AzureChatOpenAI(ChatOpenAI):

----------------------------------------

File: libs/community/langchain_community/chat_models/baichuan.py
Status: modified
Changes: +1 -1
Diff:
@@ -206,7 +206,7 @@ class ChatBaichuan(BaseChatModel):
 
     Key init args — client params:
         api_key: Optional[str]
-            MiniMax API key. If not passed in will be read from env var BAICHUAN_API_KEY.
+            Baichuan API key. If not passed in will be read from env var BAICHUAN_API_KEY.
         base_url: Optional[str]
             Base URL for API requests.
 

----------------------------------------

File: libs/community/langchain_community/chat_models/baidu_qianfan_endpoint.py
Status: modified
Changes: +22 -5
Diff:
@@ -200,7 +200,7 @@ class QianfanChatEndpoint(BaseChatModel):
                 ("system", "你是一名专业的翻译家，可以将用户的中文翻译为英文。"),
                 ("human", "我喜欢编程。"),
             ]
-            qianfan_chat.invoke(message)
+            qianfan_chat.invoke(messages)
 
         .. code-block:: python
 
@@ -219,6 +219,7 @@ class QianfanChatEndpoint(BaseChatModel):
 
         .. code-block:: python
 
+            stream = chat.stream(messages)
             full = next(stream)
             for chunk in stream:
                 full += chunk
@@ -511,22 +512,30 @@ def _generate(
         if self.streaming:
             completion = ""
             chat_generation_info: Dict = {}
+            usage_metadata: Optional[UsageMetadata] = None
             for chunk in self._stream(messages, stop, run_manager, **kwargs):
                 chat_generation_info = (
                     chunk.generation_info
                     if chunk.generation_info is not None
                     else chat_generation_info

----------------------------------------

File: libs/community/langchain_community/chat_models/bedrock.py
Status: modified
Changes: +1 -1
Diff:
@@ -202,7 +202,7 @@ def format_messages(
 
 
 @deprecated(
-    since="0.0.34", removal="0.3", alternative_import="langchain_aws.ChatBedrock"
+    since="0.0.34", removal="1.0", alternative_import="langchain_aws.ChatBedrock"
 )
 class BedrockChat(BaseChatModel, BedrockBase):
     """Chat model that uses the Bedrock API."""

----------------------------------------

File: libs/community/langchain_community/chat_models/cohere.py
Status: modified
Changes: +1 -1
Diff:
@@ -96,7 +96,7 @@ def get_cohere_chat_request(
 
 
 @deprecated(
-    since="0.0.30", removal="0.3.0", alternative_import="langchain_cohere.ChatCohere"
+    since="0.0.30", removal="1.0", alternative_import="langchain_cohere.ChatCohere"
 )
 class ChatCohere(BaseChatModel, BaseCohere):
     """`Cohere` chat large language models.

----------------------------------------

File: libs/community/langchain_community/chat_models/fireworks.py
Status: modified
Changes: +1 -1
Diff:
@@ -81,7 +81,7 @@ def convert_dict_to_message(_dict: Any) -> BaseMessage:
 
 @deprecated(
     since="0.0.26",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_fireworks.ChatFireworks",
 )
 class ChatFireworks(BaseChatModel):

----------------------------------------

File: libs/community/langchain_community/chat_models/huggingface.py
Status: modified
Changes: +1 -1
Diff:
@@ -38,7 +38,7 @@
 
 @deprecated(
     since="0.0.37",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_huggingface.ChatHuggingFace",
 )
 class ChatHuggingFace(BaseChatModel):

----------------------------------------

File: libs/community/langchain_community/chat_models/openai.py
Status: modified
Changes: +1 -1
Diff:
@@ -147,7 +147,7 @@ def _convert_delta_to_message_chunk(
 
 
 @deprecated(
-    since="0.0.10", removal="0.3.0", alternative_import="langchain_openai.ChatOpenAI"
+    since="0.0.10", removal="1.0", alternative_import="langchain_openai.ChatOpenAI"
 )
 class ChatOpenAI(BaseChatModel):
     """`OpenAI` Chat large language models API.

----------------------------------------

File: libs/community/langchain_community/chat_models/solar.py
Status: modified
Changes: +1 -1
Diff:
@@ -11,7 +11,7 @@
 
 
 @deprecated(  # type: ignore[arg-type]
-    since="0.0.34", removal="0.3.0", alternative_import="langchain_upstage.ChatUpstage"
+    since="0.0.34", removal="1.0", alternative_import="langchain_upstage.ChatUpstage"
 )
 class SolarChat(SolarCommon, ChatOpenAI):
     """Wrapper around Solar large language models.

----------------------------------------

File: libs/community/langchain_community/chat_models/sparkllm.py
Status: modified
Changes: +3 -3
Diff:
@@ -126,9 +126,9 @@ class ChatSparkLLM(BaseChatModel):
 
             from langchain_community.chat_models import ChatSparkLLM
 
-            chat = MiniMaxChat(
-                api_key=api_key,
-                api_secret=ak,
+            chat = ChatSparkLLM(
+                api_key="your-api-key",
+                api_secret="your-api-secret",

----------------------------------------

File: libs/community/langchain_community/chat_models/vertexai.py
Status: modified
Changes: +1 -1
Diff:
@@ -206,7 +206,7 @@ def _get_question(messages: List[BaseMessage]) -> HumanMessage:
 
 @deprecated(
     since="0.0.12",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_vertexai.ChatVertexAI",
 )
 class ChatVertexAI(_VertexAICommon, BaseChatModel):

----------------------------------------

File: libs/community/langchain_community/chat_models/zhipuai.py
Status: modified
Changes: +205 -5
Diff:
@@ -7,12 +7,25 @@
 import time
 from collections.abc import AsyncIterator, Iterator
 from contextlib import asynccontextmanager, contextmanager
-from typing import Any, Dict, List, Optional, Tuple, Type, Union
+from operator import itemgetter
+from typing import (
+    Any,
+    Callable,
+    Dict,
+    List,
+    Literal,
+    Optional,
+    Sequence,
+    Tuple,
+    Type,
+    Union,
+)
 
 from langchain_core.callbacks import (
     AsyncCallbackManagerForLLMRun,
     CallbackManagerForLLMRun,
 )
+from langchain_core.language_models import LanguageModelInput
 from langchain_core.language_models.chat_models import (
     BaseChatModel,
     agenerate_from_stream,
@@ -30,16 +43,28 @@
     SystemMessage,
     SystemMessageChunk,
 )
+from langchain_core.output_parsers.base import OutputParserLike
+from langchain_core.output_parsers.openai_tools import (
+    JsonOutputKeyToolsParser,
+    PydanticToolsParser,
+)
 from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult
 from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
+from langchain_core.runnables import Runnable, RunnableMap, RunnablePassthrough
+from langchain_core.tools import BaseTool
 from langchain_core.utils import get_from_dict_or_env
+from langchain_core.utils.function_calling import convert_to_openai_tool
 
 logger = logging.getLogger(__name__)
 
 API_TOKEN_TTL_SECONDS = 3 * 60
 ZHIPUAI_API_BASE = "https://open.bigmodel.cn/api/paas/v4/chat/completions"
 
 
+def _is_pydantic_class(obj: Any) -> bool:
+    return isinstance(obj, type) and issubclass(obj, BaseModel)
+
+
 @contextmanager
 def connect_sse(client: Any, method: str, url: str, **kwargs: Any) -> Iterator:
     """Context manager for connecting to an SSE stream.
@@ -199,17 +224,17 @@ class ChatZhipuAI(BaseChatModel):
 
     Key init args — completion params:
         model: Optional[str]
-            Name of OpenAI model to use.
+            Name of ZhipuAI model to use.
         temperature: float
             Sampling temperature.
         max_tokens: Optional[int]
             Max number of tokens to generate.
 
     Key init args — client params:
         api_key: Optional[str]
-        ZhipuAI API key. If not passed in will be read from env var ZHIPUAI_API_KEY.
+            ZhipuAI API key. If not passed in will be read from env var ZHIPUAI_API_KEY.
         api_base: Optional[str]
-        Base URL for API requests.
+            Base URL for API requests.
 
     See full list of supported init args and their descriptions in the params section.
 
@@ -255,7 +280,7 @@ class ChatZhipuAI(BaseChatModel):
 
         .. code-block:: python
 
-            stream = llm.stream(messages)
+            stream = zhipuai_chat.stream(messages)
             full = next(stream)
             for chunk in stream:
                 full += chunk
@@ -587,3 +612,178 @@ async def _astream(
 

----------------------------------------

File: libs/community/langchain_community/document_loaders/astradb.py
Status: modified
Changes: +1 -1
Diff:
@@ -27,7 +27,7 @@
 
 @deprecated(
     since="0.0.29",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_astradb.AstraDBLoader",
 )
 class AstraDBLoader(BaseLoader):

----------------------------------------

File: libs/community/langchain_community/document_loaders/bigquery.py
Status: modified
Changes: +1 -1
Diff:
@@ -14,7 +14,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.BigQueryLoader",
 )
 class BigQueryLoader(BaseLoader):

----------------------------------------

File: libs/community/langchain_community/document_loaders/docugami.py
Status: modified
Changes: +1 -1
Diff:
@@ -29,7 +29,7 @@
 
 @deprecated(
     since="0.0.24",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="docugami_langchain.DocugamiLoader",
 )
 class DocugamiLoader(BaseLoader, BaseModel):

----------------------------------------

File: libs/community/langchain_community/document_loaders/firecrawl.py
Status: modified
Changes: +56 -4
Diff:
@@ -6,11 +6,63 @@
 
 
 class FireCrawlLoader(BaseLoader):
-    """Load web pages as Documents using FireCrawl.
-
-    Must have Python package `firecrawl` installed and a FireCrawl API key. See
-        https://www.firecrawl.dev/ for more.
     """
+    FireCrawlLoader document loader integration
+
+    Setup:
+        Install ``firecrawl-py``,``langchain_community`` and set environment variable ``FIRECRAWL_API_KEY``.
+
+        .. code-block:: bash
+
+            pip install -U firecrawl-py langchain_community
+            export FIRECRAWL_API_KEY="your-api-key"
+
+    Instantiate:
+        .. code-block:: python
+

----------------------------------------

File: libs/community/langchain_community/document_loaders/gcs_directory.py
Status: modified
Changes: +1 -1
Diff:
@@ -13,7 +13,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GCSDirectoryLoader",
 )
 class GCSDirectoryLoader(BaseLoader):

----------------------------------------

File: libs/community/langchain_community/document_loaders/gcs_file.py
Status: modified
Changes: +1 -1
Diff:
@@ -12,7 +12,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GCSFileLoader",
 )
 class GCSFileLoader(BaseLoader):

----------------------------------------

File: libs/community/langchain_community/document_loaders/google_speech_to_text.py
Status: modified
Changes: +1 -1
Diff:
@@ -15,7 +15,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.SpeechToTextLoader",
 )
 class GoogleSpeechToTextLoader(BaseLoader):

----------------------------------------

File: libs/community/langchain_community/document_loaders/googledrive.py
Status: modified
Changes: +1 -1
Diff:
@@ -21,7 +21,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GoogleDriveLoader",
 )
 class GoogleDriveLoader(BaseLoader, BaseModel):

----------------------------------------

File: libs/community/langchain_community/document_loaders/html_bs.py
Status: modified
Changes: +68 -1
Diff:
@@ -10,7 +10,74 @@
 
 
 class BSHTMLLoader(BaseLoader):
-    """Load `HTML` files and parse them with `beautiful soup`."""
+    """
+    __ModuleName__ document loader integration
+
+    Setup:
+        Install ``langchain-community`` and ``bs4``.
+
+        .. code-block:: bash
+
+            pip install -U langchain-community bs4
+
+    Instantiate:
+        .. code-block:: python
+
+            from langchain_community.document_loaders import BSHTMLLoader
+
+            loader = BSHTMLLoader(
+                file_path="./example_data/fake-content.html",
+            )
+
+    Lazy load:

----------------------------------------

File: libs/community/langchain_community/document_loaders/markdown.py
Status: modified
Changes: +49 -8
Diff:
@@ -13,19 +13,60 @@ class UnstructuredMarkdownLoader(UnstructuredFileLoader):
     You can pass in additional unstructured kwargs after mode to apply
     different unstructured settings.
 
-    Examples
-    --------
-    from langchain_community.document_loaders import UnstructuredMarkdownLoader
+    Setup:
+        Install ``langchain-community``.
 
-    loader = UnstructuredMarkdownLoader(
-        "example.md", mode="elements", strategy="fast",
-    )
-    docs = loader.load()
+        .. code-block:: bash
+
+            pip install -U langchain-community
+
+    Instantiate:
+        .. code-block:: python
+
+            from langchain_community.document_loaders import UnstructuredMarkdownLoader
+

----------------------------------------

File: libs/community/langchain_community/document_loaders/parsers/docai.py
Status: modified
Changes: +1 -1
Diff:
@@ -37,7 +37,7 @@ class DocAIParsingResults:
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.DocAIParser",
 )
 class DocAIParser(BaseBlobParser):

----------------------------------------

File: libs/community/langchain_community/document_loaders/parsers/generic.py
Status: modified
Changes: +8 -8
Diff:
@@ -23,14 +23,14 @@ class MimeTypeBasedParser(BaseBlobParser):
 
         .. code-block:: python
 
-        from langchain_community.document_loaders.parsers.generic import MimeTypeBasedParser
-
-        parser = MimeTypeBasedParser(
-            handlers={
-                "application/pdf": ...,
-            },

----------------------------------------

File: libs/community/langchain_community/document_loaders/pdf.py
Status: modified
Changes: +60 -4
Diff:
@@ -161,10 +161,66 @@ def load(self) -> List[Document]:
 
 
 class PyPDFLoader(BasePDFLoader):
-    """Load PDF using pypdf into list of documents.
-
-    Loader chunks by page and stores page numbers in metadata.
     """
+    PyPDFLoader document loader integration
+
+    Setup:
+        Install ``langchain-community``.
+
+        .. code-block:: bash
+
+            pip install -U langchain-community
+
+    Instantiate:
+        .. code-block:: python
+
+            from langchain_community.document_loaders import PyPDFLoader
+
+            loader = PyPDFLoader(
+                file_path = "./example_data/layout-parser-paper.pdf",
+                password = "my-pasword",
+                extract_images = True,

----------------------------------------

File: libs/community/langchain_community/document_loaders/unstructured.py
Status: modified
Changes: +4 -4
Diff:
@@ -168,7 +168,7 @@ def _check_if_both_mode_and_chunking_strategy_are_by_page(
 
 @deprecated(
     since="0.2.8",
-    removal="0.4.0",
+    removal="1.0",
     alternative_import="langchain_unstructured.UnstructuredLoader",
 )
 class UnstructuredFileLoader(UnstructuredBaseLoader):
@@ -269,7 +269,7 @@ def get_elements_from_api(
 
 @deprecated(

----------------------------------------

File: libs/community/langchain_community/document_loaders/web_base.py
Status: modified
Changes: +69 -1
Diff:
@@ -39,7 +39,75 @@ def _build_metadata(soup: Any, url: str) -> dict:
 
 
 class WebBaseLoader(BaseLoader):
-    """Load HTML pages using `urllib` and parse them with `BeautifulSoup'."""
+    """
+    WebBaseLoader document loader integration
+
+    Setup:
+        Install ``langchain_community``.
+
+        .. code-block:: bash
+
+            pip install -U langchain_community
+
+    Instantiate:
+        .. code-block:: python
+
+            from langchain_community.document_loaders import WebBaseLoader
+
+            loader = WebBaseLoader(
+                web_path = "https://www.espn.com/"
+                # header_template = None,
+                # verify_ssl = True,
+                # proxies = None,

----------------------------------------

File: libs/community/langchain_community/document_transformers/google_translate.py
Status: modified
Changes: +1 -1
Diff:
@@ -8,7 +8,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.DocAIParser",
 )
 class GoogleTranslateTransformer(BaseDocumentTransformer):

----------------------------------------

File: libs/community/langchain_community/embeddings/azure_openai.py
Status: modified
Changes: +1 -1
Diff:
@@ -16,7 +16,7 @@
 
 @deprecated(
     since="0.0.9",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_openai.AzureOpenAIEmbeddings",
 )
 class AzureOpenAIEmbeddings(OpenAIEmbeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/bedrock.py
Status: modified
Changes: +1 -1
Diff:
@@ -12,7 +12,7 @@
 
 @deprecated(
     since="0.2.11",
-    removal="0.4.0",
+    removal="1.0",
     alternative_import="langchain_aws.BedrockEmbeddings",
 )
 class BedrockEmbeddings(BaseModel, Embeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/cohere.py
Status: modified
Changes: +1 -1
Diff:
@@ -10,7 +10,7 @@
 
 @deprecated(
     since="0.0.30",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_cohere.CohereEmbeddings",
 )
 class CohereEmbeddings(BaseModel, Embeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/huggingface.py
Status: modified
Changes: +3 -3
Diff:
@@ -21,7 +21,7 @@
 
 @deprecated(
     since="0.2.2",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_huggingface.HuggingFaceEmbeddings",
 )
 class HuggingFaceEmbeddings(BaseModel, Embeddings):
@@ -171,7 +171,7 @@ def __init__(self, **kwargs: Any):

----------------------------------------

File: libs/community/langchain_community/embeddings/huggingface_hub.py
Status: modified
Changes: +1 -1
Diff:
@@ -12,7 +12,7 @@
 
 @deprecated(
     since="0.2.2",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_huggingface.HuggingFaceEndpointEmbeddings",
 )
 class HuggingFaceHubEmbeddings(BaseModel, Embeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/openai.py
Status: modified
Changes: +1 -1
Diff:
@@ -144,7 +144,7 @@ async def _async_embed_with_retry(**kwargs: Any) -> Any:
 
 @deprecated(
     since="0.0.9",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_openai.OpenAIEmbeddings",
 )
 class OpenAIEmbeddings(BaseModel, Embeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/solar.py
Status: modified
Changes: +1 -1
Diff:
@@ -46,7 +46,7 @@ def _embed_with_retry(*args: Any, **kwargs: Any) -> Any:
 
 
 @deprecated(
-    since="0.0.34", removal="0.3.0", alternative_import="langchain_upstage.ChatUpstage"
+    since="0.0.34", removal="1.0", alternative_import="langchain_upstage.ChatUpstage"
 )
 class SolarEmbeddings(BaseModel, Embeddings):
     """Solar's embedding service.

----------------------------------------

File: libs/community/langchain_community/embeddings/vertexai.py
Status: modified
Changes: +1 -1
Diff:
@@ -22,7 +22,7 @@
 
 @deprecated(
     since="0.0.12",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_vertexai.VertexAIEmbeddings",
 )
 class VertexAIEmbeddings(_VertexAICommon, Embeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/voyageai.py
Status: modified
Changes: +1 -1
Diff:
@@ -61,7 +61,7 @@ def _embed_with_retry(**kwargs: Any) -> Any:
 
 @deprecated(
     since="0.0.29",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_voyageai.VoyageAIEmbeddings",
 )
 class VoyageEmbeddings(BaseModel, Embeddings):

----------------------------------------

File: libs/community/langchain_community/embeddings/zhipuai.py
Status: modified
Changes: +14 -2
Diff:
@@ -1,4 +1,4 @@
-from typing import Any, Dict, List
+from typing import Any, Dict, List, Optional
 
 from langchain_core.embeddings import Embeddings
 from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
@@ -70,6 +70,11 @@ class ZhipuAIEmbeddings(BaseModel, Embeddings):
     """Model name"""
     api_key: str
     """Automatically inferred from env var `ZHIPU_API_KEY` if not provided."""
+    dimensions: Optional[int] = None

----------------------------------------

File: libs/community/langchain_community/graph_vectorstores/cassandra.py
Status: modified
Changes: +2 -0
Diff:
@@ -32,6 +32,7 @@ def __init__(
         session: Optional[Session] = None,
         keyspace: Optional[str] = None,
         setup_mode: SetupMode = SetupMode.SYNC,
+        **kwargs: Any,
     ):
         """
         Create the hybrid graph store.
@@ -74,6 +75,7 @@ async def aembed_query(self, text: str) -> List[float]:
             session=session,

----------------------------------------

File: libs/community/langchain_community/llms/__init__.py
Status: modified
Changes: +2 -2
Diff:
@@ -172,7 +172,7 @@ def _import_databricks() -> Type[BaseLLM]:
 def _import_databricks_chat() -> Any:
     warn_deprecated(
         since="0.0.22",
-        removal="0.3",
+        removal="1.0",
         alternative_import="langchain_community.chat_models.ChatDatabricks",
     )
     from langchain_community.chat_models.databricks import ChatDatabricks
@@ -342,7 +342,7 @@ def _import_mlflow() -> Type[BaseLLM]:

----------------------------------------

File: libs/community/langchain_community/llms/anthropic.py
Status: modified
Changes: +1 -1
Diff:
@@ -151,7 +151,7 @@ def _get_anthropic_stop(self, stop: Optional[List[str]] = None) -> List[str]:
 
 @deprecated(
     since="0.0.28",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_anthropic.AnthropicLLM",
 )
 class Anthropic(LLM, _AnthropicCommon):

----------------------------------------

File: libs/community/langchain_community/llms/bedrock.py
Status: modified
Changes: +1 -1
Diff:
@@ -713,7 +713,7 @@ async def _aprepare_input_and_invoke_stream(
 
 
 @deprecated(
-    since="0.0.34", removal="0.3", alternative_import="langchain_aws.BedrockLLM"
+    since="0.0.34", removal="1.0", alternative_import="langchain_aws.BedrockLLM"
 )
 class Bedrock(LLM, BedrockBase):
     """Bedrock models.

----------------------------------------

File: libs/community/langchain_community/llms/cohere.py
Status: modified
Changes: +2 -4
Diff:
@@ -71,7 +71,7 @@ async def _completion_with_retry(**kwargs: Any) -> Any:
 
 
 @deprecated(
-    since="0.0.30", removal="0.3.0", alternative_import="langchain_cohere.BaseCohere"
+    since="0.0.30", removal="1.0", alternative_import="langchain_cohere.BaseCohere"
 )
 class BaseCohere(Serializable):
     """Base class for Cohere models."""
@@ -121,9 +121,7 @@ def validate_environment(cls, values: Dict) -> Dict:

----------------------------------------

File: libs/community/langchain_community/llms/fireworks.py
Status: modified
Changes: +1 -1
Diff:
@@ -29,7 +29,7 @@ def _stream_response_to_generation_chunk(
 
 @deprecated(
     since="0.0.26",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_fireworks.Fireworks",
 )
 class Fireworks(BaseLLM):

----------------------------------------

File: libs/community/langchain_community/llms/huggingface_endpoint.py
Status: modified
Changes: +1 -1
Diff:
@@ -28,7 +28,7 @@
 
 @deprecated(
     since="0.0.37",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_huggingface.HuggingFaceEndpoint",
 )
 class HuggingFaceEndpoint(LLM):

----------------------------------------

File: libs/community/langchain_community/llms/huggingface_hub.py
Status: modified
Changes: +1 -1
Diff:
@@ -21,7 +21,7 @@
 
 @deprecated(
     "0.0.21",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_huggingface.HuggingFaceEndpoint",
 )
 class HuggingFaceHub(LLM):

----------------------------------------

File: libs/community/langchain_community/llms/huggingface_pipeline.py
Status: modified
Changes: +1 -1
Diff:
@@ -24,7 +24,7 @@
 
 @deprecated(
     since="0.0.37",
-    removal="0.3",
+    removal="1.0",
     alternative_import="langchain_huggingface.HuggingFacePipeline",
 )
 class HuggingFacePipeline(BaseLLM):

----------------------------------------

File: libs/community/langchain_community/llms/huggingface_text_gen_inference.py
Status: modified
Changes: +1 -1
Diff:
@@ -16,7 +16,7 @@
 
 @deprecated(
     "0.0.21",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_huggingface.HuggingFaceEndpoint",
 )
 class HuggingFaceTextGenInference(LLM):

----------------------------------------

File: libs/community/langchain_community/llms/openai.py
Status: modified
Changes: +3 -5
Diff:
@@ -730,9 +730,7 @@ def max_tokens_for_prompt(self, prompt: str) -> int:
         return self.max_context_size - num_tokens
 
 
-@deprecated(
-    since="0.0.10", removal="0.3.0", alternative_import="langchain_openai.OpenAI"
-)
+@deprecated(since="0.0.10", removal="1.0", alternative_import="langchain_openai.OpenAI")
 class OpenAI(BaseOpenAI):
     """OpenAI large language models.

----------------------------------------

File: libs/community/langchain_community/llms/sparkllm.py
Status: modified
Changes: +113 -28
Diff:
@@ -24,64 +24,149 @@
 
 
 class SparkLLM(LLM):
-    """iFlyTek Spark large language model.
+    """iFlyTek Spark completion model integration.
+
+    Setup:
+        To use, you should set environment variables ``IFLYTEK_SPARK_APP_ID``,
+        ``IFLYTEK_SPARK_API_KEY`` and ``IFLYTEK_SPARK_API_SECRET``.
+
+    .. code-block:: bash
+
+            export IFLYTEK_SPARK_APP_ID="your-app-id"
+            export IFLYTEK_SPARK_API_KEY="your-api-key"
+            export IFLYTEK_SPARK_API_SECRET="your-api-secret"
+
+    Key init args — completion params:
+        model: Optional[str]
+            Name of IFLYTEK SPARK model to use.
+        temperature: Optional[float]
+            Sampling temperature.
+        top_k: Optional[float]
+            What search sampling control to use.
+        streaming: Optional[bool]
+             Whether to stream the results or not.
+
+    Key init args — client params:
+        app_id: Optional[str]
+            IFLYTEK SPARK API KEY. Automatically inferred from env var `IFLYTEK_SPARK_APP_ID` if not provided.
+        api_key: Optional[str]
+            IFLYTEK SPARK API KEY. If not passed in will be read from env var IFLYTEK_SPARK_API_KEY.
+        api_secret: Optional[str]
+            IFLYTEK SPARK API SECRET. If not passed in will be read from env var IFLYTEK_SPARK_API_SECRET.
+        api_url: Optional[str]
+            Base URL for API requests.
+        timeout: Optional[int]
+            Timeout for requests.
+
+    See full list of supported init args and their descriptions in the params section.
+
+    Instantiate:
+        .. code-block:: python
+
+            from langchain_community.llms import SparkLLM
 
-    To use, you should pass `app_id`, `api_key`, `api_secret`
-    as a named parameter to the constructor OR set environment
-    variables ``IFLYTEK_SPARK_APP_ID``, ``IFLYTEK_SPARK_API_KEY`` and
-    ``IFLYTEK_SPARK_API_SECRET``
+            llm = SparkLLM(
+                app_id="your-app-id",
+                api_key="your-api_key",
+                api_secret="your-api-secret",
+                # model='Spark4.0 Ultra',
+                # temperature=...,
+                # other params...
+            )
 
-    Example:
+    Invoke:
         .. code-block:: python
 
-        client = SparkLLM(
-            spark_app_id="<app_id>",
-            spark_api_key="<api_key>",

----------------------------------------

File: libs/community/langchain_community/llms/together.py
Status: modified
Changes: +1 -1
Diff:
@@ -19,7 +19,7 @@
 
 
 @deprecated(
-    since="0.0.12", removal="0.3", alternative_import="langchain_together.Together"
+    since="0.0.12", removal="1.0", alternative_import="langchain_together.Together"
 )
 class Together(LLM):
     """LLM models from `Together`.

----------------------------------------

File: libs/community/langchain_community/llms/vertexai.py
Status: modified
Changes: +2 -2
Diff:
@@ -203,7 +203,7 @@ def _prepare_params(
 
 @deprecated(
     since="0.0.12",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_vertexai.VertexAI",
 )
 class VertexAI(_VertexAICommon, BaseLLM):
@@ -393,7 +393,7 @@ def _stream(

----------------------------------------

File: libs/community/langchain_community/llms/watsonxllm.py
Status: modified
Changes: +1 -1
Diff:
@@ -13,7 +13,7 @@
 
 
 @deprecated(
-    since="0.0.18", removal="0.3", alternative_import="langchain_ibm.WatsonxLLM"
+    since="0.0.18", removal="1.0", alternative_import="langchain_ibm.WatsonxLLM"
 )
 class WatsonxLLM(BaseLLM):
     """

----------------------------------------

File: libs/community/langchain_community/retrievers/cohere_rag_retriever.py
Status: modified
Changes: +1 -1
Diff:
@@ -43,7 +43,7 @@ def _get_docs(response: Any) -> List[Document]:
 
 @deprecated(
     since="0.0.30",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_cohere.CohereRagRetriever",
 )
 class CohereRagRetriever(BaseRetriever):

----------------------------------------

File: libs/community/langchain_community/retrievers/google_cloud_documentai_warehouse.py
Status: modified
Changes: +1 -1
Diff:
@@ -23,7 +23,7 @@
 
 @deprecated(
     since="0.0.32",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.DocumentAIWarehouseRetriever",
 )
 class GoogleDocumentAIWarehouseRetriever(BaseRetriever):

----------------------------------------

File: libs/community/langchain_community/retrievers/google_vertex_ai_search.py
Status: modified
Changes: +2 -2
Diff:
@@ -198,7 +198,7 @@ def _convert_website_search_response(
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.VertexAISearchRetriever",
 )
 class GoogleVertexAISearchRetriever(BaseRetriever, _BaseGoogleVertexAISearchRetriever):
@@ -396,7 +396,7 @@ def get_relevant_documents_with_response(

----------------------------------------

File: libs/community/langchain_community/storage/astradb.py
Status: modified
Changes: +2 -2
Diff:
@@ -99,7 +99,7 @@ async def ayield_keys(self, *, prefix: Optional[str] = None) -> AsyncIterator[st
 
 @deprecated(
     since="0.0.22",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_astradb.AstraDBStore",
 )
 class AstraDBStore(AstraDBBaseStore[Any]):
@@ -167,7 +167,7 @@ def encode_value(self, value: Any) -> Any:

----------------------------------------

File: libs/community/langchain_community/tools/__init__.py
Status: modified
Changes: +12 -8
Diff:
@@ -22,11 +22,15 @@
 
 if TYPE_CHECKING:
     from langchain_core.tools import (
-        BaseTool,
-        StructuredTool,
-        Tool,
-        tool,
+        BaseTool as BaseTool,
     )
+    from langchain_core.tools import (
+        StructuredTool as StructuredTool,
+    )
+    from langchain_core.tools import (
+        Tool as Tool,
+    )
+    from langchain_core.tools.convert import tool as tool
 
     from langchain_community.tools.ainetwork.app import (

----------------------------------------

File: libs/community/langchain_community/tools/bearly/tool.py
Status: modified
Changes: +1 -2
Diff:
@@ -7,8 +7,7 @@
 
 import requests
 from langchain_core.pydantic_v1 import BaseModel, Field
-
-from langchain_community.tools import Tool
+from langchain_core.tools import Tool
 
 
 def strip_markdown_code(md_string: str) -> str:

----------------------------------------

File: libs/community/langchain_community/tools/bing_search/tool.py
Status: modified
Changes: +39 -1
Diff:
@@ -29,7 +29,45 @@ def _run(
 
 
 class BingSearchResults(BaseTool):
-    """Tool that queries the Bing Search API and gets back json."""
+    """Bing Search tool.
+
+    Setup:
+        Install ``langchain-community`` and set environment variable ``BING_SUBSCRIPTION_KEY``.
+
+        .. code-block:: bash
+
+            pip install -U langchain-community
+            export BING_SUBSCRIPTION_KEY="your-api-key"
+

----------------------------------------

File: libs/community/langchain_community/tools/databricks/tool.py
Status: modified
Changes: +2 -1
Diff:
@@ -5,7 +5,8 @@
 from typing import TYPE_CHECKING, Any, Dict, List, Optional, Type, Union
 
 from langchain_core.pydantic_v1 import BaseModel, Field, create_model
-from langchain_core.tools import BaseTool, BaseToolkit, StructuredTool
+from langchain_core.tools import BaseTool, StructuredTool
+from langchain_core.tools.base import BaseToolkit
 from typing_extensions import Self
 
 if TYPE_CHECKING:

----------------------------------------

File: libs/community/langchain_community/tools/ddg_search/tool.py
Status: modified
Changes: +35 -1
Diff:
@@ -17,7 +17,41 @@ class DDGInput(BaseModel):
 
 
 class DuckDuckGoSearchRun(BaseTool):
-    """Tool that queries the DuckDuckGo search API."""
+    """DuckDuckGo tool.
+
+    Setup:
+        Install ``duckduckgo-search`` and ``langchain-community``.
+
+        .. code-block:: bash
+
+            pip install -U duckduckgo-search langchain-community
+

----------------------------------------

File: libs/community/langchain_community/tools/e2b_data_analysis/tool.py
Status: modified
Changes: +1 -1
Diff:
@@ -13,8 +13,8 @@
     CallbackManagerForToolRun,
 )
 from langchain_core.pydantic_v1 import BaseModel, Field, PrivateAttr
+from langchain_core.tools import BaseTool, Tool
 
-from langchain_community.tools import BaseTool, Tool
 from langchain_community.tools.e2b_data_analysis.unparse import Unparser
 
 if TYPE_CHECKING:

----------------------------------------

File: libs/community/langchain_community/tools/google_cloud/texttospeech.py
Status: modified
Changes: +1 -1
Diff:
@@ -39,7 +39,7 @@ def _encoding_file_extension_map(encoding: texttospeech.AudioEncoding) -> Option
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.TextToSpeechTool",
 )
 class GoogleCloudTextToSpeechTool(BaseTool):

----------------------------------------

File: libs/community/langchain_community/tools/google_places/tool.py
Status: modified
Changes: +1 -1
Diff:
@@ -18,7 +18,7 @@ class GooglePlacesSchema(BaseModel):
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GooglePlacesTool",
 )
 class GooglePlacesTool(BaseTool):

----------------------------------------

File: libs/community/langchain_community/tools/google_search/tool.py
Status: modified
Changes: +2 -2
Diff:
@@ -11,7 +11,7 @@
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GoogleSearchRun",
 )
 class GoogleSearchRun(BaseTool):
@@ -36,7 +36,7 @@ def _run(

----------------------------------------

File: libs/community/langchain_community/tools/metaphor_search/tool.py
Status: modified
Changes: +1 -1
Diff:
@@ -14,7 +14,7 @@
 
 @deprecated(
     since="0.0.15",
-    removal="0.3.0",
+    removal="1.0",
     alternative="langchain_exa.ExaSearchResults",
 )
 class MetaphorSearchResults(BaseTool):

----------------------------------------

File: libs/community/langchain_community/tools/riza/command.py
Status: modified
Changes: +37 -1
Diff:
@@ -19,7 +19,43 @@ class ExecPythonInput(BaseModel):
 
 
 class ExecPython(BaseTool):
-    """A tool implementation to execute Python via Riza's Code Interpreter API."""
+    """Riza Code tool.
+
+    Setup:
+        Install ``langchain-community`` and ``rizaio`` and set environment variable ``RIZA_API_KEY``.
+
+        .. code-block:: bash
+
+            pip install -U langchain-community rizaio
+            export RIZA_API_KEY="your-api-key"
+

----------------------------------------

File: libs/community/langchain_community/tools/searx_search/tool.py
Status: modified
Changes: +1 -0
Diff:
@@ -60,6 +60,7 @@ class SearxSearchResults(BaseTool):
     wrapper: SearxSearchWrapper
     num_results: int = 4
     kwargs: dict = Field(default_factory=dict)
+    args_schema: Type[BaseModel] = SearxSearchQueryInput
 
     class Config:
         extra = "allow"

----------------------------------------

File: libs/community/langchain_community/tools/steamship_image_generation/tool.py
Status: modified
Changes: +1 -1
Diff:
@@ -19,9 +19,9 @@
 
 from langchain_core.callbacks import CallbackManagerForToolRun
 from langchain_core.pydantic_v1 import root_validator
+from langchain_core.tools import BaseTool
 from langchain_core.utils import get_from_dict_or_env
 
-from langchain_community.tools import BaseTool
 from langchain_community.tools.steamship_image_generation.utils import make_image_public
 

----------------------------------------

File: libs/community/langchain_community/tools/youtube/search.py
Status: modified
Changes: +1 -2
Diff:
@@ -13,8 +13,7 @@
 from typing import Optional
 
 from langchain_core.callbacks import CallbackManagerForToolRun
-
-from langchain_community.tools import BaseTool
+from langchain_core.tools import BaseTool
 
 
 class YouTubeSearchTool(BaseTool):

----------------------------------------

File: libs/community/langchain_community/utilities/google_places_api.py
Status: modified
Changes: +1 -1
Diff:
@@ -10,7 +10,7 @@
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GooglePlacesAPIWrapper",
 )
 class GooglePlacesAPIWrapper(BaseModel):

----------------------------------------

File: libs/community/langchain_community/utilities/google_search.py
Status: modified
Changes: +1 -1
Diff:
@@ -9,7 +9,7 @@
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.GoogleSearchAPIWrapper",
 )
 class GoogleSearchAPIWrapper(BaseModel):

----------------------------------------

File: libs/community/langchain_community/utilities/sql_database.py
Status: modified
Changes: +1 -1
Diff:
@@ -287,7 +287,7 @@ def get_usable_table_names(self) -> Iterable[str]:
             return sorted(self._include_tables)
         return sorted(self._all_tables - self._ignore_tables)
 
-    @deprecated("0.0.1", alternative="get_usable_table_names", removal="0.3.0")
+    @deprecated("0.0.1", alternative="get_usable_table_names", removal="1.0")
     def get_table_names(self) -> Iterable[str]:
         """Get names of tables available."""
         return self.get_usable_table_names()

----------------------------------------

File: libs/community/langchain_community/vectorstores/astradb.py
Status: modified
Changes: +1 -1
Diff:
@@ -67,7 +67,7 @@ def _unique_list(lst: List[T], key: Callable[[T], U]) -> List[T]:
 
 @deprecated(
     since="0.0.21",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_astradb.AstraDBVectorStore",
 )
 class AstraDB(VectorStore):

----------------------------------------

File: libs/community/langchain_community/vectorstores/azuresearch.py
Status: modified
Changes: +131 -94
Diff:
@@ -1,5 +1,6 @@
 from __future__ import annotations
 
+import asyncio
 import base64
 import itertools
 import json
@@ -41,7 +42,12 @@
 
 if TYPE_CHECKING:
     from azure.search.documents import SearchClient, SearchItemPaged
-    from azure.search.documents.aio import SearchClient as AsyncSearchClient
+    from azure.search.documents.aio import (
+        AsyncSearchItemPaged,
+    )
+    from azure.search.documents.aio import (
+        SearchClient as AsyncSearchClient,
+    )
     from azure.search.documents.indexes.models import (
         CorsOptions,
         ScoringProfile,
@@ -360,6 +366,31 @@ def __init__(
         self._user_agent = user_agent
         self._cors_options = cors_options
 
+    def __del__(self) -> None:
+        # Close the sync client
+        if hasattr(self, "client") and self.client:
+            self.client.close()
+
+        # Close the async client
+        if hasattr(self, "async_client") and self.async_client:
+            # Check if we're in an existing event loop
+            try:
+                loop = asyncio.get_event_loop()
+                if loop.is_running():
+                    # Schedule the coroutine to close the async client
+                    loop.create_task(self.async_client.close())
+                else:
+                    # If no event loop is running, run the coroutine directly
+                    loop.run_until_complete(self.async_client.close())
+            except RuntimeError:
+                # Handle the case where there's no event loop
+                loop = asyncio.new_event_loop()
+                asyncio.set_event_loop(loop)
+                try:
+                    loop.run_until_complete(self.async_client.close())
+                finally:
+                    loop.close()
+
     @property
     def embeddings(self) -> Optional[Embeddings]:
         # TODO: Support embedding object directly
@@ -518,21 +549,19 @@ async def aadd_embeddings(
             ids.append(key)
             # Upload data in batches
             if len(data) == MAX_UPLOAD_BATCH_SIZE:
-                async with self.async_client as async_client:
-                    response = await async_client.upload_documents(documents=data)
-                    # Check if all documents were successfully uploaded
-                    if not all(r.succeeded for r in response):
-                        raise LangChainException(response)
-                    # Reset data
-                    data = []
+                response = await self.async_client.upload_documents(documents=data)
+                # Check if all documents were successfully uploaded
+                if not all(r.succeeded for r in response):
+                    raise LangChainException(response)
+                # Reset data
+                data = []
 
         # Considering case where data is an exact multiple of batch-size entries
         if len(data) == 0:
             return ids
 
         # Upload data to index
-        async with self.async_client as async_client:
-            response = await async_client.upload_documents(documents=data)
+        response = await self.async_client.upload_documents(documents=data)
         # Check if all documents were successfully uploaded
         if all(r.succeeded for r in response):
             return ids
@@ -566,9 +595,8 @@ async def adelete(self, ids: Optional[List[str]] = None, **kwargs: Any) -> bool:
             False otherwise.
         """
         if ids:
-            async with self.async_client as async_client:
-                res = await async_client.delete_documents([{"id": i} for i in ids])
-                return len(res) > 0
+            res = await self.async_client.delete_documents([{"id": i} for i in ids])
+            return len(res) > 0
         else:
             return False
 
@@ -748,7 +776,7 @@ async def avector_search_with_score(
             embedding, "", k, filters=filters, **kwargs
         )
 
-        return _results_to_documents(results)
+        return await _aresults_to_documents(results)
 
     def max_marginal_relevance_search_with_score(
         self,
@@ -897,7 +925,7 @@ async def ahybrid_search_with_score(
             embedding, query, k, filters=filters, **kwargs

----------------------------------------

File: libs/community/langchain_community/vectorstores/bigquery_vector_search.py
Status: modified
Changes: +1 -1
Diff:
@@ -38,7 +38,7 @@
 
 @deprecated(
     since="0.0.33",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_community.BigQueryVectorSearch",
 )
 class BigQueryVectorSearch(VectorStore):

----------------------------------------

File: libs/community/langchain_community/vectorstores/chroma.py
Status: modified
Changes: +2 -2
Diff:
@@ -50,7 +50,7 @@ def _results_to_docs_and_scores(results: Any) -> List[Tuple[Document, float]]:
     ]
 
 
-@deprecated(since="0.2.9", removal="0.4", alternative_import="langchain_chroma.Chroma")
+@deprecated(since="0.2.9", removal="1.0", alternative_import="langchain_chroma.Chroma")
 class Chroma(VectorStore):
     """`ChromaDB` vector store.
 
@@ -705,7 +705,7 @@ def get(

----------------------------------------

File: libs/community/langchain_community/vectorstores/couchbase.py
Status: modified
Changes: +1 -1
Diff:
@@ -14,7 +14,7 @@
 
 @deprecated(
     since="0.2.4",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_couchbase.CouchbaseVectorStore",
 )
 class CouchbaseVectorStore(VectorStore):

----------------------------------------

File: libs/community/langchain_community/vectorstores/databricks_vector_search.py
Status: modified
Changes: +1 -1
Diff:
@@ -657,7 +657,7 @@ def _alias_filters(kwargs: Dict[str, Any]) -> Optional[Dict[str, Any]]:
     if "filters" in kwargs:
         warn_deprecated(
             since="0.2.11",
-            removal="0.3",
+            removal="1.0",
             message="DatabricksVectorSearch received a key `filters` in search_kwargs. "
             "`filters` was deprecated since langchain-community 0.2.11 and will "
             "be removed in 0.3. Please use `filter` instead.",

----------------------------------------

File: libs/community/langchain_community/vectorstores/kdbai.py
Status: modified
Changes: +1 -1
Diff:
@@ -16,7 +16,7 @@
 class KDBAI(VectorStore):
     """`KDB.AI` vector store.
 
-     See [https://kdb.ai](https://kdb.ai)
+    See https://kdb.ai.
 
     To use, you should have the `kdbai_client` python package installed.
 

----------------------------------------

File: libs/community/langchain_community/vectorstores/matching_engine.py
Status: modified
Changes: +1 -1
Diff:
@@ -28,7 +28,7 @@
 
 @deprecated(
     since="0.0.12",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_google_vertexai.VectorSearchVectorStore",
 )
 class MatchingEngine(VectorStore):

----------------------------------------

File: libs/community/langchain_community/vectorstores/milvus.py
Status: modified
Changes: +1 -1
Diff:
@@ -25,7 +25,7 @@
 
 @deprecated(
     since="0.2.0",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_milvus.MilvusVectorStore",
 )
 class Milvus(VectorStore):

----------------------------------------

File: libs/community/langchain_community/vectorstores/mongodb_atlas.py
Status: modified
Changes: +1 -1
Diff:
@@ -35,7 +35,7 @@
 
 @deprecated(
     since="0.0.25",
-    removal="0.3.0",
+    removal="1.0",
     alternative_import="langchain_mongodb.MongoDBAtlasVectorSearch",
 )
 class MongoDBAtlasVectorSearch(VectorStore):

----------------------------------------

File: libs/community/langchain_community/vectorstores/pinecone.py
Status: modified
Changes: +1 -1
Diff:
@@ -43,7 +43,7 @@ def _is_pinecone_v3() -> bool:
 
 
 @deprecated(
-    since="0.0.18", removal="0.3.0", alternative_import="langchain_pinecone.Pinecone"
+    since="0.0.18", removal="1.0", alternative_import="langchain_pinecone.Pinecone"
 )
 class Pinecone(VectorStore):
     """`Pinecone` vector store.

----------------------------------------

File: libs/community/langchain_community/vectorstores/qdrant.py
Status: modified
Changes: +1 -3
Diff:
@@ -66,9 +66,7 @@ async def wrapper(self: Any, *args: Any, **kwargs: Any) -> Any:
     return wrapper
 
 
-@deprecated(
-    since="0.0.37", removal="0.3.0", alternative_import="langchain_qdrant.Qdrant"
-)
+@deprecated(since="0.0.37", removal="1.0", alternative_import="langchain_qdrant.Qdrant")
 class Qdrant(VectorStore):
     """`Qdrant` vector store.

----------------------------------------

File: libs/community/poetry.lock
Status: modified
Changes: +8 -7
Diff:
@@ -1,4 +1,4 @@
-# This file is automatically @generated by Poetry 1.8.2 and should not be changed by hand.
+# This file is automatically @generated by Poetry 1.8.3 and should not be changed by hand.
 
 [[package]]
 name = "aiohappyeyeballs"
@@ -2110,7 +2110,7 @@ files = [
 
 [[package]]
 name = "langchain"
-version = "0.2.12"
+version = "0.2.13"
 description = "Building applications with LLMs through composability"
 optional = false
 python-versions = ">=3.8.1,<4.0"
@@ -2120,7 +2120,7 @@ develop = true
 [package.dependencies]
 aiohttp = "^3.8.3"
 async-timeout = {version = "^4.0.0", markers = "python_version < \"3.11\""}
-langchain-core = "^0.2.27"
+langchain-core = "^0.2.30"
 langchain-text-splitters = "^0.2.0"

----------------------------------------

File: libs/community/pyproject.toml
Status: modified
Changes: +3 -3
Diff:
@@ -4,7 +4,7 @@ build-backend = "poetry.core.masonry.api"
 
 [tool.poetry]
 name = "langchain-community"
-version = "0.2.11"
+version = "0.2.12"
 description = "Community contributed LangChain integrations."
 authors = []
 license = "MIT"
@@ -30,8 +30,8 @@ ignore-words-list = "momento,collison,ned,foor,reworkd,parth,whats,aapply,mysogy

----------------------------------------

File: libs/community/tests/integration_tests/embeddings/test_zhipuai.py
Status: modified
Changes: +11 -0
Diff:
@@ -18,3 +18,14 @@ def test_zhipuai_embedding_query() -> None:
     embedding = ZhipuAIEmbeddings()  # type: ignore[call-arg]
     res = embedding.embed_query(document)
     assert len(res) == 1024  # type: ignore[arg-type]
+
+
+def test_zhipuai_embedding_dimensions() -> None:
+    """Test ZhipuAI Text Embedding for query by assigning dimensions"""
+    document = "This is a test query."
+    embedding = ZhipuAIEmbeddings(

----------------------------------------

